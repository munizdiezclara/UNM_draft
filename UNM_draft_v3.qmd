---
title: "Effects of expected and unexpected uncertainty on cue processing"
# If blank, the running header is the title in upper case.
shorttitle: "Effects of uncertainty on cue processing"
# Set names and affiliations.
# It is nice to specify everyone's orcid, if possible.
# There can be only one corresponding author, but declaring one is optional.
author:
  - name: Clara Muñiz-Diez
    corresponding: true
    orcid: 0000-0001-5192-0462
    email: c.muniz-diez@lancaster.ac.uk
    # Roles are optional. 
    # Select from the CRediT: Contributor Roles Taxonomy https://credit.niso.org/
    # conceptualization, data curation, formal Analysis, funding acquisition, investigation, 
    # methodology, project administration, resources, software, supervision, validation, 
    # visualization, writing, editing
    affiliations:
      - id: id1
        name: "Lancaster University"
        department: Department of Psychology
        city: Lancaster
        region: UK
  - name: Sandra Lagator
    orcid: 0000-0001-6060-2941
    affiliations: 
      - id: id2
        name: "The University of Nottingham"
        department: School of Psychology
        city: Nottingham
        region: UK
  - name: Mark Haselgrove
    orcid: 0000-0001-8981-1181
    affiliations:
      - ref: id2
  - name: Tom Beesley
    orcid: 0000-0003-2836-2743
    # List city and region/state for unaffiliated authors
    affiliations:
      - ref: id1
author-note:
  status-changes: 
    # Example: [Author name] is now at [affiliation].
    affiliation-change: ~
    # Example: [Author name] is deceased.
    deceased: ~
  # Disclosures condensed to one paragraph, but you can start a field with two line breaks to break them up: \n\nNew Paragraph
  disclosures:
    # Example: This study was registered at X (Identifier Y).
    study-registration: ~
    # Acknowledge and cite data/materials to be shared.
    data-sharing: "The programs of the experiments presented here, the data and the full code for the writing this manuscript are freely available on www.github.com/munizdiezclara/UNM_draft."
    # Example: This article is based on data published in [Reference].
    # Example: This article is based on the dissertation completed by [citation].  
    related-report: ~
    # Example: [Author name] has been a paid consultant for Corporation X, which funded this study.
    conflict-of-interest: ~
    # Example: This study was supported by Grant [Grant Number] from [Funding Source].
    financial-support: "This study was supported by the ESRC grant Known unknowns and unknown unknowns (ES/W013215/1)." 
    # Example: The authors are grateful to [Person] for [Reason].
    gratitude: ~
    # Example. Because the authors are equal contributors, order of authorship was determined by a fair coin toss.
    authorship-agreements: ~
abstract: "Learning influences the overt attention that is paid to stimuli in two main ways: first, stimuli which are reliable predictors of an outcome are paid more attention than unreliable stimuli; and second, stimuli associated with uncertain outcomes capture more attention than stimuli associated with certain outcomes. Past studies have shown that these two phenomena can be demonstrated within the same experiment, but strikingly, the increase in attention due to uncertainty does not necessarily translate into subsequent better learning. We investigate this paradox by examining stimulus processing in three experiments that included predictive and non-predictive cues, trained under different conditions of uncertainty. In Experiment 1, this test revealed that recognition  memory was similar after learning with certain and uncertain stimulus-outcome contingencies. In Experiment 2, uncertain contingencies were introduced after a period of learning with certain contingencies. During the subsequent memory test, this training resulted in better memory than training with certain contingencies throughout the learning phase. These results suggest the importance of drawing a distinction between expected and unexpected uncertainty on stimulus processing. The implications of these results for attentional models of learning are discussed."
# Put as many keywords at you like, separated by commmas (e.g., [reliability, validity, generalizability])
keywords: [Associative Learning, Attention, Uncertainty, Predictiveness, Cue processing]
# If true, tables and figures are mingled with the text instead of listed at the end of the document.
floatsintext: true
# Numbered lines (.pdf and .docx only)
numbered-lines: false
# File with references
bibliography: references.bib
# Suppress title page
suppress-title-page: false
# Masks references that appear in the masked-citations list
mask: false
masked-citations:
  - schneider2012cattell
  - schneider2015intelligence
# Language options. See https://quarto.org/docs/authoring/language.html
lang: en
language:
  citation-last-author-separator: "and"
  citation-masked-author: "Masked Citation"
  citation-masked-date: "n.d."
  citation-masked-title: "Masked Title"
  title-block-author-note: "Author Note"
  title-block-correspondence-note: "Correspondence concerning this article should be addressed to"
  title-block-role-introduction: "Author roles were classified using the Contributor Role Taxonomy (CRediT; https://credit.niso.org/) as follows:"
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-pdf:
    # Can be jou (journal), man (manuscript), stu (student), or doc (document)
    documentmode: man
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(afex)
library(BayesFactor)
library(apa)
library(emmeans)
library(papaja)
library(rstatix)
library("writexl")
options(scipen=999)
bfit = 10000

# function to force scientific formatting of numbers (used for large BFs)
changeSciNot <- function(n) {
  output <- format(n, scientific = TRUE, digits = 2) #Transforms the number into scientific notation even if small
  output <- sub("e", "x10^", output) #Replace e with 10^
  output <- sub("\\+0?", "", output) #Remove + symbol and leading zeros on exponent, if > 1
  output <- sub("-0?", "-", output) #Leaves - symbol but removes leading zeros on exponent, if < 1
  output <- paste0(output,"^")
  # output = strsplit(output, "^", fixed = TRUE)
  # output = paste0(output[[1]][1],"^", output[[1]][2], "^")
  output
}
# function to extract and report BFs with error %s
report_BF_and_error <- function(BF_in, sci_not = FALSE, hyp = "alt"){
  
  if (hyp == "alt") {
    BF_notation = "BF~10~ = "
  } else if (hyp == "null") {
    BF_notation = "BF~01~ = "
  }
  
  if (sci_not == TRUE) {
    BF_value = changeSciNot(extractBF(BF_in)$bf) # change to sci notation
  } else {
    BF_value = round(extractBF(BF_in)$bf,2) # otherwise round
  }
  
  paste0(BF_notation, 
         BF_value, 
         " &plusmn; ", 
         round(100*extractBF(BF_in)$error,2), 
         "%")
}
```

A central feature of the cognition of humans and other animals is the ability to learn the predictive relationships between events in the world in order to anticipate future goals and modify behaviour accordingly. However, not all events that co-occur have predictive validity, that is, not all events that happen at the same time are related to each other; furthermore, because of capacity limitations, processing all stimulus pairings would neither be functional nor possible. The cognitive system must therefore select events that are task relevant to focus resources and refine the allocation of attention. The attention that is paid to a stimulus plays an important role in models of associative learning. Take for example the influential Rescorla & Wagner [-@rescorlaTheoryPavlovianConditioning1972] model, in which, the parameter $\alpha$ refers to the salience of a cue. The inherent salience of a cue (e.g., how loud a sound is; how bright a light is) will determine how much it captures attention, and thus how successful learning will be with it. However, the attention paid to a stimulus is not just inherent – it can also be determined by its associative history [for a review, see @lepelleyAttentionAssociativeLearning2016]; that is, from what has been previously learned about that stimulus. For example, at busy pedestrian crossings/crosswalks it is common for a sound to be played when it is safe to cross. Through experience, this sound will readily come to capture attention due to its predictive nature, while other salient but non-predictive stimuli (e.g., an advertising billboard) will not.

There are two main ways in which learning can shape attention. The first is often referred to as the *predictiveness principle*, according to which attention increases to stimuli that reliably signal the occurrence of an outcome [e.g., @mackintoshTheoryAttentionVariations1975; see also: @kruschkeUnifiedModelAttention2001; -@kruschkeAttentionLearning2003; @lepelleyRoleAssociativeHistory2004]. It is thought that this mode of attention is advantageous as it allows for the *exploitation* of reliable knowledge and permits animals to be prepared to make responses to stimuli with known consequences. A common method for studying this process in the lab is with the “learned predictiveness” design [e.g., @lepelleyLearnedAssociabilityAssociative2003]. In this contingency learning procedure, cues are trained as differentially predictive of particular outcomes (e.g., in the allergist task, participants are instructed that various foods are differentially predictive of one kind of allergic reaction or another on an imaginary patient). Typically, compounds of cues are presented, where one cue is perfectly predictive of an outcome, while the other is non-predictive. Take for example, a training phase in which compounds AX and AY are followed by outcome 1, whereas compounds BX and BY are followed by outcome 2. Here, cues A and B are predictive of outcomes 1 and 2 respectively, but cues X and Y are non-predictive, being paired with outcomes 1 and 2 equally often. Once this training is complete and participants show good levels of learning, a second phase is introduced, in which the cues are trained with new outcomes, and both cues are now perfectly predictive of these outcomes (e.g., AX-O3; BY-O4). The central finding of this procedure is that, in the second phase, participants learn more about the cues that were predictive in the first phase than about the cues that were previously non-predictive. The interpretation of this result [e.g., @lepelleyLearnedAssociabilityAssociative2003] is that, in the first phase, the cues that were established as predictive undergo an increase in their ability to attract attention, which enhances learning in the second phase. Consistent with this interpretation is the observation that (a) cues which have been established as predictive attract longer eye-gaze durations than non-predictive cues and (b) this overt measure of differential attention correlates with the bias established to learning [@lepelleyOvertAttentionPredictiveness2011]. The learned predictiveness effect has been extensively replicated and reproduced in studies of learning [for a review, see: @lepelleyAttentionAssociativeLearning2016].

The second way in which learning can modify the attention paid to stimuli is the *uncertainty principle* [e.g., @pearceModelPavlovianLearning1980; see also: @lepelleyModelingAttentionAssociative2012; @schmajukLatentInhibitionNeural1996] which states that more attention will be paid to cues which have an uncertain outcome. It is thought that this mode of attention is useful as it allows for the exploration of cues, whose predictive validity is uncertain, in order to discover relationships between these events. Griffiths et al. [-@griffithsNegativeTransferHuman2011] showed an instance of this principle using the “negative transfer” procedure. In this study, participants experienced a stimulus followed by a small-magnitude outcome (a food predicted a minor allergic reaction) in the first phase, and the same stimulus followed by a larger-magnitude outcome (a food predicted a critical allergic reaction) in the second phase. The study had two groups, with the only difference between the groups being that one group received a small number of presentations of the stimulus in the absence of the outcome between the first and second phases of the experiment in order to introduce uncertainty into the learnt contingency. The critical result was that the group that received “no outcome” trials learned more quickly about the large outcome in the second phase, compared to the group who did not have these no outcome trials. This result suggests that this brief period of uncertainty enhanced the attention paid to the cues facilitating subsequent learning[^1].

[^1]: It should be noted that this result has proved difficult to reproduce (see Le Pelley et al., 2016).

At face value, these two principles seem to be incompatible or contradictory: the predictiveness principle states we focus resources on cues that we know about, whilst the uncertainty principle states that we focus resources on cues we are less sure about. However, it is quite possible that both principles operate and describe changes in the allocation of attention, depending on the experienced contingencies. In fact, a number of hybrid models of learning and attention have tried to reconcile the evidence in favour of both principles [e.g., @esberReconcilingInfluencePredictiveness2011; @lepelleyRoleAssociativeHistory2004; @pearceTwoTheoriesAttention2010], and some of them propose that the predictiveness and the uncertainty principles may have different functions [e.g., @kerstenTwoCompetingAttentional1998; @lepelleyRoleAssociativeHistory2004]. The predictiveness principle leads to a prioritization of information in situations in which outcome events are reliable. However, when outcome events are less stable, it is less advantageous to invest cognitive resources in exploiting what is known. Under these circumstances it might be more advantageous to explore other sources of information, in order to attempt to reduce the uncertainty in the environment. For example, a teacher can easily identify students that might need extra help, solely focusing on their grades on the exams. However, there might be students who pass those exams, but show other, less reliable signs of a need for extra help, such as poor class engagement or absenteeism. For this reason, if the teacher wants to better understand the needs of their students, they might explore new signals in order to reduce uncertainty.

There is a growing body of evidence that points towards both principles operating in parallel in human contingency learning tasks [@koenigRewardDrawsEye2017; @luquePredictionUncertaintyAssociative2017; @torrents-rodasEvidenceTwoAttentional2021]. Beesley et al. [-@beesleyUncertaintyPredictivenessDetermine2015], for example, adapted the learned predictiveness design of Le Pelley and McLaren [-@lepelleyLearnedAssociabilityAssociative2003] to manipulate both predictiveness and uncertainty within the same procedure. In this study, each compound of cues had either a certain contingency with the outcome (i.e., it was consistently followed by the same outcome), or an uncertain contingency (i.e., it was probabilistically related to the outcomes, with one outcome occurring on 70% of trials, and the other on 30% of trials). Measuring participants eye gaze, this study showed that on “uncertain trials”, all cues (both predictive and non-predictive) received more attention than the cues did on “certain trials”. However, a predictiveness effect was also evident, with higher attention to predictive than to non-predictive cues, although this effect was only evident for cues. Thus, this study showed that attention is both determined by the uncertainty principle, since there was higher attention when uncertainty was high, as well as by the predictiveness principle, since within each compound, attention was devoted more to predictive over non-predictive cues.

A study by Easdale et al. [-@easdaleOnsetUncertaintyFacilitates2019] examined how these differences in uncertainty affected the rate of learning about cues. Participants experienced the same certain and uncertain contingencies as in Beesley et al. [-@beesleyUncertaintyPredictivenessDetermine2015] in a first phase, before receiving a second phase in which there were new contingencies to learn that would resolve the uncertainty entirely. Contrary to the expectations of models of the uncertainty principle [e.g., @pearceModelPavlovianLearning1980] it was found that participants who initially experienced the uncertain contingencies learnt about these new contingencies more *slowly* than those participants who first learnt about certain contingencies. Easdale et al. argued that this result provides evidence to support a distinction between “expected uncertainty” and “unexpected uncertainty”: in the former, participants may learn to anticipate variation in the outcome, which then leads to slower acquisition of the new contingencies [see also, @behrensLearningValueInformation2007].

Torrent-Rodas et al. [-@torrents-rodasEffectPredictionError2023] also examined the impact of uncertainty on overt attention and new learning using a within-subjects design. In a first phase they found that non-predictive cues that were associated with maximal prediction error (e.g., cue X during XZ-O1 and XZ-O2 training) received higher levels of attention compared to predictive cues (e.g., cues A and B during AZ-O1 and BZ-O2 training). However, when the participants were given new contingencies to learn in a second stage, discriminations between compounds that relied on previously non-predictive cues were not learnt at a faster rate than those that relied on previously predictive cues. Thus, like the results of Easdale et al., the data from Torrents-Rodas et al. suggest that expected uncertainty drives higher levels of overt attention to cues, but this does not translate into more rapid learning. One of the reasons why this finding of slower learning under conditions of expected uncertainty is surprising, is that participants in this condition showed higher attention to the cues in the first stage. Thus, the data from Easdale et al. and Torrents-Rodas et al. represent a paradoxical set of results for theories of associative learning to explain, since participants were overtly attending to cues more in the uncertain condition, yet this did not translate into faster learning about these cues. All attentional theories of associative learning predict that the attention paid to a stimulus is directly related to the rate at which learning occurs for that stimulus. This raises the question of what the high levels of overt attention to uncertain cues represent in the results of Beesley et al. [-@beesleyUncertaintyPredictivenessDetermine2015], Easdale et al. [-@easdaleOnsetUncertaintyFacilitates2019], and Torrents-Rodas et al. [-@torrents-rodasEffectPredictionError2023]. It is this process that is currently poorly understood and is the focus of the current study.

A critical question arises from this paradox: do uncertain conditions result in an increase in cognitive processing? Pearce and Hall [-@pearceModelPavlovianLearning1980] thought so, suggesting that stimuli which are part of an unfamiliar (i.e. unlearned) task undergo more controlled processing (Pearce and Hall, 1980, p 549) and only transition to more automatic processing once the task is familiar. Consequently, we might expect that uncertainty should not only increase just the associative learning pertaining to these stimuli (i.e., “learning rate”), but also the memory of the stimulus representation itself [@chunInteractionsAttentionMemory2007]. For example, Otten et al. [-@ottenBrainActivityEvent2006] have shown that neural activity associated with a cue to semantically process an upcoming stimulus predicts the successful later retrieval of that stimulus at test; deeper processing tasks encourage richer encoding.

In the current study, two experiments were conducted with a design similar to the one employed by Beesley et al. [-@beesleyUncertaintyPredictivenessDetermine2015], in which the predictiveness and the uncertainty of the cues were manipulated. Based on the notion that greater stimulus processing is associated with superior memory recall [@craikLevelsProcessingFramework1972; @craikDepthProcessingRetention1975; @fletcherFunctionalRolesPrefrontal1998]. Stimulus processing was measured by means of a recognition memory test for the cues at the end of the task. Experiment 1 assessed the memory for predictive and non-predictive cues trained either under certain or expected uncertain cues, and Experiment 2 contrasted the effect of expected and unexpected uncertainty.

# Experiment 1

The purpose of Experiment 1 was to examine differences in recognition memory in a learned predictiveness procedure under certain and uncertain cue-outcome contingency conditions. Two groups were trained, one with a perfect contingency between the predictive cues and their paired outcome (Group Certain) and one with a contingency of 0.8 between the predictive cues and their paired outcome (Group Uncertain). After this training, we tested the memory for cues in both groups using a forced choice memory test, between a cue participants had seen in the training phase, the target, and a foil, very similar to the cues seen before.

The design of Experiment 1 is shown in @tbl-exp1. Previous experiments have established that for uncertain contingencies, participants spend longer attending to (looking at) all cues compared to attention to cues in certain contingencies [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019; @walkerProtectionUncertaintyExploration2022]. Experiment 1 therefore aimed to test whether uncertain contingencies, where it is well established that there is a high level of attention to cues, result in an improvement in the processing of these stimuli. As such, we predicted that memory would be better, overall, for the cues in group Uncertain compared to group Certain. Also, on the basis of the better attention found to predictive than non-predictive cues in the learned predictiveness effect, we anticipate seeing superior memory scores for the predictive than the non-predictive cues in group Certain.

::: {#tbl-exp1 apa-note="Uppercase letters A, B, X, and Y represent the cues presented during training. O1 and O2 represent the outcomes presented in training. Lowercase letters a, b, x, and y represent the foils that are similar to the (corresponding upper-case letter) cues presented in the training phase. The numbers before the trials define the proportion of trials of that type that were presented." apa-twocolumn="true"}
+----------------+---------------------------+------------------+
| Group          | Training                  | Test             |
+================+:=========================:+:================:+
| Certain        | AX - O1                   | A vs *b*/*x*/*y* |
|                |                           |                  |
|                | AY - O1                   | B vs *a*/*x*/*y* |
|                |                           |                  |
|                | BX - O2                   | X vs *a*/*b*/*y* |
|                |                           |                  |
|                | BY - O2                   | Y vs *a*/*b*/*x* |
+----------------+---------------------------+------------------+
| Uncertain      | 0.8 AX - O1 / 0.2 AX - O2 | A vs *b*/*x*/*y* |
|                |                           |                  |
|                | 0.8 AY - O1 / 0.2 AY - O2 | B vs *a*/*x*/*y* |
|                |                           |                  |
|                | 0.8 BX - O2 / 0.2 BX - O1 | X vs *a*/*b*/*y* |
|                |                           |                  |
|                | 0.8 BY - O2 / 0.2 BY - O1 | Y vs *a*/*b*/*x* |
+----------------+---------------------------+------------------+

Design of Experiment 1
:::

## Methods

### Transparency and openness statement

In this study we detail the processes for identifying any data to be excluded, any data exclusions and all measures in the study. Statistical analyses were conducted using RStudio [-@positteamRStudio2024], with R version 4.3.3 [@rcoreteamLanguageEnvironmentStatistical2023]. All experiments were built with the open-source software PsychoPy [v. 2022.2.4, @peircePsychoPy2ExperimentsBehavior2019], and all experiments were run on Pavlovia. Participants were recruited through Prolific. The design and analysis of the experiments were based on previously published manuscripts but were not preregistered. Materials and data are freely available at: www.github.com/munizdiezclara/UNM_draft. All the experiments reported in this paper received ethical approval by the Ethics Committee at the School of Psychology, Lancaster University, UK.

### Participants

```{r, include=FALSE}
#load the data
load("UNM07_proc_data.RData")
UNM07_demographics <- demographics
UNM07_training <- training
UNM07_test <- test
UNM07_not_passed <- not_passed_pNum

#create the PPR measure
UNM07_training <- UNM07_training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0, 
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1))

#detect and clean participants that not passed the test comprehension check
UNM07_training <- filter(UNM07_training, !pNum %in% UNM07_not_passed$pNum)
UNM07_test <- filter(UNM07_test, !pNum %in% UNM07_not_passed$pNum)
```

`r nrow(UNM07_demographics)` participants were recruited through Prolific. The sample consisted of `r length(which(UNM07_demographics$gender == "female"))` women, `r length(which(UNM07_demographics$gender == "male"))` men and one non-binary person, with `r n_distinct(UNM07_demographics$Nationality)` different nationalities. The mean age was `r format(mean(UNM07_demographics$age, na.rm = TRUE), digits = 3)` calculated for the `r nrow(UNM07_demographics) - sum(is.na(UNM07_demographics$age))` participants that reported their age (range `r min(UNM07_demographics$age, na.rm = TRUE)` - `r max(UNM07_demographics$age, na.rm = TRUE)`). Pre-screening of participants in Prolific ensured that they had normal or corrected to normal vision, fluency in English language, and had not participated in previous studies from our lab. Participants were rewarded with £2.70 for their participation in the study. Participants were randomly allocated to either the Certain or Uncertain condition. Four participants were excluded due to failing the comprehension check before the test (three in group Certain and one in group Uncertain). Post-hoc calculations using G\*Power 3.1 [@faulStatisticalPowerAnalyses2007] revealed that this sample size had a power of .99 to detect an effect size of *η~p~^2^* = .08 that was observed for the *group x predictiveness* interaction reported in @fig-testExp1.

### Apparatus and stimuli

Participants were presented with a task built in PsychoPy [v. 2022.2.4, @peircePsychoPy2ExperimentsBehavior2019] and hosted in Pavlovia. The task was designed so it could only be run on a computer, but not on mobile devices. The screen background colour was grey (RGB: 128, 128, 128) and all stimuli and instructions were presented against this background. The four cues presented to each participant (A, B, X and Y) were randomly selected from a set of eight images, representing imaginary chemical compounds made of three red circles and three blue circles connected with black lines. Each cue was 945 x 945 pixels, automatically re-scaled to 0.4 x 0.4 of the window height. The foils (*a*, *b*, *x* and *y*) used in the tests were colour-modifications of the original cues: the colours of one red and one blue circle were switched (four remained unchanged). The outcomes (O1 and O2) were two images displaying a mutant creature, black with yellow details. Each was 332 x 664 pixels, automatically re-scaled to 0.16 x 0.2 of the window height. All of the images used in the experiment are presented in Appendix I.

### Design

The design of Experiment 1 is shown in @tbl-exp1. The experiment used a mixed design, with cue-predictiveness (P and NP) manipulated within-subjects and the contingency between predictive cues and outcomes manipulated between-subjects (group Certain and Uncertain). The training phase consisted of eight block, each consistent of 20 trials. There were four trial types (compound cues), each presented five times per block, with cues A and B predictive of outcome 1 and 2, respectively. In the Certain group, cues A and B were perfectly predictive of the outcomes they were paired with, while cues X and Y were non-predictive. For the Uncertain group, cues A and B were the best available predictors on each trial but had a 0.8 contingency with the predicted outcome. To implement this contingency, in each block, for four of the five trials one outcome was “correct” (e.g., AX-O1) and for the remaining one the alternative outcome was “correct” (e.g., AX-O2). Cues X and Y were paired equally often with outcomes 1 and 2 and were therefore non-predictive. The position of the cues and the outcomes (right-left), as well as the order of presentation of the trials, was fully randomized within each block. 

Training was followed by a memory test, consisting of six presentations of each of the four cues (24 trials in total). Each cue was presented twice with each of the three foils shown in @tbl-exp1. For example, cue A was presented with the foil corresponding to cue B, the foil corresponding to cue X, and the foil corresponding to cue Y. The left-right display of the target and the foil was counterbalanced, in such a way that each target appeared once on the left and once on the right.

### Procedure

Participants were presented with the study information and responded to a series of questions to give informed consent. If participants gave consent, they proceeded to the training phase instructions. These described the initial learning task, in which they would see two images of fictitious chemicals that would be mixed to produce a mutant creature. Participants were told that their task was to predict which mutant will result from each combination of chemicals. They were also instructed to use the feedback provided after their decision to make their future choices more accurate.

After reading the instructions, participants were presented with a comprehension check, in which the instructions were summarised, and they were asked to select the answer that best described what they had to do in the task. The experiment ended if participants failed this comprehension check twice. If participants passed the comprehension check, they proceeded to the training phase.

All the trials in the training phase started with a 0.5 second blank screen. After that, two cues were presented in the top part and the two outcomes in the bottom part. The coordinates (x/y PsychoPy height units) of the centre of the four stimuli images were: left cue, -0.3 x 0.2; right cue, 0.3 x 0.2 left outcome, -0.125 x -0.2; right outcome, 0.125 x -0.2. All stimuli were rescaled according to the height of the monitor. The participants had to select one of the outcomes by clicking on them, which was indicated by a yellow frame surrounding the selected outcome. Feedback was provided after 0.5 seconds: the correct outcome was surrounded by a green frame. If the correct outcome was selected by participants, the message “CORRECT!” was displayed in the centre of the screen in green (RGB: 0, 255, 0), otherwise the message “INCORRECT!” appeared in red (RGB: 255, 0, 0). After two seconds, the next trial started. If participants failed to select an outcome within 10 seconds of the trial starting, all images disappeared from the screen and the message “TIMEOUT - TOO SLOW” was presented in the centre of the screen in red, and the next trial started after one second. An example of a training trial can be seen in @fig-trainexample.

```{r @fig-trainexample}
#| label: fig-trainexample
#| fig-cap: An example of a Training Trial in Experiment 1.
#| apa-twocolumn: true
#| apa-note: "The timings represent the duration of each display. "
#| out-width: 100%
#| fig-pos: h
knitr::include_graphics("images/trainexample.png")
```

Once participants had completed the training phase, the instructions for the memory test were displayed, telling participants that they were about to see two similar chemicals on each trial, and only one of them had appeared in the previous task. They had to select that chemical and then rate their confidence on a scale from 1 to 10 (see below). No feedback on response accuracy was provided. After the instructions, a comprehension check was included, presented only once and participants continued to the test, irrespective of the response given.

All test trials started with a 0.5 second blank screen. After that, the images of a target (a cue presented in the training phase), and a foil were presented in the top half of the screen. These images had the same size and position as in the training phase. Participants had to click on the image they thought they had seen in the previous phase, after which a rating scale was displayed for them to give a confidence rating. Above this rating scale, the question *How confident are you of your response?* was displayed. The rating scale had 10 points, with the labels *I am guessing* on the left end (point 1), and *I am certain* on the right end (point 10), and a red dot in the middle. Participants had to click on the rating scale to move the red dot to give their confidence rating. After this, a button with the word *CONTINUE* appeared. All responses in the test phase had no time limit and participants could advance to the next test trial at their own pace. The test trials procedure is shown in @fig-testexample.

```{r @fig-testexample}
#| label: fig-testexample
#| fig-cap: An example of a test Trial in Experiment 1.
#| apa-twocolumn: true
#| apa-note: "The timings represent the duration of each display. "
#| out-width: 100%
#| fig-pos: h
knitr::include_graphics("images/testexample.png")
```

## Results

Since participants in the uncertain condition received trials in which the alternative outcome was presented on 20% of the trials, even if participants in group Uncertain were to always select the most probable outcome (O1 when A is present and O2 when B is present), it would result in an accuracy score of 80%. Thus, we calculated the proportion of probable responses (PPR): for the Uncertain group, on each trial, the score was 0 when participants chose the less probable outcome (i.e., O2 for A and O1 for B) and 1 when they chose the most probable outcome (i.e., O1 for A and O2 for B). For the certain condition, this equates to a standard accuracy score.

```{r, include = FALSE}
#Calculate the mean PPR and standard error for each block, including the groups
UNM07_MA_training <- UNM07_training %>%
  group_by(block, condition) %>%
  summarise(mean_accuracy = mean(prob_response, na.rm = TRUE), 
            se_accuracy = sd(prob_response, na.rm = TRUE)/sqrt(length(prob_response)))
```

@fig-trainingExp1 shows the mean PPR across blocks for each group. Participants in the Certain group showed a higher PPR through training than the Uncertain group, reaching a PPR of about 0.85 on block 8. The Uncertain group showed consistently lower PPR, that reached approximately 0.7 in block 8.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-trainingExp1
#| fig-cap: PPR on the training phase of Experiment 1.
#| apa-note: "Mean proportion of probable responses (±SEM) during the training phase of Experiment 1, for groups trained with certain and uncertain contingencies."
#| fig-height: 4
ggplot(UNM07_MA_training, mapping = aes(x = block, y = mean_accuracy, group = condition, color = condition)) +
  geom_point(mapping = aes(shape = condition), size = 2.5) +
  geom_line() +
  geom_errorbar(aes(x= block, y = mean_accuracy, ymin = mean_accuracy-se_accuracy, ymax = mean_accuracy+se_accuracy), colour = "black", width=.1)+
  scale_x_continuous(name = "Block") + 
  labs(shape = "Group", colour = "Group") +
  scale_color_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8))+
  scale_y_continuous(name = "PPR", limits = c(NA, 1))+
  theme_apa()
```

```{r, include=FALSE}
#ANOVA
UNM07_acc <- UNM07_training %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
UNM07_acc$block <- factor(UNM07_acc$block)
UNM07_acc$pNum <- factor(UNM07_acc$pNum)
UNM07_acc$condition <- factor(UNM07_acc$condition)
ANOVA_UNM07_acc <- aov_car(formula = mean_response ~ condition + Error(pNum/block), data = UNM07_acc)
print(ANOVA_UNM07_acc)
#Bayesian Anova
bay_ANOVA_UNM07_acc <- anovaBF(formula = mean_response ~ condition + block + pNum,
        data = data.frame(UNM07_acc),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM07_acc)
bay_ANOVA_UNM07_acc_int <- bay_ANOVA_UNM07_acc[4]/bay_ANOVA_UNM07_acc[3]
print(bay_ANOVA_UNM07_acc_int)
```

This data were analysed with a mixed model ANOVA including the between-subjects factor * group* and the within-subjects factor *predictiveness*. This ANOVA (and all the following ones in the paper) included the Greenhouse-Geisser correction of the degrees of freedom when the sphericity asumption was not fulfilled. The ANOVA found significant both the main effect of *group*, `r apa(ANOVA_UNM07_acc, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM07_acc[2])`, and of *block*, `r apa(ANOVA_UNM07_acc, effect = "block")`, `r report_BF_and_error(bay_ANOVA_UNM07_acc[1], sci_not = TRUE)`. There was no interaction effect between these factors, `r apa(ANOVA_UNM07_acc, effect = "condition:block")`, `r report_BF_and_error(bay_ANOVA_UNM07_acc_int[1])`. These results indicate that the training increased the PPR for both groups, as the effect of block was significant, with the Certain group showing a consistently higher PPR than Uncertain group.

```{r, include=FALSE}
#Calculate the mean accuracy and standard error for each block, including the groups
MA_test <- UNM07_test %>%
  group_by(condition, predictiveness) %>%
    summarise(mean_acc = mean(acc, na.rm = TRUE), 
            se_acc = sd(acc, na.rm = TRUE)/sqrt(length(acc)))
```

@fig-acctestExp1 shows the accuracy results from the recognition memory test. Accuracy for non-predictive cues was lower than for the predictive cues in the Certain group, but this difference was not present in the Uncertain group. Also, accuracy was similar in both groups.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-acctestExp1
#| fig-cap: Accuracy on the test phase of Experiment 1.
#| apa-note: "Mean accuracy (±SEM) during the test phase of Experiment 1, for groups trained with certain and uncertain contingencies."
#| fig-height: 4
ggplot(data = MA_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain')), y = mean_acc, fill = predictiveness)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(y= mean_acc, ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width = .2, position = position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_y_continuous(name = "Accuracy") +
  coord_cartesian(ylim = c(0.5, 1)) +
  scale_fill_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  theme_apa()
```

```{r, include=FALSE}
#ANOVA accuracy
acc_UNM07_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
acc_UNM07_test$predictiveness <- factor(acc_UNM07_test$predictiveness)
acc_UNM07_test$condition <- factor(acc_UNM07_test$condition)
acc_UNM07_test$pNum <- factor(acc_UNM07_test$pNum)
ANOVA_acc_UNM07_test <- aov_car(formula = acc ~ condition + Error(pNum*predictiveness), data = acc_UNM07_test)
print(ANOVA_acc_UNM07_test)

bay_ANOVA_acc_UNM07_test <- anovaBF(formula = acc ~ condition*predictiveness + pNum,
        data = data.frame(acc_UNM07_test),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_acc_UNM07_test)

bay_ANOVA_acc_UNM07_test_gxp <- bay_ANOVA_acc_UNM07_test[4]/bay_ANOVA_acc_UNM07_test[3]
print(bay_ANOVA_acc_UNM07_test_gxp)
```

```{r, include = FALSE}
# SME of the condition:predictiveness interaction
SME_acc_UNM07_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
#calculate the simple main effect of condition
sme_acc_UNM07_test_condition <- SME_acc_UNM07_test %>%
  group_by(predictiveness) %>%
  anova_test(acc ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_acc_UNM07_test_condition #Call the output table
#calculate the simple main effect of predictiveness
sme_acc_UNM07_test_pred <- SME_acc_UNM07_test %>%
  group_by(condition) %>%
  anova_test(acc ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_acc_UNM07_test_pred #Call the output table

SME_acc_UNM07_test_certain <- filter(UNM07_test, condition == "Certain") %>%
  group_by(pNum, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
SME_acc_UNM07_test_certain$predictiveness <- factor(SME_acc_UNM07_test_certain$predictiveness)
SME_acc_UNM07_test_certain$pNum <- factor(SME_acc_UNM07_test_certain$pNum)

SME_acc_UNM07_test_uncertain <- filter(UNM07_test, condition == "Uncertain") %>%
  group_by(pNum, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
SME_acc_UNM07_test_uncertain$predictiveness <- factor(SME_acc_UNM07_test_uncertain$predictiveness)
SME_acc_UNM07_test_uncertain$pNum <- factor(SME_acc_UNM07_test_uncertain$pNum)

bay_SME_acc_UNM07_test_certain <- anovaBF(formula = acc ~ predictiveness + pNum,
        data = data.frame(SME_acc_UNM07_test_certain),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_acc_UNM07_test_certain)
bay_SME_acc_UNM07_test_uncertain <- anovaBF(formula = acc ~ predictiveness + pNum,
        data = data.frame(SME_acc_UNM07_test_uncertain),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_acc_UNM07_test_uncertain)
```

A mixed model ANOVA with the between subjects-factor *group* (Uncertain vs Certain) and the within-subjects factor *predictiveness*, found no significant effect of the main effects (*group*: `r apa(ANOVA_acc_UNM07_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test[1])`; *predictiveness*: `r apa(ANOVA_acc_UNM07_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test[2])`), but a significant *group x predictiveness* interaction, `r apa(ANOVA_acc_UNM07_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test_gxp[1])`. Simple main effects analysis showed a significant effect of predictiveness in group Certain, *F* (`r sme_acc_UNM07_test_pred[1, 3]`, `r sme_acc_UNM07_test_pred[1, 4]`) = `r sme_acc_UNM07_test_pred[1, 5]`, *p* = `r sme_acc_UNM07_test_pred[1, 9]`, *η~p~^2^* = `r sme_acc_UNM07_test_pred[1, 8]`, `r report_BF_and_error(bay_SME_acc_UNM07_test_certain[1])`,  but not in group Uncertain, *F* (`r sme_acc_UNM07_test_pred[2, 3]`, `r sme_acc_UNM07_test_pred[2, 4]`) = `r sme_acc_UNM07_test_pred[2, 5]`, *p* = `r sme_acc_UNM07_test_pred[2, 9]`, *η~p~^2^* = `r sme_acc_UNM07_test_pred[2, 8]`, `r report_BF_and_error(bay_SME_acc_UNM07_test_uncertain[1])`. These analyses suggest that group Certain were more accurate at remembering predictive than non-predictive cues, whereas group Uncertain did not show this difference.

```{r, include = FALSE}
#Calculate the mean memory score and standard error for each group and predictiveness of the cues
UNM07_MS_test <- UNM07_test %>%
  group_by(predictiveness, condition) %>%
    summarise(mean_mem_score = mean(c_mem_score, na.rm = TRUE), 
            se_mem_score = sd(c_mem_score, na.rm = TRUE)/sqrt(length(c_mem_score)))
```

Memory scores, calculated as the product of the accuracy score (1 or 0) with the confidence rating given, can be seen in @fig-testExp1. The memory scores for non-predictive cues was lower than for the predictive cues in the Certain group. This difference was notably attenuated in the Uncertain group, and there was no indication of higher memory scores in the uncertain group relative to the Certain group.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-testExp1
#| fig-cap: Memory scores during the Test of Experiment 1.
#| apa-note: "Mean memory scores (±SEM) during the Test phase of Experiment 1 for predictive and non-predictive trials in the Certain and Uncertain groups."
#| fig-height: 4
ggplot(UNM07_MS_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain')), y = mean_mem_score, fill = predictiveness)) + #display groups in axis x, memory score in axis y, and fill the bars in different colours depending on predictiveness
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(ymin = mean_mem_score - se_mem_score, ymax = mean_mem_score + se_mem_score), width=.2, position=position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_fill_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  scale_y_continuous(name = "Memory score")+
  #scale_fill_grey(start = 0.33) +
  theme_apa()
```

```{r, include=FALSE}
#ANOVA mem_score
UNM07_memscore_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
UNM07_memscore_test$predictiveness <- factor(UNM07_memscore_test$predictiveness)
UNM07_memscore_test$condition <- factor(UNM07_memscore_test$condition)
UNM07_memscore_test$pNum <- factor(UNM07_memscore_test$pNum)
ANOVA_UNM07_test <- aov_car(formula = mem_score ~ condition + Error(pNum*predictiveness), data = UNM07_memscore_test)
print(ANOVA_UNM07_test)

bay_ANOVA_UNM07_test <- anovaBF(formula = mem_score ~ condition*predictiveness + pNum,
        data = data.frame(UNM07_memscore_test),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM07_test)
bay_ANOVA_UNM07_test_gxp <- bay_ANOVA_UNM07_test[4]/bay_ANOVA_UNM07_test[3]
print(bay_ANOVA_UNM07_test_gxp)
```

```{r, include = FALSE}
# SME of the condition:predictiveness interaction
SME_mem_UNM07_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem = mean(c_mem_score, na.rm = TRUE))
#calculate the simple main effect of condition
sme_mem_UNM07_test_condition <- SME_mem_UNM07_test %>%
  group_by(predictiveness) %>%
  anova_test(mem ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_mem_UNM07_test_condition #Call the output table
#calculate the simple main effect of predictiveness
sme_mem_UNM07_test_pred <- SME_mem_UNM07_test %>%
  group_by(condition) %>%
  anova_test(mem ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_mem_UNM07_test_pred #Call the output table
```

The mixed model ANOVA mirrored the findings from the accuracy analysis: there was no main effects of *group*: `r apa(ANOVA_UNM07_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM07_test[1])`, nor of *predictiveness*,`r apa(ANOVA_UNM07_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM07_test[2])`, but there was a  significant *group x predictiveness* interaction, `r apa(ANOVA_UNM07_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM07_test_gxp[1])`. Simple main effects showed a significant effect of *predictiveness* in group Certain, *F*(`r sme_mem_UNM07_test_pred[1,3]`, `r sme_mem_UNM07_test_pred[1,4]`) = `r sme_mem_UNM07_test_pred[1,5]`, *p* = `r sme_mem_UNM07_test_pred[1,9]`, *η~p~^2^* = `r sme_mem_UNM07_test_pred[1,8]`, but not in group Uncertain, *F*(`r sme_mem_UNM07_test_pred[2,3]`, `r sme_mem_UNM07_test_pred[2,4]`) = `r sme_mem_UNM07_test_pred[2,5]`, *p* = `r sme_mem_UNM07_test_pred[2,9]`, *η~p~^2^* = `r sme_mem_UNM07_test_pred[2,8]`. Again, memory score analysis suggests there was better memory for predictive cues than for non-predictive cues in group Certain, whereas this difference was not present in group Uncertain. The lack of a main effect of the group suggest that overall memory was similar in both groups.

## Discussion

Experiment 1 aimed to examine the effect of uncertainty on recognition memory for predictive and non-predictive cues. The participants in group Uncertain were exposed to a probabilistic relationship between the predictive cues and their respective outcomes, while those in group Certain received deterministic relationships. There was an effect of cue-predictiveness in group Certain with better recognition memory for the predictive than the non-predictive cues, but this effect was not present in the uncertain group, with evidence to suggest memory for predictive and non-predictive cues was equivalent. This is consistent with previous studies [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019] that have shown that attention (in those cases measured by eye-gaze dwell times) decreased for non-predictive cues but not for predictive cues, only under certain training. That decrease in attention could be responsible for the worse memory performance for the non-predictive cues, compared with the predictive cues, in the certain group. However, we hypothesised that the previously observed effect of uncertainty on increased overt attention (e.g., Beesley et al., 2015) would lead to better memory for cues in that condition. This was not the case: in a final recognition memory test, the two groups showed a similar overall level of recognition memory for the cues.

A central distinction made in Easdale et al. [-@easdaleOnsetUncertaintyFacilitates2019] was that between *expected-* and *unexpected-uncertainty*. In those experiments, participants who experienced a sustained period of training with uncertain compounds (as is the case in group “Uncertain” in Experiment 1) learnt more slowly about new contingencies, compared to a group that received a sudden and unexpected change in the contingencies. Thus, it may be the case that the current uncertain condition does not promote higher recognition memory overall, because participants have come to expect a certain level of uncertainty and are no longer engaging in an exploratory mode of cue-processing. Of course, the expected levels of high attention to cues under uncertain conditions presents a paradox for learning and attention research: why does a high level of attention not translate to better learning and memory for those cues? We return to this point in the general discussion. Nevertheless, this analysis of the findings in terms of expected and unexpected uncertainty suggests that a more acute period of uncertainty may (re)engage a mode of exploratory attentional processing for the cues, which would result in better memory of those cues. Experiment 2 tested this hypothesis.

# Experiment 2

Experiment 2 aimed to examine whether the introduction of uncertainty, following a period of certain training (i.e., unexpected uncertainty), would lead to an increase in cue-processing (better recognition memory). The design of Experiment 2 can be seen in @tbl-exp2. The experiment consisted of three groups. Groups Certain Long and Certain Short received training that was similar to the Certain condition from Experiment 1, experiencing certain contingencies between the cue compounds and the outcomes throughout the training phase, differing only in the amount of training they experienced. Group Uncertain first experienced the same certain contingencies experienced by the certain groups, before the contingencies were changed to uncertain for a short period before the recognition memory test. Our prediction was that, if the introduction of unexpected uncertainty promotes greater levels of exploratory attention, then we should see better recognition memory performance in this uncertain condition, compared to the certain condition.

::: {#tbl-exp2 apa-note="Uppercase letters A, B, X, and Y represent the cues presented during training. O1 and O2 represent the outcomes presented in training. Lowercase letters a, b, x, and y represent the foils that are similar to the (corresponding upper-case letter) cues presented in the training phase. The numbers before the trials define the proportion of trials of that type that were presented." apa-twocolumn="true"}
+---------------+--------------+---------------------------+------------------+
| Group         | Stage 1      | Stage 2                   | Test             |
+===============+==============+:=========================:+:================:+
| Certain Long  | AX - O1      | AX - O1                   | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      | AY - O1                   | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      | BX - O2                   | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      | BY - O2                   | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+
| Certain Short | AX - O1      |                           | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      |                           | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      |                           | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      |                           | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+
| Uncertain     | AX - O1      | 0.8 AX - O1 / 0.2 AX - O2 | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      | 0.8 AY - O1 / 0.2 AY - O2 | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      | 0.8 BX - O2 / 0.2 BX - O1 | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      | 0.8 BY - O2 / 0.2 BY - O1 | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+

Design of Experiment 2
:::

Group Certain Short received the same certain contingencies as the other two conditions in Stage 1 but did not experience Stage 2; they received a shorter training phase than the other two conditions. If the onset of the uncertainty leads to greater cue-processing, then we should also see better cue-memory in the Uncertain condition compared to the Certain Short condition. The inclusion of this condition is important because longer training with the certain contingencies in the “Certain Long” condition could *decrease* cue processing, which would be an alternative explanation of any difference in cue processing we observe between Group Uncertain and Group Certain Long. If this is the case, we should see equivalent recognition memory in the Certain Short and Uncertain conditions, and poorer recognition memory in the Certain Long condition. Therefore, the addition of this third condition allowed us to make stronger inferences about the causal relationship between the onset of uncertainty and cue-processing.

## Methods

### Participants

```{r, include=FALSE}
#load the data
load("UNM08_proc_data.RData")
UNM08_demographics <- demographics
UNM08_training <- rbind(stage1, stage2)
UNM08_test <- test
UNM08_not_passed <- not_passed_pNum
UNM08_training <- filter(UNM08_training, !pNum %in% UNM08_not_passed$pNum)
UNM08_test <- filter(UNM08_test, !pNum %in% UNM08_not_passed$pNum)
```

```{r, include = FALSE}
#create the PPR measure
UNM08_training <- UNM08_training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1))

#detect and clean participants that had an PPR lower than 0.6 in the final block or not passed the test comprehension check
UNM08_block6 <- filter(UNM08_training, block == 6) %>%
  group_by(pNum, condition) %>%
 summarise (mean_response = mean(prob_response, na.rm = TRUE))
UNM08_low_acc_total <- filter(UNM08_block6, mean_response < 0.75) 
UNM08_low_acc <- UNM08_low_acc_total$pNum
UNM08_training <- filter(UNM08_training, !pNum %in% UNM08_low_acc_total$pNum)
UNM08_test <- filter(UNM08_test, !pNum %in% UNM08_low_acc_total$pNum)
```

`r nrow(UNM08_demographics)` participants were recruited through Prolific. The mean age of the `r nrow(UNM08_demographics) - sum(is.na(UNM08_demographics$age))` participants that reported their age was `r format(mean(UNM08_demographics$age, na.rm = TRUE), digits = 3)` (range `r min(UNM08_demographics$age, na.rm = TRUE)` - `r max(UNM08_demographics$age, na.rm = TRUE)`), with `r length(which(UNM08_demographics$gender == "female"))` women, `r length(which(UNM08_demographics$gender == "male"))` men, and one non-binary person, and `r n_distinct(UNM08_demographics$Nationality)` different nationalities. Participants were randomly allocated to each condition. Eight participants were excluded on the basis of failing the comprehension check before the test, six in group Uncertain, one in group Certain Short, and one in group Certain Long. Since all three conditions experienced the same training in Stage 1, we imposed a performance criterion of 75% PPR (i.e., accuracy) in the last block of Stage 1, on the basis that the effect of "unexpected uncertainty"  would be minimal if the contingencies had not been learned to a reasonable level at the point of this manipulation. `r nrow(UNM08_low_acc_total)` participants were excluded due to a low PPR (\< 0.75) on the last block of Stage 1, `r length(which(UNM08_low_acc_total$condition == "Certain Long"))` in group Certain Long, `r length(which(UNM08_low_acc_total$condition == "Certain Short"))` in group Certain Short and `r length(which(UNM08_low_acc_total$condition == "Uncertain"))` in group Uncertain. Thus, the results below are for the remaining `r nrow(UNM08_test)/24` participants. Post-hoc calculations using G\*Power 3.1 [@faulStatisticalPowerAnalyses2007] revealed that this sample size had a power of .79 to detect an effect size of *η~p~^2^* = .05 that was observed for the group main effect reported in @fig-testExp2.

### Apparatus and stimuli

The materials were the same as in Experiment 1.

### Design

The experiment used a mixed design (as seen in @tbl-exp2), with three groups: Certain Long, Certain Short, and Uncertain. All groups received six blocks of certain training. Group Certain Long then received a further 4 blocks of certain training; group Uncertain, received a further four blocks of uncertain training (with contingencies of 0.8); and group Certain Short received no further training (they completed six training blocks only). When training was completed, all groups progressed to the memory test, which was identical to the one Experiment 1.

### Procedure

All the details about the procedure were identical to Experiment 1.

## Results

```{r, include = FALSE}
#Calculate the mean PPR and standard error for each block, including the groups and stages
UNM08_MA_training <- UNM08_training %>%
  group_by(block, stage, condition) %>%
  summarise(mean_accuracy = mean(prob_response, na.rm = TRUE), 
            se_accuracy = sd(prob_response, na.rm = TRUE)/sqrt(length(prob_response)))

#add a dummy to display stage 2 for Certain Short
MA_stage2_dummy <- data.frame(stage = c('stage 2', 'stage 2', 'stage 2', 'stage 2'),
                              block = c(7:10),
                              condition = c('Certain Short', 'Certain Short', 'Certain Short', 'Certain Short'),
                              mean_accuracy = c(0.001, 0.002, 0.003, 0.004),
                              se_accuracy = c(0.0001, 0.00020, 0.0003, 0.00004))
UNM08_MA_training <- rbind(UNM08_MA_training, MA_stage2_dummy)
#change stage 1 and stage 2 to Stage1 and Stage 2, and Certain_short to Certain Short
UNM08_MA_training <- UNM08_MA_training %>%
  mutate(stage = case_when(stage == "stage 1" ~ "Stage 1",
                           stage == "stage 2" ~ "Stage 2"))
```

@fig-trainingExp2 shows the mean PPR for each group across the ten blocks of training. All participants showed a similar increase in PPR in stage 1, reaching a PPR of around 0.93 on block 6. In Stage 2, group Certain showed a similar PPR to block 6, but the Uncertain group showed a decrease in PPR to a level of around 0.85.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-trainingExp2
#| fig-cap: PPR on the training phase of Experiment 2.
#| apa-note: "Mean proportion of probable responses (±SEM) during the training phase of Experiment 2, plotted against the ten blocks of trials, for each Group."
#| fig-height: 4
ggplot(UNM08_MA_training, mapping = aes(x = block, y = mean_accuracy, group = condition)) +
  geom_point(mapping = aes(shape = condition, color = condition), size = 2.5) +
  geom_line(mapping = aes(color = condition)) +
  geom_errorbar(aes(x= block, y = mean_accuracy, ymin = mean_accuracy-se_accuracy, ymax = mean_accuracy+se_accuracy), colour = "black", width=.1)+
  facet_grid(cols = vars(stage), space = "free_x", scales = "free_x") + 
  scale_x_continuous(name = "Block", breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) + 
  scale_color_discrete(type = c("#AF8DC3", "#FEB24C", "#7FBF7B"))+
  labs(shape = "Group", color = "Group") +
  scale_y_continuous(name = "PPR", limits = c(0.5, 1))+
  theme_apa()
```

```{r, include=FALSE}
#ANOVA
UNM08_stage1 <- filter(UNM08_training, stage == "stage 1") %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
UNM08_stage1$block <- factor(UNM08_stage1$block)
UNM08_stage1$pNum <- factor(UNM08_stage1$pNum)
UNM08_stage1$condition <- factor(UNM08_stage1$condition)
ANOVA_UNM08_stage1 <- aov_car(formula = mean_response ~ condition + Error(pNum/block), data = UNM08_stage1)
print(ANOVA_UNM08_stage1)
#Bayesian Anova
bay_ANOVA_UNM08_stage1 <- anovaBF(formula = mean_response ~ condition + block + pNum,
        data = data.frame(UNM08_stage1),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM08_stage1)
bay_ANOVA_UNM08_stage1_int <- bay_ANOVA_UNM08_stage1[4]/bay_ANOVA_UNM08_stage1[3]
print(bay_ANOVA_UNM08_stage1_int)
```

The Stage 1 data were analysed with a mixed-model ANOVA, with the between-subjects factor of *group* (Certain Long, Certain Short, and Uncertain), and the within-subjects factor of *block* (1-6). This revealed a significant effect of *block*, `r apa(ANOVA_UNM08_stage1, effect = "block")`, `r report_BF_and_error(bay_ANOVA_UNM08_stage1[1], sci_not = TRUE)`. There was no effect of *group*, `r apa(ANOVA_UNM08_stage1, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM08_stage1[2])`, and no interaction effect, `r apa(ANOVA_UNM08_stage1, effect = "condition:block")`, `r report_BF_and_error(bay_ANOVA_UNM08_stage1_int[1])`.

```{r, include=FALSE}
#ANOVA
UNM08_acc <- filter(UNM08_training, condition == "Certain Long" | condition == "Uncertain") %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
UNM08_acc$block <- factor(UNM08_acc$block)
UNM08_acc$pNum <- factor(UNM08_acc$pNum)
UNM08_acc$condition <- factor(UNM08_acc$condition)
ANOVA_UNM08_acc <- aov_car(formula = mean_response ~ condition + Error(pNum/block), data = UNM08_acc)
print(ANOVA_UNM08_acc)
#Bayesian Anova
bay_ANOVA_UNM08_acc <- anovaBF(formula = mean_response ~ condition + block + pNum,
        data = data.frame(UNM08_acc),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM08_acc) 
bay_ANOVA_UNM08_acc_int <- bay_ANOVA_UNM08_acc[4]/bay_ANOVA_UNM08_acc[3]
print(bay_ANOVA_UNM08_acc_int)
```

```{r, include = FALSE}
# SME of the condition:block interaction
SME_acc_UNM08_training <- filter(UNM08_training, condition == "Certain Long" | condition == "Uncertain") %>%
  group_by(pNum, condition, block) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
#calculate the simple main effect of condition
sme_acc_UNM08_training_condition <- SME_acc_UNM08_training %>%
  group_by(block) %>%
  anova_test(mean_response ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_acc_UNM08_training_condition #Call the output table
#calculate the simple main effect of block
sme_acc_UNM08_training_pred <- SME_acc_UNM08_training %>%
  group_by(condition) %>%
  anova_test(mean_response ~ block + Error(pNum/block), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_acc_UNM08_training_pred #Call the output table

SME_acc_UNM08_training_block7 <- filter(UNM08_training, block == 7) %>%
  group_by(pNum, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
SME_acc_UNM08_training_block7$condition <- factor(SME_acc_UNM08_training_block7$condition)
SME_acc_UNM08_training_block7$pNum <- factor(SME_acc_UNM08_training_block7$pNum)

SME_acc_UNM08_training_block4 <- filter(UNM08_training, block == 4) %>%
  group_by(pNum, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
SME_acc_UNM08_training_block4$condition <- factor(SME_acc_UNM08_training_block4$condition)
SME_acc_UNM08_training_block4$pNum <- factor(SME_acc_UNM08_training_block4$pNum)

bay_sme_acc_UNM08_training_block7 <- anovaBF(formula = mean_response ~ condition,
        data = data.frame(SME_acc_UNM08_training_block7),
        iterations = bfit)
print(bay_sme_acc_UNM08_training_block7)
bay_sme_acc_UNM08_training_block4 <- anovaBF(formula = mean_response ~ condition,
        data = data.frame(SME_acc_UNM08_training_block4),
        iterations = bfit)
print(bay_sme_acc_UNM08_training_block4)
```

The data from Stage 1 and 2 were analysed with a mixed model ANOVA (using the Greenhouse-Geisser correction when needed), with the between-subjects factor of *group* (Certain Long vs Uncertain) and the within-subjects factor of *block* (1-10). There was no effect of *group*, `r apa(ANOVA_UNM08_acc, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc[2])`, but there was a significant effect of *block*, `r apa(ANOVA_UNM07_acc, effect = "block")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc[1], sci_not = TRUE)`, and a significant *group x block* interaction, `r apa(ANOVA_UNM08_acc, effect = "condition:block")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc_int[1])`. Simple main effects showed a significant effect of condition on blocks 7 to 10, *F*(`r sme_acc_UNM08_training_condition[7, 3]`, `r sme_acc_UNM08_training_condition[7, 4]`) > `r sme_acc_UNM08_training_condition[7, 5]`, *p* < `r sme_acc_UNM08_training_condition[7, 9]`, `r report_BF_and_error(bay_sme_acc_UNM08_training_block7[1])`, but not in block 1 to 6, *F*(`r sme_acc_UNM08_training_condition[4, 3]`, `r sme_acc_UNM08_training_condition[4, 4]`), < `r sme_acc_UNM08_training_condition[4, 5]`, *p* > `r sme_acc_UNM08_training_condition[4, 9]`, `r report_BF_and_error(bay_sme_acc_UNM08_training_block4[1])`.  


Taken together, these results indicate that the training in Stage 1 increased the PPR for all groups in the same fashion, while in Stage 2, the Certain Long group showed a consistently higher PPR than the Uncertain group.

```{r, include=FALSE}
#Calculate the mean accuracy and standard error for each block, including the groups
MA_UNM08_test <- UNM08_test %>%
  group_by(predictiveness, condition) %>%
    summarise(mean_acc = mean(acc, na.rm = TRUE), 
            se_acc = sd(acc, na.rm = TRUE)/sqrt(length(acc)))
```

@fig-acctestExp2 shows the accuracy results from the recognition memory test. Overall, accuracy was higher in group Uncertain compated with the two Certain groups. Accuracy for non-predictive cues was lower than for the predictive cues in both Certain Long and Certain Short groups, but this difference was attenuated in the Uncertain group.

```{r, echo=FALSE, message=FALSE}
#| label: fig-acctestExp2
#| fig-cap: Accuracy on the test phase of Experiment 2.
#| apa-note: "Mean accuracy (±SEM) during the test phase of Experiment 2, across the three groups."
#| fig-height: 4
ggplot(data = MA_UNM08_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain Short','Certain Long')), y = mean_acc, fill = predictiveness)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(y= mean_acc, ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width = .2, position = position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_y_continuous(name = "Accuracy") +
  coord_cartesian(ylim = c(0.5, 1)) +
  scale_fill_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  theme_apa()
```

```{r, include=FALSE}
#ANOVA accuracy
acc_UNM08_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
acc_UNM08_test$predictiveness <- factor(acc_UNM08_test$predictiveness)
acc_UNM08_test$condition <- factor(acc_UNM08_test$condition)
acc_UNM08_test$pNum <- factor(acc_UNM08_test$pNum)
ANOVA_acc_UNM08_test <- aov_car(formula = acc ~ condition + Error(pNum*predictiveness), data = acc_UNM08_test)
print(ANOVA_acc_UNM08_test)

bay_ANOVA_acc_UNM08_test <- anovaBF(formula = acc ~ condition*predictiveness + pNum,
        data = data.frame(acc_UNM08_test),
        whichRandom = "pNum", 
        iterations = bfit)
print(bay_ANOVA_acc_UNM08_test)

bay_ANOVA_acc_UNM08_test_gxp <- bay_ANOVA_acc_UNM08_test[4]/bay_ANOVA_acc_UNM08_test[3]
print(bay_ANOVA_acc_UNM08_test_gxp)
```

```{r, include = FALSE}
# Pairwise comparisons for the main effect of condition
acc_UNM08_test_interaction <- emmeans(ANOVA_acc_UNM08_test, ~condition)
contrast(acc_UNM08_test_interaction, adjust = "bon", "trt.vs.ctrl", ref = c(1,2))

acc_UNM08_test_certs <- subset(acc_UNM08_test, (condition == "Certain Long") | (condition == "Certain Short"), acc, drop = TRUE)
acc_UNM08_test_uncert <- subset(acc_UNM08_test, condition == "Uncertain", acc, drop = TRUE)
bay_t.test_acc_UNM08_int_uncer_vs_certs <-  ttestBF(acc_UNM08_test_certs, acc_UNM08_test_uncert)
print(bay_t.test_acc_UNM08_int_uncer_vs_certs)

pairs(acc_UNM08_test_interaction, adjust = "bon")

acc_UNM08_test_cert_l <- subset(acc_UNM08_test, condition == "Certain Long", acc, drop = TRUE)
acc_UNM08_test_cert_s <- subset(acc_UNM08_test, condition == "Certain Short", acc, drop = TRUE)
bay_t.test_acc_UNM08_test_certs <-  ttestBF(acc_UNM08_test_cert_l, acc_UNM08_test_cert_s)
print(bay_t.test_acc_UNM08_test_certs)
```

There was a significant main effect of the *group*, `r apa(ANOVA_acc_UNM08_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test[1])`, and a main effect of *predictiveness*: `r apa(ANOVA_acc_UNM08_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test[2])`. The *group x predictiveness* interaction was not significant, `r apa(ANOVA_acc_UNM08_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test_gxp[1])`. These results indicate that all groups were more accurate at recognising predictive cues than non-predictive cues and that overall accuracy was higher in group Uncertain compared to the other two groups. This interpretation of the main effect of group was confirmed by  Bonferroni corrected pairwise comparisons, which revealed a significant difference between the overall accuracy (average of P and NP cues) in group Uncertain compared to the overall accuracy in groups Certain Long and Certain Short, *t*(133) = 3.449, *p* < .001, `r report_BF_and_error(bay_t.test_acc_UNM08_int_uncer_vs_certs[1])`. There was no difference in accuracy between group Certain Long and group Certain Short, *t*(133) = 0.01, *p* = 1, `r report_BF_and_error(bay_t.test_acc_UNM08_test_certs[1])`.

```{r, include = FALSE}
#create the memory_score
UNM08_test <- UNM08_test %>%
  mutate (c_mem_score = case_when(acc == 0 ~ 0, acc == 1 ~ mem_score))
#Calculate the mean PPR and standard error for each block, including the groups
UNM08_MS_test <- UNM08_test %>%
  group_by(predictiveness, condition) %>%
    summarise(mean_mem_score = mean(c_mem_score, na.rm = TRUE), 
            se_mem_score = sd(c_mem_score, na.rm = TRUE)/sqrt(length(c_mem_score)))
```

@fig-testExp2 shows the recognition memory scores for the three conditions. Memory for non-predictive cues was lower than for predictive cues in all groups, but this difference was notably attenuated in the Uncertain group. Mirroring the accuracy data, the memory scores for the cues in group Uncertain were on average higher, than those for groups Certain Long and Certain Short.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-testExp2
#| fig-cap: Memory scores on the Test of Experiment 2.
#| apa-note: "Mean memory scores (±SEM) during the Test of Experiment 2 for predictive and non-predictive trials across the three groups."
#| fig-height: 4
ggplot(UNM08_MS_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain Short', 'Certain Long')), y = mean_mem_score, fill = predictiveness)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(ymin = mean_mem_score - se_mem_score, ymax = mean_mem_score + se_mem_score), width=.2, position=position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_fill_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  scale_y_continuous(name = "Memory score")+
  #scale_fill_grey(start = 0.33) +
  theme_apa()
```

```{r, include=FALSE}
#ANOVA mem_score
UNM08_memscore_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
UNM08_memscore_test$predictiveness <- factor(UNM08_memscore_test$predictiveness)
UNM08_memscore_test$condition <- factor(UNM08_memscore_test$condition)
UNM08_memscore_test$pNum <- factor(UNM08_memscore_test$pNum)
ANOVA_UNM08_test <- aov_car(formula = mem_score ~ condition + Error(pNum*predictiveness), data = UNM08_memscore_test)
print(ANOVA_UNM08_test)
bay_ANOVA_UNM08_test <- anovaBF(formula = mem_score ~ condition + predictiveness ,
        data = data.frame(UNM08_memscore_test),
        whichRandom = "pNum", 
        iterations = bfit)
print(bay_ANOVA_UNM08_test)
bay_ANOVA_UNM08_test_gxp <- bay_ANOVA_UNM08_test[4]/bay_ANOVA_UNM08_test[3]
print(bay_ANOVA_UNM08_test_gxp)
```

```{r, include = FALSE}
# Pairwise comparisons for the main effect of condition
UNM08_test_interaction <- emmeans(ANOVA_UNM08_test, ~condition)
contrast(UNM08_test_interaction, adjust = "bon", "trt.vs.ctrl", ref = c(1,2))

UNM08_test_certs <- subset(UNM08_memscore_test, (condition == "Certain Long") | (condition == "Certain Short"), mem_score, drop = TRUE)
UNM08_test_uncert <- subset(UNM08_memscore_test, condition == "Uncertain", mem_score, drop = TRUE)
bay_t.test_UNM08_int_uncer_vs_certs <-  ttestBF(UNM08_test_certs, UNM08_test_uncert)
print(bay_t.test_UNM08_int_uncer_vs_certs)

pairs(UNM08_test_interaction, adjust = "bon")

UNM08_test_cert <- subset(UNM08_memscore_test, condition == "Certain Long", mem_score, drop = TRUE)
UNM08_test_cert_s <- subset(UNM08_memscore_test, condition == "Certain Short", mem_score, drop = TRUE)
bay_t.test_UNM08_test_certs <-  ttestBF(UNM08_test_cert, UNM08_test_cert_s)
print(bay_t.test_UNM08_test_certs)
```

```{r, include = FALSE}
# SME of the condition:predictiveness interaction
SME_UNM08_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
#calculate the simple main effect of predictiveness
sme_UNM08_test_pred <- SME_UNM08_test %>%
  group_by(condition) %>%
  anova_test(mem_score ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_UNM08_test_pred #Call the output table

SME_UNM08_test_CL <- filter(UNM08_test, condition == "Certain Long") %>%
  group_by(pNum, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
SME_UNM08_test_CL$predictiveness <- factor(SME_UNM08_test_CL$predictiveness)
SME_UNM08_test_CL$pNum <- factor(SME_UNM08_test_CL$pNum)

bay_SME_UNM08_test_CL <- anovaBF(formula = mem_score ~ predictiveness + pNum,
        data = data.frame(SME_UNM08_test_CL),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_UNM08_test_CL)

SME_UNM08_test_CS <- filter(UNM08_test, condition == "Certain Short") %>%
  group_by(pNum, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
SME_UNM08_test_CS$predictiveness <- factor(SME_UNM08_test_CS$predictiveness)
SME_UNM08_test_CS$pNum <- factor(SME_UNM08_test_CS$pNum)

bay_SME_UNM08_test_CS <- anovaBF(formula = mem_score ~ predictiveness + pNum,
        data = data.frame(SME_UNM08_test_CS),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_UNM08_test_CS)

SME_UNM08_test_U <- filter(UNM08_test, condition == "Uncertain") %>%
  group_by(pNum, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
SME_UNM08_test_U$predictiveness <- factor(SME_UNM08_test_U$predictiveness)
SME_UNM08_test_U$pNum <- factor(SME_UNM08_test_U$pNum)

bay_SME_UNM08_test_U <- anovaBF(formula = mem_score ~ predictiveness + pNum,
        data = data.frame(SME_UNM08_test_U),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_UNM08_test_U)
```
```{r, include = FALSE}
# SME of the condition:predictiveness interaction
SME_UNM08_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
#calculate the simple main effect of condition
sme_UNM08_test_condition <- SME_UNM08_test %>%
  group_by(predictiveness) %>%
  anova_test(mem_score ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_UNM08_test_condition #Call the output table

SME_UNM08_test_NP <- filter(UNM08_test, predictiveness == "non-predictive") %>%
  group_by(pNum, condition) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
SME_UNM08_test_NP$condition <- factor(SME_UNM08_test_NP$condition)
SME_UNM08_test_NP$pNum <- factor(SME_UNM08_test_NP$pNum)

bay_SME_UNM08_test_NP <- anovaBF(formula = mem_score ~ condition,
        data = data.frame(SME_UNM08_test_NP),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_UNM08_test_NP)

SME_UNM08_test_P <- filter(UNM08_test, predictiveness == "predictive") %>%
  group_by(pNum, condition) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
SME_UNM08_test_P$condition <- factor(SME_UNM08_test_P$condition)
SME_UNM08_test_P$pNum <- factor(SME_UNM08_test_P$pNum)

bay_SME_UNM08_test_P <- anovaBF(formula = mem_score ~ condition,
        data = data.frame(SME_UNM08_test_P),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_UNM08_test_P)
```

A mixed model ANOVA, including the between-subjects factor *group* (Certain Long, Certain Short, Uncertain), and the within-subjects factor *predictiveness* (predictive vs non-predictive) showed a significant main effect of *group*, `r apa(ANOVA_UNM08_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM08_test_gxp[1])`, and *predictiveness*, `r apa(ANOVA_UNM08_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM08_test[2])`, and a significant *group x predictiveness* interaction, `r apa(ANOVA_UNM08_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM08_test_gxp[1])`. However, is worth noting that the Bayesian analysis indicated moderate evidence in favour of the null hypothesis for this interaction. Bonferroni corrected pairwise comparisons on the main effect of *group* showed that group Uncertain differed significantly from the average of the Certain groups, *t*(133) = 2.624, *p* = .01, `r report_BF_and_error(bay_t.test_UNM08_int_uncer_vs_certs[1])`, but memory scores for the two Certain groups did not differ from each other, *t*(133) = 0.732, *p* = 1, `r report_BF_and_error(bay_t.test_UNM08_test_certs[1])`, with the Bayesian evidence suggesting that memory performance was the same in these two groups. Furthermore, simple main effects showed a significant effect of *predictiveness* for group Certain Long, *F* (`r sme_UNM08_test_pred[1, 3]`, `r sme_UNM08_test_pred[1, 4]`) = `r sme_UNM08_test_pred[1, 5]`, *p* = `r sme_UNM08_test_pred[1, 9]`, *η~p~^2^* = `r sme_UNM08_test_pred[1, 8]`, `r report_BF_and_error(bay_SME_UNM08_test_CL[1])`, and for group Certain Short, *F* (`r sme_UNM08_test_pred[2, 3]`, `r sme_UNM08_test_pred[2, 4]`) = `r sme_UNM08_test_pred[2, 5]`, *p* = `r sme_UNM08_test_pred[2, 9]`, *η~p~^2^* = `r sme_UNM08_test_pred[2, 8]`, `r report_BF_and_error(bay_SME_UNM08_test_CS[1])`, but not for group Uncertain, *F* (`r sme_UNM08_test_pred[3, 3]`, `r sme_UNM08_test_pred[3, 4]`) = `r sme_UNM08_test_pred[3, 5]`, *p* = `r sme_UNM08_test_pred[3, 9]`, *η~p~^2^* = `r sme_UNM08_test_pred[3, 8]`, `r report_BF_and_error(bay_SME_UNM08_test_U[1])`. It is also important to note that when the simple main effect of *group* was analysed, it only had a significant effect on the non-predictive cues, *F* (`r sme_UNM08_test_condition[1, 3]`, `r sme_UNM08_test_condition[1, 4]`) = `r sme_UNM08_test_condition[1, 5]`, *p* = `r sme_UNM08_test_condition[1, 9]`, *η~p~^2^* = `r sme_UNM08_test_condition[1, 8]`, `r report_BF_and_error(bay_SME_UNM08_test_NP[1])`, but not on predictive cues, *F* (`r sme_UNM08_test_condition[2, 3]`, `r sme_UNM08_test_condition[2, 4]`) = `r sme_UNM08_test_condition[2, 5]`, *p* = `r sme_UNM08_test_condition[2, 9]`, *η~p~^2^* = `r sme_UNM08_test_condition[2, 8]`, `r report_BF_and_error(bay_SME_UNM08_test_P[1])`.

## Discussion

Experiment 2 examined the effect of unexpected uncertainty on recognition memory. The “Uncertain” group of participants first experienced a period of training with certain contingencies, before receiving a second period with uncertain contingencies. Participants that were exposed to this unexpected uncertainty showed a higher level of recognition memory for the cues than participants that received only certain training. Furthermore, group uncertain does not show an effect of predictiveness, and the better overall memory seems to be related to a better memory for the non-predictive cues. An important difference between Experiment 1 and 2 is that in Experiment 1, the Certain and Uncertain groups had a similar recognition memory for the cues, whereas in the current experiment, the Uncertain group showed better cue-recognition. We interpret this difference to be a consequence of the expectancy of uncertainty: in Experiment 2, but not Experiment 1, uncertainty is suddenly introduced after a sustained period of certain training.

These results suggest that introducing a period of unexpected uncertainty results in enhanced cue processing, consistent with previous results [@easdaleOnsetUncertaintyFacilitates2019] that showed that unexpected uncertainty enhances learning. Easdale et al. used a training phase in which participants learnt about either certain or uncertain contingencies. Participants showed better attention to cues under uncertain conditions. However, when those cues were subsequently trained under new contingencies, it was participants in the certain condition that learnt about these more rapidly, compared to those participants in the uncertain condition. Easdale et al. suggested that the transition from certain to uncertain contingencies brought about a state of “unexpected uncertainty” which promoted new learning. Experiment 2 shows more directly that a period of unexpected uncertainty leads to superior cue processing and stronger memory representations.

# General discussion

Two experiments explored the processing of cues under different conditions of certainty and uncertainty during a contingency learning task. In Experiment 1, participant were trained in either a “certain” condition, in which there were cues that were perfectly predictive of the outcomes, or in an "uncertain" condition, in which there was a probabilistic relationship between the predictive cues and the outcomes. We predicted that uncertainty would increase the memory for cues, in line with the previously established increased levels of overt attention to cues trained under uncertain conditions [e.g., @beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019; @torrents-rodasEffectPredictionError2023; @walkerRoleUncertaintyAttentional2019; @walkerProtectionUncertaintyExploration2022]. However, this was not the case: overall, there was no effect of uncertainty on memory scores, with evidence to support a conclusion of equivalent levels of memory for cues (overall) in the certain and uncertain conditions. Memory scores for the predictive cues were higher than those for the non-predictive cues, but this result was restricted to group Certain: there was no observed difference between predictive and non-predictive cues in group Uncertain. This latter result is consistent with the higher attention paid to cues observed i the learned predictiveness design [e.g., @lepelleyLearnedAssociabilityAssociative2003].

Experiment 2 explored the differences in recognition memory for conditions of “expected” and “unexpected” uncertainty. Unexpected uncertainty is defined here as using a procedure in which participants were initially trained on certain contingencies and then given further training, for a shorter period, with uncertain contingencies. This condition was compared to the certain condition (as trained in Experiment 1). This period of unexpected uncertainty in the task had an important effect on cue-processing and memory performance: participants in this unexpected uncertainty condition showed better memory than those in the certain condition. We included an additional condition in Experiment 2 that received just the first phase of certain training, equivalent in length to that experienced in the unexpected uncertainty condition. This condition provided a strong test to determine if it was indeed the period of unexpected uncertainty that led to increases in cue-processing, rather than further training of the certain contingencies (in the standard certain condition) leading to a decrease in cue-processing. Memory was better in the case of the unexpected uncertainty condition compared to this short-certain condition, and therefore a short period of unexpected uncertainty appears to enhance the memory for, and thus processing of, the cues.

Attentional theories of associative learning have long recognised the role that uncertainty plays in determining the allocation of processing resources to stimuli in the environment. According to the Pearce and Hall [-@pearceModelPavlovianLearning1980] model, the effective salience of a stimulus is determined by the magnitude of the absolute prediction error that stimulus has received on the previous trial. That is, if a stimulus was followed by an unexpected outcome, then the associability of the stimulus on the next trial should be high; if an expected outcome was received, then the associability should be low. Pearce and Hall described this as an active attentional process that aids the animal in discovering information about stimuli for which it is unsure about the consequences. In the original model, the attention, and therefore the associability of a stimulus, is determined by the prediction error on the previous trial, while in the revised model of Pearce, Kaye, and Hall [-@pearcePredictiveAccuracyStimulus1982] this was determined by a longer history of reinforcement (the length of which was controlled by a parameter in the model). In either case, the model makes the prediction that uncertainty – periods in which there is prediction error in the reinforcement schedule – will result in high levels of attention to a stimulus. The results of Experiment 1 are therefore not compatible with the principles of the Pearce-Hall model [@pearceModelPavlovianLearning1980; @pearcePredictiveAccuracyStimulus1982], since the uncertain condition did not show evidence of greater levels of cue-processing than the certain condition, despite the substantial level of prediction error that was experienced in the former. Since we know from previous work that this same procedure results in higher levels of overt attention to cues [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019; @walkerProtectionUncertaintyExploration2022; @walkerRoleUncertaintyAttentional2019], the results of Experiment 1 provide insights into the complex relationships between overt attention, active stimulus processing, and associative learning. The data from Experiment 1 suggest that the circumstances that favour high levels of overt attention do not necessarily translate directly into active and enhanced processing of the stimuli. Thus, the data are consistent with the failures to observe more rapid learning about new associations under such conditions of uncertainty [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019; @torrents-rodasEffectPredictionError2023]. Taken alone, the data from Experiment 1 suggest that the hitherto assumption that eye-gaze dwell time can be used as a proxy measure of stimulus associability, is on shaky ground.

The data from Experiment 2, however, suggest that uncertainty can, under some circumstances, lead to enhancements in stimulus processing. In this procedure, after a period of training in which the task contingencies were deterministic, there was a sudden change to uncertain (probabilistic) contingencies. Under these conditions, evidence for enhanced stimulus processing was obtained, with better memory for the cue stimuli overall, compared to conditions in which participants were only trained with certain contingencies. In light of the findings of Experiment 1, these findings from Experiment 2 provide strong evidence for the distinction made by Easdale et al. [-@easdaleOnsetUncertaintyFacilitates2019] between expected and unexpected uncertainty. After periods of prolonged exposure to stable levels of uncertainty, participants appear to develop a tolerance for this uncertainty and their stimulus processing decreases. In contrast, a sudden onset of uncertain contingencies, following exposure to entirely certain contingencies, boosts stimulus processing. Together, these data suggest a non-linear relationship between contingency exposure and stimulus processing under uncertainty. It is likely that, at the outset of exposure to an uncertain contingency, stimulus processing will be high, and this level of processing will decline over the course of experience with the stable (but uncertain) contingency. In contrast, the sudden experience of a prediction error, following certain contingencies, increases the level of stimulus processing to a maximal level. Continual training with uncertain contingencies would be expected to see a decline in stimulus processing; it is likely that the configuration of our procedure in Experiment 3 was able to capture this high level of stimulus processing prior to an expected decline in the level of stimulus processing with continued uncertainty (i.e., a transition to a state of expected uncertainty).

In view of the analysis provided in the context of the Pearce and Hall model, it is clear that the conditions of expected uncertainty present a major challenge to attentional theories of associative learning. The data from the current studies and others using similar designs [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019; @walkerProtectionUncertaintyExploration2022; @walkerRoleUncertaintyAttentional2019] illustrates that the cognitive system is sensitive not just to the absolute level of prediction error, but how long that prediction error has been experienced for, and how stable that pattern of uncertainty has been. Indeed, the manner in which the uncertainty is experienced in the task, not just the overall level of uncertainty, can affect the pattern of choices and attention. One line of examination for future experimental and theoretical work would be to explore whether expected uncertainty reflects a localised cue-specific parameter or is better reflected as a global property of the learning system, akin to a reflection of “vigilance” on the task.


The results of Experiment 2 suggest that unexpected uncertainty returns participants to an exploratory mode of processing. To what extent was this directed more towards predictive or non-predictive cues? The analysis of the memory scores in Experiment 2 found an simple main effect of group on non-predictive cues, but not on predictive cues. Thus, there is a suggestion that the elevated levels of recognition memory seen for the unexpected uncertain condition in Experiment 2 was primarily driven by increases in cue-processing for the non-predictive cues.

According to the uncertainty principle, the increased levels of attention to cues associated with uncertainty operates as a mechanism to discover new cue-outcome relationships. This process has been referred to as “exploratory attention” [e.g., @beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019] or “attention for learning” [e.g., Hall & Rodríguez, -@hallAttentionPerceiveLearn2019a]. Thus, it is an attempt to resolve the prediction errors that are experienced by learning new and valid signals for the outcomes. In Experiment 2, it is possible that the non-predictive cues have greater “capacity” for learning, or perhaps offer a more plausible signal, given an association already exists between the predictive cues and the outcomes from the early certain phase. This exploratory process will be short lived in this procedure, since the uncertainty that is experienced cannot be resolved by learning new associations. Indeed, in the procedure of Easdale et al. [-@easdaleOnsetUncertaintyFacilitates2019], participants could resolve the uncertainty in a second stage by learning about the meaningful associations pertaining to the previously non-predictive cues. In this situation increased attentional processing of the non-predictive cues was observed.

This characterisation of the effect as one driven primarily by changes in processing for non-predictive cues is also consistent with the theory protection account proposed by Spicer and colleagues [-@spicerTheoryProtectionAssociative2020; -@spicerTheoryProtectionHumans2022]. According to this account, participants tend to protect existing associations as much as possible. When prediction errors are experienced during learning, rather than adjust those associations that result in the largest error, the learning system will instead direct resources to learning about cues that are not already strongly associated with outcomes. In line with this proposed property of human learning, it is possible that, in Experiment 3, participants in group Uncertain directed their attention more towards non-predictive cues than predictive cues at the onset of the unexpected uncertainty, since the predictive cues had already been established as reliable predictors of the outcomes in the first stage of training (in which the relationship between the predictive cues and the outcomes was perfect). Further studies will be necessary to confirm if theory protection offers an accurate account of the manner in which attentional resources are allocated during uncertainty.

The current results provide a stark warning about the interpretation of eye-gaze as a proxy for attentional processing. While we have not collected eye-gaze in the current tasks (since they were conducted online), we have substantial evidence that uncertain conditions lead to higher levels of both absolute dwell times on cues, and a higher proportion of the response time spent on cues [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019; @walkerRoleUncertaintyAttentional2019; @walkerProtectionUncertaintyExploration2022]. The finding that higher overt attention doesn’t lead to faster learning [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019; @torrents-rodasEffectPredictionError2023] and, in the current studies, that it doesn’t lead to greater cue-processing, is problematic for the use of eye-data in constraining attentional models of associative learning. Of course, this concern of the apparent disconnect between overt attention and active stimulus engagement stretches beyond the field of human learning. As has been noted in other literatures, most notably in the case of inattentional blindness [e.g., @simonsGorillasOurMidst1999]; looking does not always reflect an active and engaged attentional process.

In conclusion, the studies reported here revealed that unexpected-, but not expected- uncertainty, leads to an enhancement in the processing of cues during associative learning, highlighting the importance of the distinction between expected and unexpected uncertainty. Future work will be needed to understand the implications of this distinction on associability and subsequent learning, as well as on eye-gaze. Furthermore, attentional models of associative learning will need to accommodate and refine our understanding of expected and unexpected uncertainty in order to adequately map out the relationships between patterns of reinforcement, stimulus processing, and learning.

# References

::: {#refs}
:::

# Appendix I

The two sets of images from which the cues and foils displayed in the study were randomly selected can be seen in @fig-cues_and_foils.

```{r @fig-cues_and_foils}
#| label: fig-cues_and_foils
#| fig-cap: Cues and foils used in Experiments 1 and 2.
#| apa-twocolumn: true
#apa-note: "Panel A displays the cues that can be selected for the training phase. Panel B displays the set of foils that could be selected in the memory test."
#| out-width: 100%
#| fig-pos: h
knitr::include_graphics("images/cues_foils.png")
```

The two images used as outcomes in these experiments can be seen in @fig-outcomes.

```{r fig-outcomes}
#| label: fig-outcomes
#| fig-cap: Outcomes used in all experiments.
#| apa-twocolumn: true
#| out-width: 100%
#| fig-pos: h
knitr::include_graphics("images/outcomes.png")
```
