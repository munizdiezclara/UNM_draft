---
title: "UNM_draft_v2"
format: docx
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(afex)
library(BayesFactor)
library(apa)
library(emmeans)
library(papaja)
library(rstatix)
library("writexl")
options(scipen=999)
bfit = 500

# function to force scientific formatting of numbers (used for large BFs)
changeSciNot <- function(n) {
  output <- format(n, scientific = TRUE, digits = 2) #Transforms the number into scientific notation even if small
  output <- sub("e", "x10^", output) #Replace e with 10^
  output <- sub("\\+0?", "", output) #Remove + symbol and leading zeros on exponent, if > 1
  output <- sub("-0?", "-", output) #Leaves - symbol but removes leading zeros on exponent, if < 1
  output <- paste0(output,"^")
  # output = strsplit(output, "^", fixed = TRUE)
  # output = paste0(output[[1]][1],"^", output[[1]][2], "^")
  output
}
# function to extract and report BFs with error %s
report_BF_and_error <- function(BF_in, sci_not = FALSE, hyp = "alt"){
  
  if (hyp == "alt") {
    BF_notation = "BF~10~ = "
  } else if (hyp == "null") {
    BF_notation = "BF~01~ = "
  }
  
  if (sci_not == TRUE) {
    BF_value = changeSciNot(extractBF(BF_in)$bf) # change to sci notation
  } else {
    BF_value = round(extractBF(BF_in)$bf,2) # otherwise round
  }
  
  paste0(BF_notation, 
         BF_value, 
         " &plusmn; ", 
         round(100*extractBF(BF_in)$error,2), 
         "%")
}
```

# 3. Experiment 2

::: {#tbl-exp2 apa-note="Uppercase letters A, B, X, and Y represent the cues presented during training. O1 and O2 represent the outcomes presented in training. Lowercase letters a, b, x, and y represent the foils that are similar to the (corresponding upper-case letter) cues presented in the training phase. The numbers before the trials define the proportion of trials of that type that were presented." apa-twocolumn="true"}
+--------------+---------------------------+------------------+
| Group        | Training                  | Test             |
+==============+:=========================:+:================:+
| Certain      | AX - O1                   | A vs *b*/*x*/*y* |
|              |                           |                  |
|              | AY - O1                   | B vs *a*/*x*/*y* |
|              |                           |                  |
|              | BX - O2                   | X vs *a*/*b*/*y* |
|              |                           |                  |
|              | BY - O2                   | Y vs *a*/*b*/*x* |
+--------------+---------------------------+------------------+
| Uncertain    | 0.8 AX - O1 / 0.2 AX - O2 | A vs *b*/*x*/*y* |
|              |                           |                  |
|              | 0.8 AY - O1 / 0.2 AY - O2 | B vs *a*/*x*/*y* |
|              |                           |                  |
|              | 0.8 BX - O2 / 0.2 BX - O1 | X vs *a*/*b*/*y* |
|              |                           |                  |
|              | 0.8 BY - O2 / 0.2 BY - O1 | Y vs *a*/*b*/*x* |
+--------------+---------------------------+------------------+

Design of Experiment 2
:::


```{r, include=FALSE}
#load the data
load("UNM07_proc_data.RData")
UNM07_demographics <- demographics
UNM07_training <- training
UNM07_test <- test
UNM07_not_passed <- not_passed_pNum

#add the congruence variable
UNM07_test <- UNM07_test %>%
  mutate(trial_type = case_when((target == 1 & distractor == 2) | (target == 2 & distractor == 1) | (target == 3 & distractor == 4) | (target == 4 & distractor == 3) ~ "P-Con" ,
                                (target == 5 & distractor == 6) | (target == 6 & distractor == 5) |  (target == 7 & distractor == 8) | (target == 8 & distractor == 7)~ "NP-Con",
                                (target == 1 & (distractor == 5 | distractor == 6)) | (target == 2 & (distractor == 5 | distractor == 6)) | (target == 3 & (distractor == 7 | distractor == 8)) | (target == 4 & (distractor == 7 | distractor == 8)) ~ "P-Incon",
                                  (target == 5 & (distractor == 1 | distractor == 2)) | (target == 6 & (distractor == 1 | distractor == 2)) | (target == 7 & (distractor == 3 | distractor == 4)) | (target == 8 & (distractor == 3 | distractor == 4)) ~  "NP-Incon"),
         #add a congruence variable
         congruence = case_when ((trial_type == "P-Con") | (trial_type == "NP-Con") ~ "congruent",
                                 (trial_type == "P-Incon") | (trial_type == "NP-Incon") ~ "incongruent"))

#create the PPR measure
UNM07_training <- UNM07_training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0, 
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1))
#create the PPR measure
UNM07_training <- UNM07_training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0, 
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1))

#detect and clean participants that not passed the test comprehension check
UNM07_training <- filter(UNM07_training, !pNum %in% UNM07_not_passed$pNum)
UNM07_test <- filter(UNM07_test, !pNum %in% UNM07_not_passed$pNum)
UNM07_test <- filter(UNM07_test, congruence == "congruent")
```

## 3.2 Results

### Accuracy

```{r, include=FALSE}
#Calculate the mean accuracy and standard error for each block, including the groups
MA_test <- UNM07_test %>%
  group_by(condition, predictiveness) %>%
    summarise(mean_acc = mean(acc, na.rm = TRUE), 
            se_acc = sd(acc, na.rm = TRUE)/sqrt(length(acc)))
```

@fig-acctestExp2 shows the accuracy results from the recognition memory test. Accuracy for non-predictive cues was lower than for the predictive cues in the Certain group, but this difference was not present in the Uncertain group. Also, accuracy was similar in both groups.

```{r, echo=FALSE, message=FALSE}
#| label: fig-acctestExp2
#| fig-cap: Accuracy on the test phase of Experiment 2.
#| apa-note: "Mean accuracy (±SEM) during the test phase of Experiment 2, for groups trained with certain and uncertain contingencies."
#| fig-height: 4
ggplot(data = MA_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain')), y = mean_acc, fill = predictiveness)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(y= mean_acc, ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width = .2, position = position_dodge(0.9)) +
  coord_cartesian(ylim = c(0, 1))+
  scale_x_discrete (name = "Group") +
  scale_y_continuous(name = "Accuracy") +
  coord_cartesian(ylim = c(0.5, 1)) +
  scale_fill_discrete(type = c("#7B3294", "#008837"))
```

```{r, include=FALSE}
#ANOVA accuracy
acc_UNM07_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
acc_UNM07_test$predictiveness <- factor(acc_UNM07_test$predictiveness)
acc_UNM07_test$condition <- factor(acc_UNM07_test$condition)
acc_UNM07_test$pNum <- factor(acc_UNM07_test$pNum)
ANOVA_acc_UNM07_test <- aov_car(formula = acc ~ condition + Error(pNum*predictiveness), data = acc_UNM07_test)
print(ANOVA_acc_UNM07_test)

bay_ANOVA_acc_UNM07_test <- anovaBF(formula = acc ~ condition*predictiveness + pNum,
        data = data.frame(acc_UNM07_test),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_acc_UNM07_test)

bay_ANOVA_acc_UNM07_test_gxp <- bay_ANOVA_acc_UNM07_test[4]/bay_ANOVA_acc_UNM07_test[3]
print(bay_ANOVA_acc_UNM07_test_gxp)
```

No significant differences. 
*group*: `r apa(ANOVA_acc_UNM07_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test[1])`
*predictiveness*: `r apa(ANOVA_acc_UNM07_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test[2])`
*group x predictiveness* interaction, `r apa(ANOVA_acc_UNM07_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test_gxp[1])`.

### Memory score
```{r, include = FALSE}
#create the memory_score
UNM07_test <- UNM07_test %>%
  mutate (c_mem_score = case_when(acc == 0 ~ 0, acc == 1 ~ mem_score))
#Calculate the mean PPR and standard error for each block, including the groups
UNM07_MS_test <- UNM07_test %>%
  group_by(predictiveness, condition) %>%
    summarise(mean_mem_score = mean(c_mem_score, na.rm = TRUE), 
            se_mem_score = sd(c_mem_score, na.rm = TRUE)/sqrt(length(c_mem_score)))
```

Memory scores, calculated as the product of the accuracy score (1 or 0) with the confidence rating given, can be seen in @fig-testExp2. The memory scores for non-predictive cues was lower than for the predictive cues in the Certain group. This difference was notably attenuated in the Uncertain group, and there was no indication of higher memory scores in the uncertain group relative to the Certain group.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-testExp2
#| fig-cap: Memory scores during the Test of Experiment 2.
#| apa-note: "Mean memory scores (±SEM) during the Test phase of Experiment 2 for predictive and non-predictive trials in the Certain and Uncertain groups."
#| fig-height: 4
ggplot(UNM07_MS_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain')), y = mean_mem_score, fill = predictiveness)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(ymin = mean_mem_score - se_mem_score, ymax = mean_mem_score + se_mem_score), width=.2, position=position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_fill_discrete(type = c("#7B3294", "#008837"))+
  scale_y_continuous(name = "Memory score")+
  #scale_fill_grey(start = 0.33) +
  theme_apa()
```

```{r, include=FALSE}
#ANOVA mem_score
UNM07_memscore_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
UNM07_memscore_test$predictiveness <- factor(UNM07_memscore_test$predictiveness)
UNM07_memscore_test$condition <- factor(UNM07_memscore_test$condition)
UNM07_memscore_test$pNum <- factor(UNM07_memscore_test$pNum)
ANOVA_UNM07_test <- aov_car(formula = mem_score ~ condition + Error(pNum*predictiveness), data = UNM07_memscore_test)
print(ANOVA_UNM07_test)

bay_ANOVA_UNM07_test <- anovaBF(formula = mem_score ~ condition*predictiveness + pNum,
        data = data.frame(UNM07_memscore_test),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM07_test)
bay_ANOVA_UNM07_test_gxp <- bay_ANOVA_UNM07_test[4]/bay_ANOVA_UNM07_test[3]
print(bay_ANOVA_UNM07_test_gxp)
```

Nothing significant. 
*group*: `r apa(ANOVA_UNM07_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM07_test[1])`
*predictiveness*, `r apa(ANOVA_UNM07_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM07_test[2])`
*group x predictiveness* interaction, `r apa(ANOVA_UNM07_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM07_test_gxp[1])`

# 4. Experiment 3

::: {#tbl-exp3 apa-note="Uppercase letters A, B, X, and Y represent the cues presented during training. O1 and O2 represent the outcomes presented in training. Lowercase letters a, b, x, and y represent the foils that are similar to the (corresponding upper-case letter) cues presented in the training phase. The numbers before the trials define the proportion of trials of that type that were presented." apa-twocolumn="true"}
+---------------+--------------+---------------------------+------------------+
| Group         | Stage 1      | Stage 2                   | Test             |
+===============+==============+:=========================:+:================:+
| Certain Long  | AX - O1      | AX - O1                   | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      | AY - O1                   | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      | BX - O2                   | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      | BY - O2                   | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+
| Certain Short | AX - O1      |                           | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      |                           | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      |                           | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      |                           | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+
| Uncertain     | AX - O1      | 0.8 AX - O1 / 0.2 AX - O2 | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      | 0.8 AY - O1 / 0.2 AY - O2 | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      | 0.8 BX - O2 / 0.2 BX - O1 | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      | 0.8 BY - O2 / 0.2 BY - O1 | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+

Design of Experiment 3
:::

```{r, include=FALSE}
#load the data
load("UNM08_proc_data.RData")
UNM08_demographics <- demographics
UNM08_training <- rbind(stage1, stage2)
UNM08_test <- test
UNM08_not_passed <- not_passed_pNum
```

```{r, include = FALSE}
#create the PPR measure
UNM08_training <- UNM08_training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0, 
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1, 
                                   cue1 == "A" & response == "o1_image" ~ 1,
                                   cue1 == "A" & response == "o2_image" ~ 0, 
                                   cue1 == "B" & response == "o1_image" ~ 0,
                                   cue1 == "B" & response == "o2_image" ~ 1))

UNM08_test <- UNM08_test %>%
  mutate(trial_type = case_when((target == 1 & distractor == 2) | (target == 2 & distractor == 1) | (target == 3 & distractor == 4) | (target == 4 & distractor == 3) ~ "P-Con" ,
                                (target == 5 & distractor == 6) | (target == 6 & distractor == 5) |  (target == 7 & distractor == 8) | (target == 8 & distractor == 7)~ "NP-Con",
                                (target == 1 & (distractor == 5 | distractor == 6)) | (target == 2 & (distractor == 5 | distractor == 6)) | (target == 3 & (distractor == 7 | distractor == 8)) | (target == 4 & (distractor == 7 | distractor == 8)) ~ "P-Incon",
                                  (target == 5 & (distractor == 1 | distractor == 2)) | (target == 6 & (distractor == 1 | distractor == 2)) | (target == 7 & (distractor == 3 | distractor == 4)) | (target == 8 & (distractor == 3 | distractor == 4)) ~  "NP-Incon"),
         #add a congruence variable
         congruence = case_when ((trial_type == "P-Con") | (trial_type == "NP-Con") ~ "congruent",
                                 (trial_type == "P-Incon") | (trial_type == "NP-Incon") ~ "incongruent"))

#detect and clean participants that had an PPR lower than 0.6 in the final block or not passed the test comprehension check
UNM08_block6 <- filter(UNM08_training, block == 6) %>%
  group_by(pNum, condition) %>%
  summarise (mean_response = mean(prob_response, na.rm = TRUE))
UNM08_low_acc_total <- filter(UNM08_block6, mean_response < 0.6) 
UNM08_low_acc <- UNM08_low_acc_total$pNum
UNM08_training <- filter(UNM08_training, !pNum %in% UNM08_not_passed$pNum & !pNum %in% UNM08_low_acc_total$pNum)
UNM08_test <- filter(UNM08_test, !pNum %in% UNM08_not_passed$pNum & !pNum %in% UNM08_low_acc_total$pNum)
UNM08_test <- filter(UNM08_test, congruence == "congruent")
```

## 4.2 Results

### Accuracy

```{r, include=FALSE}
#Calculate the mean accuracy and standard error for each block, including the groups
MA_UNM08_test <- UNM08_test %>%
  group_by(predictiveness, condition) %>%
    summarise(mean_acc = mean(acc, na.rm = TRUE), 
            se_acc = sd(acc, na.rm = TRUE)/sqrt(length(acc)))
```

@fig-acctestExp3 shows the accuracy results from the recognition memory test. Accuracy for non-predictive cues was lower than for the predictive cues in the Certain group, but this difference was not present in the Uncertain group. Also, accuracy was similar in both groups.

```{r, echo=FALSE, message=FALSE}
#| label: fig-acctestExp3
#| fig-cap: Accuracy on the test phase of Experiment 3.
#| apa-note: "Mean accuracy (±SEM) during the test phase of Experiment 3 across the three groups."
#| fig-height: 4
ggplot(data = MA_UNM08_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain Short','Certain Long')), y = mean_acc, fill = predictiveness)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(y= mean_acc, ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width = .2, position = position_dodge(0.9)) +
  coord_cartesian(ylim = c(0, 1))+
  scale_x_discrete (name = "Type of test") +
  scale_y_continuous(name = "Accuracy") +
  coord_cartesian(ylim = c(0.5, 1)) +
  scale_fill_discrete(type = c("#7B3294", "#008837"))
```

```{r, include=FALSE}
#ANOVA accuracy
acc_UNM08_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
acc_UNM08_test$predictiveness <- factor(acc_UNM08_test$predictiveness)
acc_UNM08_test$condition <- factor(acc_UNM08_test$condition)
acc_UNM08_test$pNum <- factor(acc_UNM08_test$pNum)
ANOVA_acc_UNM08_test <- aov_car(formula = acc ~ condition + Error(pNum*predictiveness), data = acc_UNM08_test)
print(ANOVA_acc_UNM08_test)

bay_ANOVA_acc_UNM08_test <- anovaBF(formula = acc ~ condition*predictiveness + pNum,
        data = data.frame(acc_UNM08_test),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_acc_UNM08_test)

bay_ANOVA_acc_UNM08_test_gxp <- bay_ANOVA_acc_UNM08_test[4]/bay_ANOVA_acc_UNM08_test[3]
print(bay_ANOVA_acc_UNM08_test_gxp)
```

Nothing significant, altough condition is nearly there. 
*group*, `r apa(ANOVA_acc_UNM08_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test[1])`
*predictiveness*: `r apa(ANOVA_acc_UNM08_test, effect = "predictiveness")`, `
*group x predictiveness* interaction, `r apa(ANOVA_acc_UNM08_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test_gxp[1])`

### Memory score

```{r, include = FALSE}
#create the memory_score
UNM08_test <- UNM08_test %>%
  mutate (c_mem_score = case_when(acc == 0 ~ 0, acc == 1 ~ mem_score))
#Calculate the mean PPR and standard error for each block, including the groups
UNM08_MS_test <- UNM08_test %>%
  group_by(predictiveness, condition) %>%
    summarise(mean_mem_score = mean(c_mem_score, na.rm = TRUE), 
            se_mem_score = sd(c_mem_score, na.rm = TRUE)/sqrt(length(c_mem_score)))
```

@fig-testExp3 shows the recognition memory data for the three conditions. Memory for non-predictive cues was lower than for predictive cues in all groups, but this difference was notably attenuated in the Uncertain group. Interestingly, the memory for the cues in the Uncertain group was higher, overall, than in the Certain Long and Certain Short groups.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-testExp3
#| fig-cap: Memory scores on the Test of Experiment 3.
#| apa-note: "Mean memory scores (±SEM) during the Test of Experiment 2 for predictive and non-predictive trials across the three groups."
#| fig-height: 4
ggplot(UNM08_MS_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain Short', 'Certain Long')), y = mean_mem_score, fill = predictiveness)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(ymin = mean_mem_score - se_mem_score, ymax = mean_mem_score + se_mem_score), width=.2, position=position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_fill_discrete(type = c("#7B3294", "#008837"))+
  scale_y_continuous(name = "Memory score")+
  #scale_fill_grey(start = 0.33) +
  theme_apa()
```

```{r, include=FALSE}
#ANOVA mem_score
UNM08_memscore_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
UNM08_memscore_test$predictiveness <- factor(UNM08_memscore_test$predictiveness)
UNM08_memscore_test$condition <- factor(UNM08_memscore_test$condition)
UNM08_memscore_test$pNum <- factor(UNM08_memscore_test$pNum)
ANOVA_UNM08_test <- aov_car(formula = mem_score ~ condition + Error(pNum*predictiveness), data = UNM08_memscore_test)
print(ANOVA_UNM08_test)
bay_ANOVA_UNM08_test <- anovaBF(formula = mem_score ~ condition + predictiveness,
        data = data.frame(UNM08_memscore_test),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM08_test)
bay_ANOVA_UNM08_test_gxp <- bay_ANOVA_UNM08_test[4]/bay_ANOVA_UNM08_test[3]
print(bay_ANOVA_UNM08_test_gxp)
```

Only a signficant effect of predictiveness. 
*group*, `r apa(ANOVA_UNM08_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM08_test[1])` 
*predictiveness*, `r apa(ANOVA_UNM08_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM08_test[2])`
*group x predictiveness*, `r apa(ANOVA_UNM08_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM08_test_int[1])`