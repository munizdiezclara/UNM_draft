---
title: "UNM_draft_v2"
format: docx
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(afex)
library(BayesFactor)
library(apa)
library(emmeans)
library(papaja)
library(rstatix)
library("writexl")
options(scipen=999)
bfit = 500

# function to force scientific formatting of numbers (used for large BFs)
changeSciNot <- function(n) {
  output <- format(n, scientific = TRUE, digits = 2) #Transforms the number into scientific notation even if small
  output <- sub("e", "x10^", output) #Replace e with 10^
  output <- sub("\\+0?", "", output) #Remove + symbol and leading zeros on exponent, if > 1
  output <- sub("-0?", "-", output) #Leaves - symbol but removes leading zeros on exponent, if < 1
  output <- paste0(output,"^")
  # output = strsplit(output, "^", fixed = TRUE)
  # output = paste0(output[[1]][1],"^", output[[1]][2], "^")
  output
}
# function to extract and report BFs with error %s
report_BF_and_error <- function(BF_in, sci_not = FALSE, hyp = "alt"){
  
  if (hyp == "alt") {
    BF_notation = "BF~10~ = "
  } else if (hyp == "null") {
    BF_notation = "BF~01~ = "
  }
  
  if (sci_not == TRUE) {
    BF_value = changeSciNot(extractBF(BF_in)$bf) # change to sci notation
  } else {
    BF_value = round(extractBF(BF_in)$bf,2) # otherwise round
  }
  
  paste0(BF_notation, 
         BF_value, 
         " &plusmn; ", 
         round(100*extractBF(BF_in)$error,2), 
         "%")
}
```

# 3. Experiment 2

The purpose of Experiment 2 was to examine differences in recognition memory in a learned predictiveness procedure under certain and uncertain cue-outcome contingency conditions. Two groups were trained, one with a perfect contingency between the predictive cues and their paired outcome (Group Certain) - replicating the training from Experiment 1 - and one with a contingency of 0.8 between the predictive cues and their paired outcome (Group Uncertain). After this training, we tested the memory for cues in both groups using the memory test procedure that was most successful in Experiment 1, namely Test 2 (where targets were paired with foils from different cues). We also used the “High” similarity stimuli from Experiment 1, since it was only using these stimuli that a difference in memory performance between predictive and non-predictive stimuli was established.

The design of Experiment 2 is shown in @tbl-exp2. Previous experiments have established that for uncertain contingencies, participants spend longer attending to (looking at) all cues compared to attention to cues in certain contingencies [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019; @walkerProtectionUncertaintyExploration2022]. Experiment 2 therefore aimed to test whether uncertain contingencies, where it is well established that there is a high level of attention to cues, result in an improvement in the processing of these stimuli. As such, we predicted that memory would be better, overall, for the cues in group Uncertain compared to group Certain. Finally, on the basis of the results of Experiment 1, we anticipate seeing superior memory scores for the predictive than the non-predictive cues in group Certain.

::: {#tbl-exp2 apa-note="Uppercase letters A, B, X, and Y represent the cues presented during training. O1 and O2 represent the outcomes presented in training. Lowercase letters a, b, x, and y represent the foils that are similar to the (corresponding upper-case letter) cues presented in the training phase. The numbers before the trials define the proportion of trials of that type that were presented." apa-twocolumn="true"}
+--------------+---------------------------+------------------+
| Group        | Training                  | Test             |
+==============+:=========================:+:================:+
| Certain      | AX - O1                   | A vs *b*/*x*/*y* |
|              |                           |                  |
|              | AY - O1                   | B vs *a*/*x*/*y* |
|              |                           |                  |
|              | BX - O2                   | X vs *a*/*b*/*y* |
|              |                           |                  |
|              | BY - O2                   | Y vs *a*/*b*/*x* |
+--------------+---------------------------+------------------+
| Uncertain    | 0.8 AX - O1 / 0.2 AX - O2 | A vs *b*/*x*/*y* |
|              |                           |                  |
|              | 0.8 AY - O1 / 0.2 AY - O2 | B vs *a*/*x*/*y* |
|              |                           |                  |
|              | 0.8 BX - O2 / 0.2 BX - O1 | X vs *a*/*b*/*y* |
|              |                           |                  |
|              | 0.8 BY - O2 / 0.2 BY - O1 | Y vs *a*/*b*/*x* |
+--------------+---------------------------+------------------+

Design of Experiment 2
:::

## 3.1 Methods

### 3.1.1 Participants

```{r, include=FALSE}
#load the data
load("UNM07_proc_data.RData")
UNM07_demographics <- demographics
UNM07_training <- training
UNM07_test <- test
UNM07_not_passed <- not_passed_pNum

#add the congruence variable
UNM07_test <- UNM07_test %>%
  mutate(trial_type = case_when((target == 1 & distractor == 2) | (target == 2 & distractor == 1) | (target == 3 & distractor == 4) | (target == 4 & distractor == 3) ~ "P-Con" ,
                                (target == 5 & distractor == 6) | (target == 6 & distractor == 5) |  (target == 7 & distractor == 8) | (target == 8 & distractor == 7)~ "NP-Con",
                                (target == 1 & (distractor == 5 | distractor == 6)) | (target == 2 & (distractor == 5 | distractor == 6)) | (target == 3 & (distractor == 7 | distractor == 8)) | (target == 4 & (distractor == 7 | distractor == 8)) ~ "P-Incon",
                                  (target == 5 & (distractor == 1 | distractor == 2)) | (target == 6 & (distractor == 1 | distractor == 2)) | (target == 7 & (distractor == 3 | distractor == 4)) | (target == 8 & (distractor == 3 | distractor == 4)) ~  "NP-Incon"),
         #add a congruence variable
         congruence = case_when ((trial_type == "P-Con") | (trial_type == "NP-Con") ~ "congruent",
                                 (trial_type == "P-Incon") | (trial_type == "NP-Incon") ~ "incongruent"))

#create the PPR measure
UNM07_training <- UNM07_training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0, 
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1))
#create the PPR measure
UNM07_training <- UNM07_training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0, 
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1))

#detect and clean participants that not passed the test comprehension check
UNM07_training <- filter(UNM07_training, !pNum %in% UNM07_not_passed$pNum)
UNM07_test <- filter(UNM07_test, !pNum %in% UNM07_not_passed$pNum)
```

`r nrow(UNM07_demographics)` participants were recruited through Prolific. The sample consisted of `r length(which(UNM07_demographics$gender == "female"))` women, `r length(which(UNM07_demographics$gender == "male"))` men and one non-binary person, with `r n_distinct(UNM07_demographics$Nationality)` different nationalities. The mean age was `r format(mean(UNM07_demographics$age, na.rm = TRUE), digits = 3)` calculated for the `r nrow(UNM07_demographics) - sum(is.na(UNM07_demographics$age))` participants that reported their age (range `r min(UNM07_demographics$age, na.rm = TRUE)` - `r max(UNM07_demographics$age, na.rm = TRUE)`). Pre-screening of participants in Prolific ensured that they had normal or corrected to normal vision, fluency in English language, and had not participated in previous studies from our lab. Participants were rewarded with £2.70 for their participation in the study. Participants were randomly allocated to either the Certain or Uncertain condition. Four participants were excluded due to failing the comprehension check before the test (three in group Certain and one in group Uncertain). Post-hoc calculations using G\*Power 3.1 [@faulStatisticalPowerAnalyses2007] revealed that this sample size had a power of .99 to detect an effect size of η~p~^2^ = .06 that was observed for the *group x predictiveness* interaction reported in @fig-testExp2.

### 3.1.2 Apparatus and stimuli

The materials used for Experiment 2 were the same as in Experiment 1, with the stimuli taken from the High similarity group.

### 3.1.3 Design

The design of Experiment 2 is shown in @tbl-exp2. The Certain group employed the same design as in Experiment 1: cues A and B were perfectly predictive of the outcomes they were paired with, while cues X and Y were non-predictive. For the Uncertain group, cues A and B were the best available predictors on each trial but had a 0.8 contingency with the predicted outcome. To implement this contingency, each block of trials contained 5 presentations of each compound, where for four of these trials one outcome was “correct” (e.g., AX-O1) and for one of these trials the alternative outcome was “correct” (e.g., AX-O2). Cues X and Y were non-predictive in the two groups. The training phase of this experiment consisted of eight blocks, resulting in a total of 160 trials. Training was followed by a test identical to Test 2 of Experiment 1.

### 3.1.4 Procedure

The procedure for both the training and test phases was identical to those described in Experiment 1.

## 3.2 Results

For the training phase, it was necessary to calculate response performance in a different manner in this experiment, since participants in the uncertain condition received trials in which the “correct” outcome was switched on 20% of the trials. Thus, even if participants in group Uncertain were to always select the most probable outcome (O1 when A is present and O2 when B is present), it would result in an accuracy score of 80%. Thus, we calculated the proportion of probable responses (PPR): for the Uncertain group, on each trial, the score was 0 when participants chose the less probable outcome (i.e., O2 for A and O1 for B) and 1 when they chose the most probable outcome (i.e., O1 for A and O2 for B). For the certain condition, this equates to a standard accuracy score.

```{r, include = FALSE}
#Calculate the mean PPR and standard error for each block, including the groups
UNM07_MA_training <- UNM07_training %>%
  group_by(block, condition) %>%
  summarise(mean_accuracy = mean(prob_response, na.rm = TRUE), 
            se_accuracy = sd(prob_response, na.rm = TRUE)/sqrt(length(prob_response)))
```

@fig-trainingExp2 shows the mean PPR across blocks for each group. Participants in the Certain group showed higher PPR through training than the Uncertain group, reaching a PPR of 0.92 on block 8. The Uncertain group showed a slower increase in their PPR that reached 0.77 in block 8.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-trainingExp2
#| fig-cap: PPR on the training phase of Experiment 2.
#| apa-note: "Mean proportion of probable responses (±SEM) during the training phase of Experiment 2, for groups trained with certain and uncertain contingencies."
#| fig-height: 4
ggplot(UNM07_MA_training, mapping = aes(x = block, y = mean_accuracy, group = condition, color = condition)) +
  geom_point(mapping = aes(shape = condition), size = 2.5) +
  geom_line() +
  geom_errorbar(aes(x= block, y = mean_accuracy, ymin = mean_accuracy-se_accuracy, ymax = mean_accuracy+se_accuracy), colour = "black", width=.1)+
  scale_x_continuous(name = "Block") + 
  labs(shape = "Group", colour = "Group") +
  scale_color_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8))+
  scale_y_continuous(name = "PPR", limits = c(NA, 1))+
  theme_apa()
```

```{r, include=FALSE}
#ANOVA
UNM07_acc <- UNM07_training %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
UNM07_acc$block <- factor(UNM07_acc$block)
UNM07_acc$pNum <- factor(UNM07_acc$pNum)
UNM07_acc$condition <- factor(UNM07_acc$condition)
ANOVA_UNM07_acc <- aov_car(formula = mean_response ~ condition + Error(pNum/block), data = UNM07_acc)
print(ANOVA_UNM07_acc)
#Bayesian Anova
bay_ANOVA_UNM07_acc <- anovaBF(formula = mean_response ~ condition + block + pNum,
        data = data.frame(UNM07_acc),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM07_acc)
bay_ANOVA_UNM07_acc_int <- bay_ANOVA_UNM07_acc[4]/bay_ANOVA_UNM07_acc[3]
print(bay_ANOVA_UNM07_acc_int)
```

A mixed model ANOVA of individual PPR scores found significant both main effects, of *group*, `r apa(ANOVA_UNM07_acc, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM07_acc[2])`, and of *block*, `r apa(ANOVA_UNM07_acc, effect = "block")`, `r report_BF_and_error(bay_ANOVA_UNM07_acc[1], sci_not = TRUE)`. There was no interaction effect between these factors, `r apa(ANOVA_UNM07_acc, effect = "condition:block")`, with the Bayesian analysis providing strong evidence for the null hypothesis, `r report_BF_and_error(bay_ANOVA_UNM07_acc_int[1])`. These results indicate that the training increased the PPR for both groups, as the effect of block was significant, with the Certain group showing a consistently higher PPR than Uncertain group.

```{r, include=FALSE}
#Calculate the mean accuracy and standard error for each block, including the groups
MA_test <- UNM07_test %>%
  group_by(condition, trial_type) %>%
    summarise(mean_acc = mean(acc, na.rm = TRUE), 
            se_acc = sd(acc, na.rm = TRUE)/sqrt(length(acc)))
```

@fig-acctestExp2 shows the accuracy results from the recognition memory test. Accuracy for non-predictive cues was lower than for the predictive cues in the Certain group, but this difference was not present in the Uncertain group. Also, accuracy was similar in both groups.

```{r, echo=FALSE, message=FALSE}
#| label: fig-acctestExp2
#| fig-cap: Accuracy on the test phase of Experiment 2.
#| apa-note: "Mean accuracy (±SEM) during the test phase of Experiment 2, for groups trained with certain and uncertain contingencies."
#| fig-height: 4
ggplot(data = MA_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain')), y = mean_acc, fill = trial_type)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(y= mean_acc, ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width = .2, position = position_dodge(0.9)) +
  coord_cartesian(ylim = c(0, 1))+
  scale_x_discrete (name = "Type of test") +
  scale_y_continuous(name = "Accuracy") +
  coord_cartesian(ylim = c(0.5, 1)) +
  scale_fill_discrete(type = c("#7B3294", "#C2A5CF", "#008837", "#A6DBA0"))
```

```{r, include=FALSE}
#ANOVA accuracy
acc_UNM07_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness, congruence) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
acc_UNM07_test$predictiveness <- factor(acc_UNM07_test$predictiveness)
acc_UNM07_test$condition <- factor(acc_UNM07_test$condition)
acc_UNM07_test$pNum <- factor(acc_UNM07_test$pNum)
acc_UNM07_test$congruence<- factor(acc_UNM07_test$congruence)
ANOVA_acc_UNM07_test <- aov_car(formula = acc ~ condition + Error(pNum*predictiveness*congruence), data = acc_UNM07_test)
print(ANOVA_acc_UNM07_test)

bay_ANOVA_acc_UNM07_test <- anovaBF(formula = acc ~ condition*predictiveness*congruence + pNum,
        data = data.frame(acc_UNM07_test),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_acc_UNM07_test)

bay_ANOVA_acc_UNM07_test_gxp <- bay_ANOVA_acc_UNM07_test[4]/bay_ANOVA_acc_UNM07_test[3]
print(bay_ANOVA_acc_UNM07_test_gxp)
bay_ANOVA_acc_UNM07_test_pxc <- bay_ANOVA_acc_UNM07_test[13]/bay_ANOVA_acc_UNM07_test[7]
print(bay_ANOVA_acc_UNM07_test_pxc)
bay_ANOVA_acc_UNM07_test_sxc <- bay_ANOVA_acc_UNM07_test[10]/bay_ANOVA_acc_UNM07_test[6]
print(bay_ANOVA_acc_UNM07_test_sxc)
bay_ANOVA_acc_UNM07_test_gxpxc <- bay_ANOVA_acc_UNM07_test[18]/bay_ANOVA_acc_UNM07_test[17]
print(bay_ANOVA_acc_UNM07_test_gxpxc)
```

```{r, include = FALSE}
# SME of the condition:predictiveness interaction
SME_acc_UNM07_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
#calculate the simple main effect of condition
sme_acc_UNM07_test_condition <- SME_acc_UNM07_test %>%
  group_by(predictiveness) %>%
  anova_test(acc ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_acc_UNM07_test_condition #Call the output table
#calculate the simple main effect of predictiveness
sme_acc_UNM07_test_pred <- SME_acc_UNM07_test %>%
  group_by(condition) %>%
  anova_test(acc ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_acc_UNM07_test_pred #Call the output table
```

There was a significant *group x predictiveness* interaction, `r apa(ANOVA_acc_UNM07_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test_gxp[1])`; but no other significant differences, *group*: `r apa(ANOVA_acc_UNM07_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test[1])`; *predictiveness*: `r apa(ANOVA_acc_UNM07_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test[2])`; *congruence*: `r apa(ANOVA_acc_UNM07_test, effect ="congruence")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test[5])`; *predictiveness x congruence*: `r apa(ANOVA_acc_UNM07_test, effect = "predictiveness:congruence")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test_pxc[1])`; *group x congruence*: `r apa(ANOVA_acc_UNM07_test, effect = "condition:congruence")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test_sxc[1])`; *group x predictiveness x congruence*: `r apa(ANOVA_acc_UNM07_test, effect = "condition:predictiveness:congruence")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test_gxpxc[1])`. Simple main effects analysis showed a significant effect of predictiveness in the group Certain, *F* (`r sme_acc_UNM07_test_pred[1, 3]`, `r sme_acc_UNM07_test_pred[1, 4]`) = `r sme_acc_UNM07_test_pred[1, 5]`, *p* = `r sme_acc_UNM07_test_pred[1, 9]`, $\\eta^2_p$ = `r sme_acc_UNM07_test_pred[1, 8]`, but not on the Uncertain group, *F* (`r sme_acc_UNM07_test_pred[2, 3]`, `r sme_acc_UNM07_test_pred[2, 4]`) = `r sme_acc_UNM07_test_pred[2, 5]`, *p* = `r sme_acc_UNM07_test_pred[2, 9]`, $\\eta^2_p$ = `r sme_acc_UNM07_test_pred[2, 8]`. However, the simple main effect of condition was not significant nor for the predictive cues, *F* (`r sme_acc_UNM07_test_condition[2, 3]`, `r sme_acc_UNM07_test_condition[2, 4]`) = `r sme_acc_UNM07_test_condition[2, 5]`, *p* = `r sme_acc_UNM07_test_condition[2, 9]`, $\\eta^2_p$ = `r sme_acc_UNM07_test_condition[2, 8]`, neither for the non-predictive cues, *F* (`r sme_acc_UNM07_test_condition[1, 3]`, `r sme_acc_UNM07_test_condition[1, 4]`) = `r sme_acc_UNM07_test_condition[1, 5]`, *p* = `r sme_acc_UNM07_test_condition[1, 9]`, $\\eta^2_p$ = `r sme_acc_UNM07_test_condition[1, 8]`.

```{r, include = FALSE}
#create the memory_score
UNM07_test <- UNM07_test %>%
  mutate (c_mem_score = case_when(acc == 0 ~ 0, acc == 1 ~ mem_score))
#Calculate the mean PPR and standard error for each block, including the groups
UNM07_MS_test <- UNM07_test %>%
  group_by(trial_type, condition) %>%
    summarise(mean_mem_score = mean(c_mem_score, na.rm = TRUE), 
            se_mem_score = sd(c_mem_score, na.rm = TRUE)/sqrt(length(c_mem_score)))
```

Memory scores, calculated as the product of the accuracy score (1 or 0) with the confidence rating given, can be seen in @fig-testExp2. The memory scores for non-predictive cues was lower than for the predictive cues in the Certain group. This difference was notably attenuated in the Uncertain group, and there was no indication of higher memory scores in the uncertain group relative to the Certain group.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-testExp2
#| fig-cap: Memory scores during the Test of Experiment 2.
#| apa-note: "Mean memory scores (±SEM) during the Test phase of Experiment 2 for predictive and non-predictive trials in the Certain and Uncertain groups."
#| fig-height: 4
ggplot(UNM07_MS_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain')), y = mean_mem_score, fill = trial_type)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(ymin = mean_mem_score - se_mem_score, ymax = mean_mem_score + se_mem_score), width=.2, position=position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_fill_discrete(type = c("#7B3294", "#C2A5CF", "#008837", "#A6DBA0"))+
  scale_y_continuous(name = "Memory score")+
  #scale_fill_grey(start = 0.33) +
  theme_apa()
```

```{r, include=FALSE}
#ANOVA mem_score
UNM07_memscore_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness, congruence) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
UNM07_memscore_test$predictiveness <- factor(UNM07_memscore_test$predictiveness)
UNM07_memscore_test$congruence <- factor(UNM07_memscore_test$congruence)
UNM07_memscore_test$condition <- factor(UNM07_memscore_test$condition)
UNM07_memscore_test$pNum <- factor(UNM07_memscore_test$pNum)
ANOVA_UNM07_test <- aov_car(formula = mem_score ~ condition + Error(pNum*predictiveness*congruence), data = UNM07_memscore_test)
print(ANOVA_UNM07_test)

bay_ANOVA_UNM07_test <- anovaBF(formula = mem_score ~ condition*predictiveness*congruence + pNum,
        data = data.frame(UNM07_memscore_test),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM07_test)
bay_ANOVA_UNM07_test_gxp <- bay_ANOVA_UNM07_test[4]/bay_ANOVA_UNM07_test[3]
print(bay_ANOVA_UNM07_test_gxp)
bay_ANOVA_UNM07_test_pxc <- bay_ANOVA_UNM07_test[13]/bay_ANOVA_UNM07_test[7]
print(bay_ANOVA_UNM07_test_pxc)
bay_ANOVA_UNM07_test_sxc <- bay_ANOVA_UNM07_test[10]/bay_ANOVA_UNM07_test[6]
print(bay_ANOVA_UNM07_test_sxc)
bay_ANOVA_UNM07_test_gxpxc <- bay_ANOVA_UNM07_test[18]/bay_ANOVA_UNM07_test[17]
print(bay_ANOVA_UNM07_test_gxpxc)
```

```{r, include = FALSE}
# SME of the condition:predictiveness interaction
SME_mem_UNM07_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem = mean(c_mem_score, na.rm = TRUE))
#calculate the simple main effect of condition
sme_mem_UNM07_test_condition <- SME_mem_UNM07_test %>%
  group_by(predictiveness) %>%
  anova_test(mem ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_mem_UNM07_test_condition #Call the output table
#calculate the simple main effect of predictiveness
sme_mem_UNM07_test_pred <- SME_mem_UNM07_test %>%
  group_by(condition) %>%
  anova_test(mem ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_mem_UNM07_test_pred #Call the output table
```

There was a significant effect of *predictiveness*, `r apa(ANOVA_UNM07_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM07_test[2])`, and a significant *group x predictiveness* interaction, `r apa(ANOVA_UNM07_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM07_test_gxp[1])`. There were no other significant effects or interactions, *group*: `r apa(ANOVA_UNM07_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM07_test[1])`; *congruence*: `r apa(ANOVA_UNM07_test, effect ="congruence")`, `r report_BF_and_error(bay_ANOVA_UNM07_test[5])`; *predictiveness x congruence*: `r apa(ANOVA_UNM07_test, effect = "predictiveness:congruence")`, `r report_BF_and_error(bay_ANOVA_UNM07_test_pxc[1])`; *group x congruence*: `r apa(ANOVA_UNM07_test, effect = "condition:congruence")`, `r report_BF_and_error(bay_ANOVA_UNM07_test_sxc[1])`; *group x predictiveness x congruence*: `r apa(ANOVA_UNM07_test, effect = "condition:predictiveness:congruence")`, `r report_BF_and_error(bay_ANOVA_UNM07_test_gxpxc[1])`. Simple main effects showed a significant effect of *predictiveness* on Certain group, *F*(`r sme_mem_UNM07_test_pred[1,3]`, `r sme_mem_UNM07_test_pred[1,4]`) = `r sme_mem_UNM07_test_pred[1,5]`, *p* = `r sme_mem_UNM07_test_pred[1,9]`, $\\eta^2_p$ = `r sme_mem_UNM07_test_pred[1,8]`, but not on group Uncertain, *F*(`r sme_mem_UNM07_test_pred[2,3]`, `r sme_mem_UNM07_test_pred[2,4]`) = `r sme_mem_UNM07_test_pred[2,5]`, *p* = `r sme_mem_UNM07_test_pred[2,9]`, $\\eta^2_p$ = `r sme_mem_UNM07_test_pred[2,8]`. However, there was not simple main effect of *Condition* nor in non-predictive trials, *F*(`r sme_mem_UNM07_test_condition[1,3]`, `r sme_mem_UNM07_test_condition[1,4]`) = `r sme_mem_UNM07_test_condition[1,5]`, *p* = `r sme_mem_UNM07_test_condition[1,9]`, $\\eta^2_p$ = `r sme_mem_UNM07_test_condition[1,8]`, neither on predictive, *F*(`r sme_mem_UNM07_test_condition[2,3]`, `r sme_mem_UNM07_test_condition[2,4]`) = `r sme_mem_UNM07_test_condition[2,5]`, *p* = `r sme_mem_UNM07_test_condition[2,9]`, $\\eta^2_p$ = `r sme_mem_UNM07_test_condition[2,8]`.

## 3.3 Discussion

Experiment 2 aimed to examine the effect of uncertainty on recognition memory for predictive and non-predictive cues. The Uncertain group of participants were exposed to a probabilistic relationship between the predictive cues and their respective outcomes, while the Certain group received deterministic relationships. We hypothesised that the previously observed effect of uncertainty on overt attention (e.g., Beesley et al., 2015) would lead to better memory for cues in that condition. However, in a final recognition memory test, the two groups showed a similar overall level of recognition memory for the cues. There was an effect of cue-predictiveness in group Certain with better recognition memory for the predictive than the non-predictive cues (replicating the results of Experiment 1). However, there was no effect of cue-predictiveness in group Uncertain, with evidence to suggest memory for predictive and non-predictive cues was equivalent. This latter result is consistent with previous studies [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019] that have shown that attention (in those cases measured by eye-gaze dwell times), under certain training, decreased for non-predictive cues but not for predictive cues. That decrease in attention could be responsible for the worse memory performance for the non-predictive cues, compared with the predictive cues, in the certain group.

A central distinction made in Easdale et al. [-@easdaleOnsetUncertaintyFacilitates2019] was that between *expected-* and *unexpected-uncertainty*. In those experiments, participants who experienced a sustained period with uncertain compounds (as is the case in our “uncertain group” in Experiment 2) learnt more slowly about new contingencies, compared to a group that received a sudden and unexpected change in the contingencies. Thus, it may be the case that the current uncertain condition does not promote higher recognition memory, overall, because participants have come to expect a certain level of uncertainty and are no longer engaging in an exploratory mode of cue-processing. Of course, the expected levels of high attention to cues under these uncertain conditions presents a paradox for learning and attention research: why does a high level of attention not translate to better learning and memory for those cues? We return to this point in the general discussion. Nevertheless, this analysis of the findings in terms of expected and unexpected uncertainty suggests that a more acute period of uncertainty may (re)engage a mode of exploratory attentional processing for the cues, which would result in better memory of those cues. Experiment 3 tested this hypothesis.

# 4. Experiment 3

Experiment 3 aimed to examine whether the introduction of uncertainty, following a period of certain training (i.e., unexpected uncertainty), would lead to an increase in cue-processing (better recognition memory). The design of Experiment 3 can be seen in @tbl-exp3. The experiment consisted of three groups. Groups Certain Long and Certain Short received training that was similar to the Certain condition from Experiment 2, experiencing a protracted period of certain contingencies between the cue compounds and the outcomes throughout the training phase, differing only in the amount of training trials experienced by each of them. Group Uncertain first experienced the same certain contingencies experienced by Group Certain Long, before the contingencies were changed to uncertain for a short period before the recognition memory test. Our prediction was that, if the introduction of unexpected uncertainty promotes greater levels of exploratory attention, then we should see better recognition memory performance in this uncertain condition, compared to the certain condition.

::: {#tbl-exp3 apa-note="Uppercase letters A, B, X, and Y represent the cues presented during training. O1 and O2 represent the outcomes presented in training. Lowercase letters a, b, x, and y represent the foils that are similar to the (corresponding upper-case letter) cues presented in the training phase. The numbers before the trials define the proportion of trials of that type that were presented." apa-twocolumn="true"}
+---------------+--------------+---------------------------+------------------+
| Group         | Stage 1      | Stage 2                   | Test             |
+===============+==============+:=========================:+:================:+
| Certain Long  | AX - O1      | AX - O1                   | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      | AY - O1                   | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      | BX - O2                   | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      | BY - O2                   | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+
| Certain Short | AX - O1      |                           | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      |                           | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      |                           | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      |                           | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+
| Uncertain     | AX - O1      | 0.8 AX - O1 / 0.2 AX - O2 | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      | 0.8 AY - O1 / 0.2 AY - O2 | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      | 0.8 BX - O2 / 0.2 BX - O1 | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      | 0.8 BY - O2 / 0.2 BY - O1 | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+

Design of Experiment 3
:::

We also included a third condition, group Certain Short, which received the same certain contingencies as the other two conditions in Stage 1 but did not experience Stage 2; they received a shorter training phase than the other two conditions. If the onset of the uncertainty leads to greater cue-processing, then we should also see better cue-memory in the Uncertain condition compared to the Certain Short condition. The inclusion of this condition is important because longer training with the certain contingencies in the “Certain Long” condition could *decrease* cue processing, which would be an alternative explanation of any difference in cue processing we observe between Group Uncertain and Group Certain Long. If this is the case, we should see equivalent recognition memory in the Certain Short and Uncertain conditions, and poorer recognition memory in the Certain Long condition. Therefore, the addition of this third condition allowed us to make stronger inferences about the causal relationship between the onset of uncertainty and cue-processing.

## 4.1 Methods

### 4.1.1 Participants

```{r, include=FALSE}
#load the data
load("UNM08_proc_data.RData")
UNM08_demographics <- demographics
UNM08_training <- rbind(stage1, stage2)
UNM08_test <- test
UNM08_not_passed <- not_passed_pNum
```

```{r, include = FALSE}
#create the PPR measure
UNM08_training <- UNM08_training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0, 
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1, 
                                   cue1 == "A" & response == "o1_image" ~ 1,
                                   cue1 == "A" & response == "o2_image" ~ 0, 
                                   cue1 == "B" & response == "o1_image" ~ 0,
                                   cue1 == "B" & response == "o2_image" ~ 1))

UNM08_test <- UNM08_test %>%
  mutate(trial_type = case_when((target == 1 & distractor == 2) | (target == 2 & distractor == 1) | (target == 3 & distractor == 4) | (target == 4 & distractor == 3) ~ "P-Con" ,
                                (target == 5 & distractor == 6) | (target == 6 & distractor == 5) |  (target == 7 & distractor == 8) | (target == 8 & distractor == 7)~ "NP-Con",
                                (target == 1 & (distractor == 5 | distractor == 6)) | (target == 2 & (distractor == 5 | distractor == 6)) | (target == 3 & (distractor == 7 | distractor == 8)) | (target == 4 & (distractor == 7 | distractor == 8)) ~ "P-Incon",
                                  (target == 5 & (distractor == 1 | distractor == 2)) | (target == 6 & (distractor == 1 | distractor == 2)) | (target == 7 & (distractor == 3 | distractor == 4)) | (target == 8 & (distractor == 3 | distractor == 4)) ~  "NP-Incon"),
         #add a congruence variable
         congruence = case_when ((trial_type == "P-Con") | (trial_type == "NP-Con") ~ "congruent",
                                 (trial_type == "P-Incon") | (trial_type == "NP-Incon") ~ "incongruent"))

#detect and clean participants that had an PPR lower than 0.6 in the final block or not passed the test comprehension check
UNM08_block6 <- filter(UNM08_training, block == 6) %>%
  group_by(pNum, condition) %>%
  summarise (mean_response = mean(prob_response, na.rm = TRUE))
UNM08_low_acc_total <- filter(UNM08_block6, mean_response < 0.75) 
UNM08_low_acc <- UNM08_low_acc_total$pNum
UNM08_training <- filter(UNM08_training, !pNum %in% UNM08_not_passed$pNum & !pNum %in% UNM08_low_acc_total$pNum)
UNM08_test <- filter(UNM08_test, !pNum %in% UNM08_not_passed$pNum & !pNum %in% UNM08_low_acc_total$pNum)
```

`r nrow(UNM08_demographics)` participants were recruited through Prolific. The mean age of the `r nrow(UNM08_demographics) - sum(is.na(UNM08_demographics$age))` participants that reported their age was `r format(mean(UNM08_demographics$age, na.rm = TRUE), digits = 3)` (range `r min(UNM08_demographics$age, na.rm = TRUE)` - `r max(UNM08_demographics$age, na.rm = TRUE)`), with `r length(which(UNM08_demographics$gender == "female"))` women, `r length(which(UNM08_demographics$gender == "male"))` men, and one non-binary person, and `r n_distinct(UNM08_demographics$Nationality)` different nationalities. Participants were divided into 3 groups in the following fashion: `r nrow(filter(UNM08_demographics, condition == "Certain Long"))` in group Certain Long, `r nrow(filter(UNM08_demographics, condition == "Certain Short"))` in group Certain Short and `r nrow(filter(UNM08_demographics, condition == "Uncertain"))` in group Uncertain. Eight participants were excluded on the basis of failing the comprehension check before the test, six in group Uncertain, one in group Certain Short, and one in group Certain Long. Also, `r nrow(UNM08_low_acc_total)` participants were excluded due to a low PPR (\< 0.6) on the last block of Stage 1, five in group Certain Long, seven in group Certain Short and `r length(which(UNM08_low_acc_total$condition == "Uncertain"))`in group Uncertain. Thus, the results below are for the remaining `r nrow(UNM08_test)/24` participants. Post-hoc calculations using G\*Power 3.1 [@faulStatisticalPowerAnalyses2007] revealed that this sample size had a power of .87 to detect an effect size of η~p~^2^ = .09 that was observed for the group main effect reported in @fig-testExp3.

### 4.1.2 Apparatus and stimuli

The materials were the same as in Experiments 1 and 2.

### 4.1.3 Design

The experiment used a mixed design (as seen in @tbl-exp3), with three groups: Certain Long, Certain Short, and Uncertain. All groups received six blocks of certain training. Group Certain Long then received a further 4 blocks of certain training; group Uncertain, received a further four blocks of uncertain training (with contingencies of 0.8); and group Certain Short received no further training (they completed six training blocks only). When training was completed, all groups progressed to the memory test, which was identical to the one Experiment 2.

### 4.1.4 Procedure

All the details about the procedure were identical to Experiment 2.

## 4.2 Results

```{r, include = FALSE}
#Calculate the mean PPR and standard error for each block, including the groups and stages
UNM08_MA_training <- UNM08_training %>%
  group_by(block, stage, condition) %>%
  summarise(mean_accuracy = mean(prob_response, na.rm = TRUE), 
            se_accuracy = sd(prob_response, na.rm = TRUE)/sqrt(length(prob_response)))

#add a dummy to display stage 2 for Certain Short
MA_stage2_dummy <- data.frame(stage = c('stage 2', 'stage 2', 'stage 2', 'stage 2'),
                              block = c(7:10),
                              condition = c('Certain Short', 'Certain Short', 'Certain Short', 'Certain Short'),
                              mean_accuracy = c(0.001, 0.002, 0.003, 0.004),
                              se_accuracy = c(0.0001, 0.00020, 0.0003, 0.00004))
UNM08_MA_training <- rbind(UNM08_MA_training, MA_stage2_dummy)
#change stage 1 and stage 2 to Stage1 and Stage 2, and Certain_short to Certain Short
UNM08_MA_training <- UNM08_MA_training %>%
  mutate(stage = case_when(stage == "stage 1" ~ "Stage 1",
                           stage == "stage 2" ~ "Stage 2"))
```

@fig-trainingExp3 shows the mean PPR for each group across the four blocks of training. All participants showed a similar increase in PPR in stage 1, reaching a PPR of around 0.93 on block 6. In Stage 2, group Certain showed a similar PPR to block 6, but the Uncertain group showed a decrease in PPR to a level of around 0.85.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-trainingExp3
#| fig-cap: PPR on the training phase of Experiment 3.
#| apa-note: "Mean proportion of probable responses (±SEM) during the training phase of Experiment 3, plotted against the ten blocks of trials, for each Group."
#| fig-height: 4
ggplot(UNM08_MA_training, mapping = aes(x = block, y = mean_accuracy, group = condition)) +
  geom_point(mapping = aes(shape = condition, color = condition), size = 2.5) +
  geom_line(mapping = aes(color = condition)) +
  geom_errorbar(aes(x= block, y = mean_accuracy, ymin = mean_accuracy-se_accuracy, ymax = mean_accuracy+se_accuracy), colour = "black", width=.1)+
  facet_grid(cols = vars(stage), space = "free_x", scales = "free_x") + 
  scale_x_continuous(name = "Block", breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) + 
  scale_color_discrete(type = c("#AF8DC3", "#FEB24C", "#7FBF7B"))+
  labs(shape = "Group", color = "Group") +
  scale_y_continuous(name = "PPR", limits = c(0.5, 1))+
  theme_apa()
```

```{r, include=FALSE}
#ANOVA
UNM08_acc_stage1 <- filter(UNM08_training, stage == "stage 1") %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
UNM08_acc_stage1$block <- factor(UNM08_acc_stage1$block)
UNM08_acc_stage1$pNum <- factor(UNM08_acc_stage1$pNum)
UNM08_acc_stage1$condition <- factor(UNM08_acc_stage1$condition)
ANOVA_UNM08_acc_stage1 <- aov_car(formula = mean_response ~ condition + Error(pNum/block), data = UNM08_acc_stage1)
print(ANOVA_UNM08_acc_stage1)
#Bayesian Anova
bay_ANOVA_UNM08_acc_stage1 <- anovaBF(formula = mean_response ~ condition + block + pNum,
        data = data.frame(UNM08_acc_stage1),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM08_acc_stage1)
bay_ANOVA_UNM08_acc_stage1_int <- bay_ANOVA_UNM08_acc_stage1[4]/bay_ANOVA_UNM08_acc_stage1[3]
print(bay_ANOVA_UNM08_acc_stage1_int)
```

The Stage 1 data were analysed with a mixed-model ANOVA (with the degrees of freedom corrected by Greenhouse-Geisser when the sphericity assumption was not fulfilled), with the between-subjects factor of *group* (Certain Long, Certain Short, and Uncertain), and the within-subjects factor of *block* (1-6). This revealed a significant effect of block, with extreme Bayesian evidence for the alternative hypothesis, `r apa(ANOVA_UNM08_acc_stage1, effect = "block")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc_stage1[1], sci_not = TRUE)`. There was no effect of *group*, with strong evidence for the null hypothesis, `r apa(ANOVA_UNM08_acc_stage1, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc_stage1[2])`, and no interaction effect, with extreme evidence for the null hypothesis, `r apa(ANOVA_UNM08_acc_stage1, effect = "condition:block")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc_stage1_int[1])`.

```{r, include=FALSE}
#ANOVA
UNM08_acc <- filter(UNM08_training, condition == "Certain Long" | condition == "Uncertain") %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
UNM08_acc$block <- factor(UNM08_acc$block)
UNM08_acc$pNum <- factor(UNM08_acc$pNum)
UNM08_acc$condition <- factor(UNM08_acc$condition)
ANOVA_UNM08_acc <- aov_car(formula = mean_response ~ condition + Error(pNum/block), data = UNM08_acc)
print(ANOVA_UNM08_acc)
#Bayesian Anova
bay_ANOVA_UNM08_acc <- anovaBF(formula = mean_response ~ condition + block + pNum,
        data = data.frame(UNM08_acc),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM08_acc)
bay_ANOVA_UNM08_acc_int <- bay_ANOVA_UNM08_acc[4]/bay_ANOVA_UNM08_acc[3]
print(bay_ANOVA_UNM08_acc_int)
```

```{r, include=FALSE}
# Pairwise comparisons for the interaction analysis
resp_interaction <- emmeans(ANOVA_UNM08_acc, ~condition|block)
pairs(resp_interaction, adjust = "bon")

UNM08_acc__block1_cert <- subset(UNM08_acc, (condition == "Certain Long") & (block == 1), mean_response, drop = TRUE)
UNM08_acc__block1_uncert <- subset(UNM08_acc, (condition == "Uncertain") & (block == 1), mean_response, drop = TRUE)
bay_t.test_UNM08_int_block1 <-  ttestBF(UNM08_acc__block1_cert, UNM08_acc__block1_uncert)
print(bay_t.test_UNM08_int_block1)

UNM08_acc__block2_cert <- subset(UNM08_acc, (condition == "Certain Long") & (block == 2), mean_response, drop = TRUE)
UNM08_acc__block2_uncert <- subset(UNM08_acc, (condition == "Uncertain") & (block == 2), mean_response, drop = TRUE)
bay_t.test_UNM08_int_block2 <-  ttestBF(UNM08_acc__block2_cert, UNM08_acc__block2_uncert)
print(bay_t.test_UNM08_int_block2)

UNM08_acc__block3_cert <- subset(UNM08_acc, (condition == "Certain Long") & (block == 3), mean_response, drop = TRUE)
UNM08_acc__block3_uncert <- subset(UNM08_acc, (condition == "Uncertain") & (block == 3), mean_response, drop = TRUE)
bay_t.test_UNM08_int_block3 <-  ttestBF(UNM08_acc__block3_cert, UNM08_acc__block3_uncert)
print(bay_t.test_UNM08_int_block3)

UNM08_acc__block4_cert <- subset(UNM08_acc, (condition == "Certain Long") & (block == 4), mean_response, drop = TRUE)
UNM08_acc__block4_uncert <- subset(UNM08_acc, (condition == "Uncertain") & (block == 4), mean_response, drop = TRUE)
bay_t.test_UNM08_int_block4 <-  ttestBF(UNM08_acc__block4_cert, UNM08_acc__block4_uncert)
print(bay_t.test_UNM08_int_block4)

UNM08_acc__block5_cert <- subset(UNM08_acc, (condition == "Certain Long") & (block == 5), mean_response, drop = TRUE)
UNM08_acc__block5_uncert <- subset(UNM08_acc, (condition == "Uncertain") & (block == 5), mean_response, drop = TRUE)
bay_t.test_UNM08_int_block5 <-  ttestBF(UNM08_acc__block5_cert, UNM08_acc__block5_uncert)
print(bay_t.test_UNM08_int_block5)

UNM08_acc__block6_cert <- subset(UNM08_acc, (condition == "Certain Long") & (block == 6), mean_response, drop = TRUE)
UNM08_acc__block6_uncert <- subset(UNM08_acc, (condition == "Uncertain") & (block == 6), mean_response, drop = TRUE)
bay_t.test_UNM08_int_block6 <-  ttestBF(UNM08_acc__block6_cert, UNM08_acc__block6_uncert)
print(bay_t.test_UNM08_int_block6)

UNM08_acc__block7_cert <- subset(UNM08_acc, (condition == "Certain Long") & (block == 7), mean_response, drop = TRUE)
UNM08_acc__block7_uncert <- subset(UNM08_acc, (condition == "Uncertain") & (block == 7), mean_response, drop = TRUE)
bay_t.test_UNM08_int_block7 <-  ttestBF(UNM08_acc__block7_cert, UNM08_acc__block7_uncert)
print(bay_t.test_UNM08_int_block7)

UNM08_acc__block8_cert <- subset(UNM08_acc, (condition == "Certain Long") & (block == 8), mean_response, drop = TRUE)
UNM08_acc__block8_uncert <- subset(UNM08_acc, (condition == "Uncertain") & (block == 8), mean_response, drop = TRUE)
bay_t.test_UNM08_int_block8 <-  ttestBF(UNM08_acc__block8_cert, UNM08_acc__block8_uncert)
print(bay_t.test_UNM08_int_block8)

UNM08_acc__block9_cert <- subset(UNM08_acc, (condition == "Certain Long") & (block == 9), mean_response, drop = TRUE)
UNM08_acc__block9_uncert <- subset(UNM08_acc, (condition == "Uncertain") & (block == 9), mean_response, drop = TRUE)
bay_t.test_UNM08_int_block9 <-  ttestBF(UNM08_acc__block9_cert, UNM08_acc__block9_uncert)
print(bay_t.test_UNM08_int_block9)

UNM08_acc__block10_cert <- subset(UNM08_acc, (condition == "Certain Long") & (block == 10), mean_response, drop = TRUE)
UNM08_acc__block10_uncert <- subset(UNM08_acc, (condition == "Uncertain") & (block == 10), mean_response, drop = TRUE)
bay_t.test_UNM08_int_block10 <-  ttestBF(UNM08_acc__block10_cert, UNM08_acc__block10_uncert)
print(bay_t.test_UNM08_int_block10)
```

The data from Stage 1 and 2 were analysed with a mixed model ANOVA (using the Greenhouse-Geisser correction when needed), with the between-subjects factor of *group* (Certain Long vs Uncertain) and the within-subjects factor of *block* (1-10). There was no effect of *group*, with anecdotal Bayesian evidence for the null hypothesis, `r apa(ANOVA_UNM08_acc, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc[2])`, but there was a significant effect of *block* with extreme Bayesian evidence for the alternative hypothesis, `r apa(ANOVA_UNM07_acc, effect = "block")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc[1], sci_not = TRUE)`, and a significant group by block interaction, with extreme Bayesian evidence for the alternative hypothesis, `r apa(ANOVA_UNM08_acc, effect = "condition:block")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc_int[1])`. Bonferroni-corrected comparisons showed that the Uncertain group had a lower PPR on the Stage 2 blocks, *t*(58) \> 3.27, *p* \< .002, `r report_BF_and_error(bay_t.test_UNM08_int_block6)`, but no differences in the Stage 1 blocks, *t*(58) \< 1.15, *p* \> .254, `r report_BF_and_error(bay_t.test_UNM08_int_block7)`.

Taken together, these results indicate that the training in Stage 1 increased the PPR for all groups in the same fashion, in Stage 1, while in Stage 2, the Certain Long group showed a consistently higher PPR than the Uncertain group.

```{r, include=FALSE}
#Calculate the mean accuracy and standard error for each block, including the groups
MA_UNM08_test <- UNM08_test %>%
  group_by(trial_type, condition) %>%
    summarise(mean_acc = mean(acc, na.rm = TRUE), 
            se_acc = sd(acc, na.rm = TRUE)/sqrt(length(acc)))
```

@fig-acctestExp3 shows the accuracy results from the recognition memory test. Accuracy for non-predictive cues was lower than for the predictive cues in the Certain group, but this difference was not present in the Uncertain group. Also, accuracy was similar in both groups.

```{r, echo=FALSE, message=FALSE}
#| label: fig-acctestExp3
#| fig-cap: Accuracy on the test phase of Experiment 3.
#| apa-note: "Mean accuracy (±SEM) during the test phase of Experiment 3 across the three groups."
#| fig-height: 4
ggplot(data = MA_UNM08_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain Short','Certain Long')), y = mean_acc, fill = trial_type)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(y= mean_acc, ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width = .2, position = position_dodge(0.9)) +
  coord_cartesian(ylim = c(0, 1))+
  scale_x_discrete (name = "Type of test") +
  scale_y_continuous(name = "Accuracy") +
  coord_cartesian(ylim = c(0.5, 1)) +
  scale_fill_discrete(type = c("#7B3294", "#C2A5CF", "#008837", "#A6DBA0"))
```

```{r, include=FALSE}
#ANOVA accuracy
acc_UNM08_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness, congruence) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
acc_UNM08_test$predictiveness <- factor(acc_UNM08_test$predictiveness)
acc_UNM08_test$condition <- factor(acc_UNM08_test$condition)
acc_UNM08_test$pNum <- factor(acc_UNM08_test$pNum)
acc_UNM08_test$congruence <- factor(acc_UNM08_test$congruence)
ANOVA_acc_UNM08_test <- aov_car(formula = acc ~ condition + Error(pNum*predictiveness*congruence), data = acc_UNM08_test)
print(ANOVA_acc_UNM08_test)

bay_ANOVA_acc_UNM08_test <- anovaBF(formula = acc ~ condition*predictiveness*congruence + pNum,
        data = data.frame(acc_UNM08_test),
        whichRandom = "pNum")
print(bay_ANOVA_acc_UNM08_test)

bay_ANOVA_acc_UNM08_test_gxp <- bay_ANOVA_acc_UNM08_test[4]/bay_ANOVA_acc_UNM08_test[3]
print(bay_ANOVA_acc_UNM08_test_gxp)
bay_ANOVA_acc_UNM08_test_pxc <- bay_ANOVA_acc_UNM08_test[13]/bay_ANOVA_acc_UNM08_test[7]
print(bay_ANOVA_acc_UNM08_test_pxc)
bay_ANOVA_acc_UNM08_test_sxc <- bay_ANOVA_acc_UNM08_test[10]/bay_ANOVA_acc_UNM08_test[6]
print(bay_ANOVA_acc_UNM08_test_sxc)
bay_ANOVA_acc_UNM08_test_gxpxc <- bay_ANOVA_acc_UNM08_test[18]/bay_ANOVA_acc_UNM08_test[17]
print(bay_ANOVA_acc_UNM08_test_gxpxc)
```

```{r, include = FALSE}
# Pairwise comparisons for the interaction analysis
acc_interaction <- emmeans(ANOVA_acc_UNM08_test, ~condition)
pairs(acc_interaction, adjust = "bon")

# SME of predictiveness:congruence interaction
SME_acc_UM08_pxc <- UNM08_test %>%
  group_by (pNum, congruence, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
#calculate the simple main effect of congruence
SME_acc_UM08_pxc_congruence <- SME_acc_UM08_pxc %>%
  group_by(predictiveness) %>%
  anova_test(acc ~ congruence + Error(pNum/congruence), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
SME_acc_UM08_pxc_congruence #Call the output table
#calculate the simple main effect of predictiveness
SME_acc_UM08_pxc_pred <- SME_acc_UM08_pxc %>%
  group_by(congruence) %>%
  anova_test(acc ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
SME_acc_UM08_pxc_pred #Call the output table
```

There was a significant main effect of the *group*, `r apa(ANOVA_acc_UNM08_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test[1])`, and a main effect of *predictiveness*: `r apa(ANOVA_acc_UNM08_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test[2])`, as well as a significant *predictiveness x congruence* interaction, `r apa(ANOVA_acc_UNM08_test, effect = "predictiveness:congruence")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test_pxc[1])`. All other effects and interactions were non significant: *congruence*: `r apa(ANOVA_acc_UNM08_test, effect ="congruence")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test[5])`; *group x predictiveness* interaction, `r apa(ANOVA_acc_UNM08_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test_gxp[1])`; *group x congruence*: `r apa(ANOVA_acc_UNM08_test, effect = "condition:congruence")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test_sxc[1])`; *group x predictiveness x congruence*: `r apa(ANOVA_acc_UNM08_test, effect = "condition:predictiveness:congruence")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test_gxpxc[1])`. Bonferroni corrected pairwise comparisons showed significant differences of the group Uncertain with the group Certain Long, *t*(145) = 2.622, *p* = .029, and with the group Certain Short, *t*(145) = 2.596, *p* = .031, but not between the groups Certain Long and Certain Short, *t*(145) = 0.017, *p* = 1. Also, the simple main effects for the *predictiveness x congruence* interaction showed an effect in predictiveness in the incongruent trials, *F* (`r SME_acc_UM08_pxc_pred[2,3]`, `r SME_acc_UM08_pxc_pred[2,4]`) = `r SME_acc_UM08_pxc_pred[2,5]`, *p* = `r SME_acc_UM08_pxc_pred[2,9]`, $\\eta^2_p$ = `r SME_acc_UM08_pxc_pred[2,8]`, but not on the congruent trials, *F* (`r SME_acc_UM08_pxc_pred[1,3]`, `r SME_acc_UM08_pxc_pred[1,4]`) = `r SME_acc_UM08_pxc_pred[1,5]`, *p* = `r SME_acc_UM08_pxc_pred[1,9]`, $\\eta^2_p$ = `r SME_acc_UM08_pxc_pred[1,8]`.

```{r, include = FALSE}
#create the memory_score
UNM08_test <- UNM08_test %>%
  mutate (c_mem_score = case_when(acc == 0 ~ 0, acc == 1 ~ mem_score))
#Calculate the mean PPR and standard error for each block, including the groups
UNM08_MS_test <- UNM08_test %>%
  group_by(trial_type, condition) %>%
    summarise(mean_mem_score = mean(c_mem_score, na.rm = TRUE), 
            se_mem_score = sd(c_mem_score, na.rm = TRUE)/sqrt(length(c_mem_score)))
```

@fig-testExp3 shows the recognition memory data for the three conditions. Memory for non-predictive cues was lower than for predictive cues in all groups, but this difference was notably attenuated in the Uncertain group. Interestingly, the memory for the cues in the Uncertain group was higher, overall, than in the Certain Long and Certain Short groups.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-testExp3
#| fig-cap: Memory scores on the Test of Experiment 3.
#| apa-note: "Mean memory scores (±SEM) during the Test of Experiment 2 for predictive and non-predictive trials across the three groups."
#| fig-height: 4
ggplot(UNM08_MS_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain Short', 'Certain Long')), y = mean_mem_score, fill = trial_type)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(ymin = mean_mem_score - se_mem_score, ymax = mean_mem_score + se_mem_score), width=.2, position=position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_fill_discrete(type = c("#7B3294", "#C2A5CF", "#008837", "#A6DBA0"))+
  scale_y_continuous(name = "Memory score")+
  #scale_fill_grey(start = 0.33) +
  theme_apa()
```

```{r, include=FALSE}
#ANOVA mem_score
UNM08_memscore_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness, congruence) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
UNM08_memscore_test$predictiveness <- factor(UNM08_memscore_test$predictiveness)
UNM08_memscore_test$congruence <- factor(UNM08_memscore_test$congruence)
UNM08_memscore_test$condition <- factor(UNM08_memscore_test$condition)
UNM08_memscore_test$pNum <- factor(UNM08_memscore_test$pNum)
ANOVA_UNM08_test <- aov_car(formula = mem_score ~ condition + Error(pNum*predictiveness*congruence), data = UNM08_memscore_test)
print(ANOVA_UNM08_test)
bay_ANOVA_UNM08_test <- anovaBF(formula = mem_score ~ condition + predictiveness + congruence,
        data = data.frame(UNM08_memscore_test),
        whichRandom = "pNum")
print(bay_ANOVA_UNM08_test)
bay_ANOVA_UNM08_test_gxp <- bay_ANOVA_UNM08_test[4]/bay_ANOVA_UNM08_test[3]
print(bay_ANOVA_UNM08_test_gxp)
bay_ANOVA_UNM08_test_pxc <- bay_ANOVA_UNM08_test[13]/bay_ANOVA_UNM08_test[7]
print(bay_ANOVA_UNM08_test_pxc)
bay_ANOVA_UNM08_test_sxc <- bay_ANOVA_UNM08_test[10]/bay_ANOVA_UNM08_test[6]
print(bay_ANOVA_UNM08_test_sxc)
bay_ANOVA_UNM08_test_gxpxc <- bay_ANOVA_UNM08_test[18]/bay_ANOVA_UNM08_test[17]
print(bay_ANOVA_UNM08_test_gxpxc)
```

```{r, include = FALSE}

# Pairwise comparisons for the main effect of condition
UNM08_test_interaction <- emmeans(ANOVA_UNM08_test, ~condition)
contrast(UNM08_test_interaction, adjust = "bon", "trt.vs.ctrl", ref = c(1,2))

UNM08_test_certs <- subset(UNM08_memscore_test, (condition == "Certain Long") | (condition == "Certain Short"), mem_score, drop = TRUE)
UNM08_test_uncert <- subset(UNM08_memscore_test, condition == "Uncertain", mem_score, drop = TRUE)
bay_t.test_UNM08_int_uncer_vs_certs <-  ttestBF(UNM08_test_certs, UNM08_test_uncert)
print(bay_t.test_UNM08_int_uncer_vs_certs)

pairs(UNM08_test_interaction, adjust = "bon")

UNM08_test_cert <- subset(UNM08_memscore_test, condition == "Certain Long", mem_score, drop = TRUE)
UNM08_test_cert_s <- subset(UNM08_memscore_test, condition == "Certain Short", mem_score, drop = TRUE)
bay_t.test_UNM08_test_certs <-  ttestBF(UNM08_test_cert, UNM08_test_cert_s)
print(bay_t.test_UNM08_test_certs)
```


```{r, include = FALSE}
SME_UNM08_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
#calculate the simple main effect of condition
sme_UNM08_test_condition <- SME_UNM08_test %>%
  group_by(predictiveness) %>%
  anova_test(mem_score ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_UNM08_test_condition #Call the output table
#calculate the simple main effect of predictiveness
sme_UNM08_test_pred <- SME_UNM08_test %>%
  group_by(condition) %>%
  anova_test(mem_score ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_UNM08_test_pred #Call the output table

# SME of predictiveness:congruence interaction
SME_acc_UM08_pxc <- UNM08_test %>%
  group_by (pNum, congruence, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
#calculate the simple main effect of congruence
SME_acc_UM08_pxc_congruence <- SME_acc_UM08_pxc %>%
  group_by(predictiveness) %>%
  anova_test(mem_score ~ congruence + Error(pNum/congruence), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
SME_acc_UM08_pxc_congruence #Call the output table
#calculate the simple main effect of predictiveness
SME_acc_UM08_pxc_pred <- SME_acc_UM08_pxc %>%
  group_by(congruence) %>%
  anova_test(mem_score ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
SME_acc_UM08_pxc_pred #Call the output table
```
A mixed model ANOVA, including the between-subjects factor *group* (Certain Long, Certain Short, Uncertain), and the within-subjects factor *predictiveness* (predictive vs non-predictive) and *congruence* showed a significant main effect of the *group*`r apa(ANOVA_UNM08_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM08_test[1])` and a main effect of *predictiveness*, with extreme Bayesian evidence for the alternative hypothesis,, `r apa(ANOVA_UNM08_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM08_test[2])`, as well as the *group x predictiveness* interaction, `r apa(ANOVA_UNM08_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM08_test_gxp[1])` and the *predictiveness x congruence* interaction, `r apa(ANOVA_UNM08_test, effect = "predictiveness:congruence")`, `r report_BF_and_error(bay_ANOVA_UNM08_test_pxc[1])`. Bonferroni corrected post-hoc comparisons on the factor of group showed that group Uncertain differed significantly from the average of the Certain groups, *t*(87) = 1.18, *p* = .004, `r report_BF_and_error(bay_t.test_UNM08_int_uncer_vs_certs)`, but memory scores for the two Certain groups did not differ the one from the other, *t*(87) = 0.188, *p* = 1, `r report_BF_and_error(bay_t.test_UNM08_test_certs)`, with the Bayesian evidence suggesting that memory performance was the same in these two groups.

These results indicate that memory for predictive cues was better than for non-predictive cues independently of the contingencies that were presented at training. However, those participants that experienced an unexpected period of uncertainty showed generally better memory than the Certain groups.

## 4.3 Discussion

Experiment 3 examined the effect of unexpected uncertainty on recognition memory. The “Uncertain” group of participants first experienced a period of training with certain contingencies, before receiving a second period with uncertain contingencies. Participants that were exposed to this unexpected uncertainty showed a higher level of recognition memory for the cues than participants that received only certain training. An important difference between Experiment 2 and 3 is that in Experiment 2, the Certain and Uncertain groups had a similar recognition memory for the cues, whereas in the current experiment, the Uncertain group showed better cue-recognition. We interpret this difference to be a consequence of the expectancy of uncertainty: in Experiment 3, but not Experiment 2, uncertainty is suddenly introduced after a sustained period of certain training.

These results suggest that introducing a period of unexpected uncertainty results in enhanced cue processing and are consistent with previous results [@easdaleOnsetUncertaintyFacilitates2019] that showed that unexpected uncertainty enhanced learning. Easdale et al. used a training phase with participants learning about either certain or uncertain contingencies. Participants showed better attention to uncertain cues. However, when those cues were subsequently trained under new contingencies, it was participants in the certain condition that learned about these more rapidly, compared to those participants in the uncertain condition. Easdale et al. suggested that the transition from certain to uncertain contingencies brought about a state of “unexpected uncertainty” which promoted new learning. Experiment 3 shows more directly that a period of unexpected uncertainty leads to superior cue processing and stronger memory representations.
