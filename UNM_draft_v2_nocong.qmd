---
title: "Effects of expected and unexpected uncertainty on cue processing"
# If blank, the running header is the title in upper case.
shorttitle: "Effects of uncertainty on cue processing"
# Set names and affiliations.
# It is nice to specify everyone's orcid, if possible.
# There can be only one corresponding author, but declaring one is optional.
author:
  - name: Clara Mu√±iz-Diez
    corresponding: true
    orcid: 0000-0001-5192-0462
    email: c.muniz-diez@lancaster.ac.uk
    # Roles are optional. 
    # Select from the CRediT: Contributor Roles Taxonomy https://credit.niso.org/
    # conceptualization, data curation, formal Analysis, funding acquisition, investigation, 
    # methodology, project administration, resources, software, supervision, validation, 
    # visualization, writing, editing
    affiliations:
      - id: id1
        name: "Lancaster University"
        department: Department of Psychology
        city: Lancaster
        region: UK
  - name: Sandra Lagator
    orcid: 0000-0001-6060-2941
    affiliations: 
      - id: id2
        name: "The University of Nottingham"
        department: School of Psychology
        city: Nottingham
        region: UK
  - name: Mark Haselgrove
    orcid: 0000-0001-8981-1181
    affiliations:
      - ref: id2
  - name: Tom Beesley
    orcid: 0000-0003-2836-2743
    # List city and region/state for unaffiliated authors
    affiliations:
      - ref: id1
author-note:
  status-changes: 
    # Example: [Author name] is now at [affiliation].
    affiliation-change: ~
    # Example: [Author name] is deceased.
    deceased: ~
  # Disclosures condensed to one paragraph, but you can start a field with two line breaks to break them up: \n\nNew Paragraph
  disclosures:
    # Example: This study was registered at X (Identifier Y).
    study-registration: ~
    # Acknowledge and cite data/materials to be shared.
    data-sharing: "The programs of the experiments presented here, the data and the full code for the writing this manuscript are freely available on www.github.com/munizdiezclara/UNM_draft."
    # Example: This article is based on data published in [Reference].
    # Example: This article is based on the dissertation completed by [citation].  
    related-report: ~
    # Example: [Author name] has been a paid consultant for Corporation X, which funded this study.
    conflict-of-interest: ~
    # Example: This study was supported by Grant [Grant Number] from [Funding Source].
    financial-support: "This study was supported by the ESRC grant Known unknowns and unknown unknowns (ES/W013215/1)." 
    # Example: The authors are grateful to [Person] for [Reason].
    gratitude: ~
    # Example. Because the authors are equal contributors, order of authorship was determined by a fair coin toss.
    authorship-agreements: ~
abstract: "Learning influences the overt attention that is paid to stimuli in two main ways: first, stimuli which are reliable predictors of an outcome are paid more attention than unreliable stimuli; and second, stimuli associated with uncertain outcomes capture more attention than stimuli associated with certain outcomes. Past studies have shown that these two phenomena can be demonstrated within the same experiment, but strikingly, the increase in attention due to uncertainty does not necessarily translate into subsequent better learning. We investigate this paradox by examining stimulus processing in three experiments that included predictive and non-predictive cues, trained under different conditions of uncertainty. In Experiment 1, this test revealed that recognition  memory was similar after learning with certain and uncertain stimulus-outcome contingencies. In Experiment 2, uncertain contingencies were introduced after a period of learning with certain contingencies. During the subsequent memory test, this training resulted in better memory than training with certain contingencies throughout the learning phase. These results suggest the importance of drawing a distinction between expected and unexpected uncertainty on stimulus processing. The implications of these results for attentional models of learning are discussed."
# Put as many keywords at you like, separated by commmas (e.g., [reliability, validity, generalizability])
keywords: [Associative Learning, Attention, Uncertainty, Predictiveness, Cue processing]
# If true, tables and figures are mingled with the text instead of listed at the end of the document.
floatsintext: true
# Numbered lines (.pdf and .docx only)
numbered-lines: false
# File with references
bibliography: references.bib
# Suppress title page
suppress-title-page: false
# Masks references that appear in the masked-citations list
mask: false
masked-citations:
  - schneider2012cattell
  - schneider2015intelligence
# Language options. See https://quarto.org/docs/authoring/language.html
lang: en
language:
  citation-last-author-separator: "and"
  citation-masked-author: "Masked Citation"
  citation-masked-date: "n.d."
  citation-masked-title: "Masked Title"
  title-block-author-note: "Author Note"
  title-block-correspondence-note: "Correspondence concerning this article should be addressed to"
  title-block-role-introduction: "Author roles were classified using the Contributor Role Taxonomy (CRediT; https://credit.niso.org/) as follows:"
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-pdf:
    # Can be jou (journal), man (manuscript), stu (student), or doc (document)
    documentmode: man
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(afex)
library(BayesFactor)
library(apa)
library(emmeans)
library(papaja)
library(rstatix)
library("writexl")
options(scipen=999)
bfit = 5000

# function to force scientific formatting of numbers (used for large BFs)
changeSciNot <- function(n) {
  output <- format(n, scientific = TRUE, digits = 2) #Transforms the number into scientific notation even if small
  output <- sub("e", "x10^", output) #Replace e with 10^
  output <- sub("\\+0?", "", output) #Remove + symbol and leading zeros on exponent, if > 1
  output <- sub("-0?", "-", output) #Leaves - symbol but removes leading zeros on exponent, if < 1
  output <- paste0(output,"^")
  # output = strsplit(output, "^", fixed = TRUE)
  # output = paste0(output[[1]][1],"^", output[[1]][2], "^")
  output
}
# function to extract and report BFs with error %s
report_BF_and_error <- function(BF_in, sci_not = FALSE, hyp = "alt"){
  
  if (hyp == "alt") {
    BF_notation = "BF~10~ = "
  } else if (hyp == "null") {
    BF_notation = "BF~01~ = "
  }
  
  if (sci_not == TRUE) {
    BF_value = changeSciNot(extractBF(BF_in)$bf) # change to sci notation
  } else {
    BF_value = round(extractBF(BF_in)$bf,2) # otherwise round
  }
  
  paste0(BF_notation, 
         BF_value, 
         " &plusmn; ", 
         round(100*extractBF(BF_in)$error,2), 
         "%")
}
```

# Experiment 1

The purpose of Experiment 1 was to examine differences in recognition memory in a learned predictiveness procedure under certain and uncertain cue-outcome contingency conditions. Two groups were trained, one with a perfect contingency between the predictive cues and their paired outcome (Group Certain) and one with a contingency of 0.8 between the predictive cues and their paired outcome (Group Uncertain). After this training, we tested the memory for cues in both groups using the memory test in which targets were paired with foils from different cues.

The design of Experiment 1 is shown in @tbl-exp1. Previous experiments have established that for uncertain contingencies, participants spend longer attending to (looking at) all cues compared to attention to cues in certain contingencies [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019; @walkerProtectionUncertaintyExploration2022]. Experiment 1 therefore aimed to test whether uncertain contingencies, where it is well established that there is a high level of attention to cues, result in an improvement in the processing of these stimuli. As such, we predicted that memory would be better, overall, for the cues in group Uncertain compared to group Certain. Also, on the basis of the better attention found to predictive than non-predictive cues in the learned predictiveness effect, we anticipate seeing superior memory scores for the predictive than the non-predictive cues in group Certain.

::: {#tbl-exp1 apa-note="Uppercase letters A, B, X, and Y represent the cues presented during training. O1 and O2 represent the outcomes presented in training. Lowercase letters a, b, x, and y represent the foils that are similar to the (corresponding upper-case letter) cues presented in the training phase. The numbers before the trials define the proportion of trials of that type that were presented." apa-twocolumn="true"}
+----------------+---------------------------+------------------+
| Group          | Training                  | Test             |
+================+:=========================:+:================:+
| Certain        | AX - O1                   | A vs *b*/*x*/*y* |
|                |                           |                  |
|                | AY - O1                   | B vs *a*/*x*/*y* |
|                |                           |                  |
|                | BX - O2                   | X vs *a*/*b*/*y* |
|                |                           |                  |
|                | BY - O2                   | Y vs *a*/*b*/*x* |
+----------------+---------------------------+------------------+
| Uncertain      | 0.8 AX - O1 / 0.2 AX - O2 | A vs *b*/*x*/*y* |
|                |                           |                  |
|                | 0.8 AY - O1 / 0.2 AY - O2 | B vs *a*/*x*/*y* |
|                |                           |                  |
|                | 0.8 BX - O2 / 0.2 BX - O1 | X vs *a*/*b*/*y* |
|                |                           |                  |
|                | 0.8 BY - O2 / 0.2 BY - O1 | Y vs *a*/*b*/*x* |
+----------------+---------------------------+------------------+

Design of Experiment 1
:::

## Methods

### Participants

```{r, include=FALSE}
#load the data
load("UNM07_proc_data.RData")
UNM07_demographics <- demographics
UNM07_training <- training
UNM07_test <- test
UNM07_not_passed <- not_passed_pNum

#create the PPR measure
UNM07_training <- UNM07_training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0, 
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1))

#detect and clean participants that not passed the test comprehension check
UNM07_training <- filter(UNM07_training, !pNum %in% UNM07_not_passed$pNum)
UNM07_test <- filter(UNM07_test, !pNum %in% UNM07_not_passed$pNum)
```

`r nrow(UNM07_demographics)` participants were recruited through Prolific. The sample consisted of `r length(which(UNM07_demographics$gender == "female"))` women, `r length(which(UNM07_demographics$gender == "male"))` men and one non-binary person, with `r n_distinct(UNM07_demographics$Nationality)` different nationalities. The mean age was `r format(mean(UNM07_demographics$age, na.rm = TRUE), digits = 3)` calculated for the `r nrow(UNM07_demographics) - sum(is.na(UNM07_demographics$age))` participants that reported their age (range `r min(UNM07_demographics$age, na.rm = TRUE)` - `r max(UNM07_demographics$age, na.rm = TRUE)`). Pre-screening of participants in Prolific ensured that they had normal or corrected to normal vision, fluency in English language, and had not participated in previous studies from our lab. Participants were rewarded with ¬£2.70 for their participation in the study. Participants were randomly allocated to either the Certain or Uncertain condition. Four participants were excluded due to failing the comprehension check before the test (three in group Certain and one in group Uncertain). Post-hoc calculations using G\*Power 3.1 [@faulStatisticalPowerAnalyses2007] revealed that this sample size had a power of .99 to detect an effect size of *Œ∑~p~^2^* = .08 that was observed for the *group x predictiveness* interaction reported in @fig-testExp1.

## Results

Since participants in the uncertain condition received trials in which the alternative outcome was presented on 20% of the trials, even if participants in group Uncertain were to always select the most probable outcome (O1 when A is present and O2 when B is present), it would result in an accuracy score of 80%. Thus, we calculated the proportion of probable responses (PPR): for the Uncertain group, on each trial, the score was 0 when participants chose the less probable outcome (i.e., O2 for A and O1 for B) and 1 when they chose the most probable outcome (i.e., O1 for A and O2 for B). For the certain condition, this equates to a standard accuracy score.

```{r, include = FALSE}
#Calculate the mean PPR and standard error for each block, including the groups
UNM07_MA_training <- UNM07_training %>%
  group_by(block, condition) %>%
  summarise(mean_accuracy = mean(prob_response, na.rm = TRUE), 
            se_accuracy = sd(prob_response, na.rm = TRUE)/sqrt(length(prob_response)))
```

@fig-trainingExp1 shows the mean PPR across blocks for each group. Participants in the Certain group showed a higher PPR through training than the Uncertain group, reaching a PPR of about 0.85 on block 8. The Uncertain group showed consistently lower PPR, that reached approximately 0.7 in block 8.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-trainingExp1
#| fig-cap: PPR on the training phase of Experiment 1.
#| apa-note: "Mean proportion of probable responses (¬±SEM) during the training phase of Experiment 1, for groups trained with certain and uncertain contingencies."
#| fig-height: 4
ggplot(UNM07_MA_training, mapping = aes(x = block, y = mean_accuracy, group = condition, color = condition)) +
  geom_point(mapping = aes(shape = condition), size = 2.5) +
  geom_line() +
  geom_errorbar(aes(x= block, y = mean_accuracy, ymin = mean_accuracy-se_accuracy, ymax = mean_accuracy+se_accuracy), colour = "black", width=.1)+
  scale_x_continuous(name = "Block") + 
  labs(shape = "Group", colour = "Group") +
  scale_color_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  scale_x_continuous(breaks = c(1, 2, 3, 4, 5, 6, 7, 8))+
  scale_y_continuous(name = "PPR", limits = c(NA, 1))+
  theme_apa()
```

```{r, include=FALSE}
#ANOVA
UNM07_acc <- UNM07_training %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
UNM07_acc$block <- factor(UNM07_acc$block)
UNM07_acc$pNum <- factor(UNM07_acc$pNum)
UNM07_acc$condition <- factor(UNM07_acc$condition)
ANOVA_UNM07_acc <- aov_car(formula = mean_response ~ condition + Error(pNum/block), data = UNM07_acc)
print(ANOVA_UNM07_acc)
#Bayesian Anova
bay_ANOVA_UNM07_acc <- anovaBF(formula = mean_response ~ condition + block + pNum,
        data = data.frame(UNM07_acc),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM07_acc)
bay_ANOVA_UNM07_acc_int <- bay_ANOVA_UNM07_acc[4]/bay_ANOVA_UNM07_acc[3]
print(bay_ANOVA_UNM07_acc_int)
```

This data were analysed with a mixed model ANOVA including the between-subjects factor * group* and the within-subjects factor *predictiveness*. This ANOVA (and all the following ones in the paper) included the Greenhouse-Geisser correction of the degrees of freedom when the sphericity asumption was not fulfilled. The ANOVA found significant both the main effect of *group*, `r apa(ANOVA_UNM07_acc, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM07_acc[2])`, and of *block*, `r apa(ANOVA_UNM07_acc, effect = "block")`, `r report_BF_and_error(bay_ANOVA_UNM07_acc[1], sci_not = TRUE)`. There was no interaction effect between these factors, `r apa(ANOVA_UNM07_acc, effect = "condition:block")`, `r report_BF_and_error(bay_ANOVA_UNM07_acc_int[1])`. These results indicate that the training increased the PPR for both groups, as the effect of block was significant, with the Certain group showing a consistently higher PPR than Uncertain group.

```{r, include=FALSE}
#Calculate the mean accuracy and standard error for each block, including the groups
MA_test <- UNM07_test %>%
  group_by(condition, predictiveness) %>%
    summarise(mean_acc = mean(acc, na.rm = TRUE), 
            se_acc = sd(acc, na.rm = TRUE)/sqrt(length(acc)))
```

@fig-acctestExp1 shows the accuracy results from the recognition memory test. Accuracy for non-predictive cues was lower than for the predictive cues in the Certain group, but this difference was not present in the Uncertain group. Also, accuracy was similar in both groups.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-acctestExp1
#| fig-cap: Accuracy on the test phase of Experiment 1.
#| apa-note: "Mean accuracy (¬±SEM) during the test phase of Experiment 1, for groups trained with certain and uncertain contingencies."
#| fig-height: 4
ggplot(data = MA_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain')), y = mean_acc, fill = predictiveness)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(y= mean_acc, ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width = .2, position = position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_y_continuous(name = "Accuracy") +
  coord_cartesian(ylim = c(0.5, 1)) +
  scale_fill_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  theme_apa()
```

```{r, include=FALSE}
#ANOVA accuracy
acc_UNM07_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
acc_UNM07_test$predictiveness <- factor(acc_UNM07_test$predictiveness)
acc_UNM07_test$condition <- factor(acc_UNM07_test$condition)
acc_UNM07_test$pNum <- factor(acc_UNM07_test$pNum)
ANOVA_acc_UNM07_test <- aov_car(formula = acc ~ condition + Error(pNum*predictiveness), data = acc_UNM07_test)
print(ANOVA_acc_UNM07_test)

bay_ANOVA_acc_UNM07_test <- anovaBF(formula = acc ~ condition*predictiveness + pNum,
        data = data.frame(acc_UNM07_test),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_acc_UNM07_test)

bay_ANOVA_acc_UNM07_test_gxp <- bay_ANOVA_acc_UNM07_test[4]/bay_ANOVA_acc_UNM07_test[3]
print(bay_ANOVA_acc_UNM07_test_gxp)
```

```{r, include = FALSE}
# SME of the condition:predictiveness interaction
SME_acc_UNM07_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
#calculate the simple main effect of condition
sme_acc_UNM07_test_condition <- SME_acc_UNM07_test %>%
  group_by(predictiveness) %>%
  anova_test(acc ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_acc_UNM07_test_condition #Call the output table
#calculate the simple main effect of predictiveness
sme_acc_UNM07_test_pred <- SME_acc_UNM07_test %>%
  group_by(condition) %>%
  anova_test(acc ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_acc_UNM07_test_pred #Call the output table

SME_acc_UNM07_test_certain <- filter(UNM07_test, condition == "Certain") %>%
  group_by(pNum, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
SME_acc_UNM07_test_certain$predictiveness <- factor(SME_acc_UNM07_test_certain$predictiveness)
SME_acc_UNM07_test_certain$pNum <- factor(SME_acc_UNM07_test_certain$pNum)

SME_acc_UNM07_test_uncertain <- filter(UNM07_test, condition == "Uncertain") %>%
  group_by(pNum, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
SME_acc_UNM07_test_uncertain$predictiveness <- factor(SME_acc_UNM07_test_uncertain$predictiveness)
SME_acc_UNM07_test_uncertain$pNum <- factor(SME_acc_UNM07_test_uncertain$pNum)

bay_SME_acc_UNM07_test_certain <- anovaBF(formula = acc ~ predictiveness + pNum,
        data = data.frame(SME_acc_UNM07_test_certain),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_acc_UNM07_test_certain)
bay_SME_acc_UNM07_test_uncertain <- anovaBF(formula = acc ~ predictiveness + pNum,
        data = data.frame(SME_acc_UNM07_test_uncertain),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_acc_UNM07_test_uncertain)
```

A mixed model ANOVA with the between subjects-factor *group* (Uncertain vs Certain) and the within-subjects factor *predictiveness*, found no significant effect of the main effects (*group*: `r apa(ANOVA_acc_UNM07_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test[1])`; *predictiveness*: `r apa(ANOVA_acc_UNM07_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test[2])`), but a significant *group x predictiveness* interaction, `r apa(ANOVA_acc_UNM07_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM07_test_gxp[1])`. Simple main effects analysis showed a significant effect of predictiveness in group Certain, *F* (`r sme_acc_UNM07_test_pred[1, 3]`, `r sme_acc_UNM07_test_pred[1, 4]`) = `r sme_acc_UNM07_test_pred[1, 5]`, *p* = `r sme_acc_UNM07_test_pred[1, 9]`, *Œ∑~p~^2^* = `r sme_acc_UNM07_test_pred[1, 8]`, `r report_BF_and_error(bay_SME_acc_UNM07_test_certain[1])`,  but not in group Uncertain, *F* (`r sme_acc_UNM07_test_pred[2, 3]`, `r sme_acc_UNM07_test_pred[2, 4]`) = `r sme_acc_UNM07_test_pred[2, 5]`, *p* = `r sme_acc_UNM07_test_pred[2, 9]`, *Œ∑~p~^2^* = `r sme_acc_UNM07_test_pred[2, 8]`, `r report_BF_and_error(bay_SME_acc_UNM07_test_uncertain[1])`. These analyses suggest that group Certain were more accurate at remembering predictive than non-predictive cues, whereas group Uncertain did not show this difference.

```{r, include = FALSE}
#Calculate the mean memory score and standard error for each group and predictiveness of the cues
UNM07_MS_test <- UNM07_test %>%
  group_by(predictiveness, condition) %>%
    summarise(mean_mem_score = mean(c_mem_score, na.rm = TRUE), 
            se_mem_score = sd(c_mem_score, na.rm = TRUE)/sqrt(length(c_mem_score)))
```

Memory scores, calculated as the product of the accuracy score (1 or 0) with the confidence rating given, can be seen in @fig-testExp1. The memory scores for non-predictive cues was lower than for the predictive cues in the Certain group. This difference was notably attenuated in the Uncertain group, and there was no indication of higher memory scores in the uncertain group relative to the Certain group.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-testExp1
#| fig-cap: Memory scores during the Test of Experiment 1.
#| apa-note: "Mean memory scores (¬±SEM) during the Test phase of Experiment 1 for predictive and non-predictive trials in the Certain and Uncertain groups."
#| fig-height: 4
ggplot(UNM07_MS_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain')), y = mean_mem_score, fill = predictiveness)) + #display groups in axis x, memory score in axis y, and fill the bars in different colours depending on predictiveness
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(ymin = mean_mem_score - se_mem_score, ymax = mean_mem_score + se_mem_score), width=.2, position=position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_fill_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  scale_y_continuous(name = "Memory score")+
  #scale_fill_grey(start = 0.33) +
  theme_apa()
```

```{r, include=FALSE}
#ANOVA mem_score
UNM07_memscore_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
UNM07_memscore_test$predictiveness <- factor(UNM07_memscore_test$predictiveness)
UNM07_memscore_test$condition <- factor(UNM07_memscore_test$condition)
UNM07_memscore_test$pNum <- factor(UNM07_memscore_test$pNum)
ANOVA_UNM07_test <- aov_car(formula = mem_score ~ condition + Error(pNum*predictiveness), data = UNM07_memscore_test)
print(ANOVA_UNM07_test)

bay_ANOVA_UNM07_test <- anovaBF(formula = mem_score ~ condition*predictiveness + pNum,
        data = data.frame(UNM07_memscore_test),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM07_test)
bay_ANOVA_UNM07_test_gxp <- bay_ANOVA_UNM07_test[4]/bay_ANOVA_UNM07_test[3]
print(bay_ANOVA_UNM07_test_gxp)
```

```{r, include = FALSE}
# SME of the condition:predictiveness interaction
SME_mem_UNM07_test <- UNM07_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem = mean(c_mem_score, na.rm = TRUE))
#calculate the simple main effect of condition
sme_mem_UNM07_test_condition <- SME_mem_UNM07_test %>%
  group_by(predictiveness) %>%
  anova_test(mem ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_mem_UNM07_test_condition #Call the output table
#calculate the simple main effect of predictiveness
sme_mem_UNM07_test_pred <- SME_mem_UNM07_test %>%
  group_by(condition) %>%
  anova_test(mem ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_mem_UNM07_test_pred #Call the output table
```

The mixed model ANOVA mirrored the findings from the accuracy analysis: there was no main effects of *group*: `r apa(ANOVA_UNM07_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM07_test[1])`, nor of *predictiveness*,`r apa(ANOVA_UNM07_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM07_test[2])`, but there was a  significant *group x predictiveness* interaction, `r apa(ANOVA_UNM07_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM07_test_gxp[1])`. Simple main effects showed a significant effect of *predictiveness* in group Certain, *F*(`r sme_mem_UNM07_test_pred[1,3]`, `r sme_mem_UNM07_test_pred[1,4]`) = `r sme_mem_UNM07_test_pred[1,5]`, *p* = `r sme_mem_UNM07_test_pred[1,9]`, *Œ∑~p~^2^* = `r sme_mem_UNM07_test_pred[1,8]`, but not in group Uncertain, *F*(`r sme_mem_UNM07_test_pred[2,3]`, `r sme_mem_UNM07_test_pred[2,4]`) = `r sme_mem_UNM07_test_pred[2,5]`, *p* = `r sme_mem_UNM07_test_pred[2,9]`, *Œ∑~p~^2^* = `r sme_mem_UNM07_test_pred[2,8]`. Again, memory score analysis suggests there was better memory for predictive cues than for non-predictive cues in group Certain, whereas this difference was not present in group Uncertain. The lack of a main effect of the group suggest that overall memory was similar in both groups.

## Discussion

Experiment 1 aimed to examine the effect of uncertainty on recognition memory for predictive and non-predictive cues. The participants in group Uncertain were exposed to a probabilistic relationship between the predictive cues and their respective outcomes, while those in group Certain received deterministic relationships. There was an effect of cue-predictiveness in group Certain with better recognition memory for the predictive than the non-predictive cues, but this effect was not present in the uncertain group, with evidence to suggest memory for predictive and non-predictive cues was equivalent. This is consistent with previous studies [@beesleyUncertaintyPredictivenessDetermine2015; @easdaleOnsetUncertaintyFacilitates2019] that have shown that attention (in those cases measured by eye-gaze dwell times) decreased for non-predictive cues but not for predictive cues, only under certain training. That decrease in attention could be responsible for the worse memory performance for the non-predictive cues, compared with the predictive cues, in the certain group. However, we hypothesised that the previously observed effect of uncertainty on increased overt attention (e.g., Beesley et al., 2015) would lead to better memory for cues in that condition. This was not the case: in a final recognition memory test, the two groups showed a similar overall level of recognition memory for the cues.

A central distinction made in Easdale et al. [-@easdaleOnsetUncertaintyFacilitates2019] was that between *expected-* and *unexpected-uncertainty*. In those experiments, participants who experienced a sustained period of training with uncertain compounds (as is the case in group ‚ÄúUncertain‚Äù in Experiment 1) learnt more slowly about new contingencies, compared to a group that received a sudden and unexpected change in the contingencies. Thus, it may be the case that the current uncertain condition does not promote higher recognition memory overall, because participants have come to expect a certain level of uncertainty and are no longer engaging in an exploratory mode of cue-processing. Of course, the expected levels of high attention to cues under uncertain conditions presents a paradox for learning and attention research: why does a high level of attention not translate to better learning and memory for those cues? We return to this point in the general discussion. Nevertheless, this analysis of the findings in terms of expected and unexpected uncertainty suggests that a more acute period of uncertainty may (re)engage a mode of exploratory attentional processing for the cues, which would result in better memory of those cues. Experiment 2 tested this hypothesis.

# Experiment 2

Experiment 2 aimed to examine whether the introduction of uncertainty, following a period of certain training (i.e., unexpected uncertainty), would lead to an increase in cue-processing (better recognition memory). The design of Experiment 2 can be seen in @tbl-exp2. The experiment consisted of three groups. Groups Certain Long and Certain Short received training that was similar to the Certain condition from Experiment 1, experiencing certain contingencies between the cue compounds and the outcomes throughout the training phase, differing only in the amount of training they experienced. Group Uncertain first experienced the same certain contingencies experienced by the certain groups, before the contingencies were changed to uncertain for a short period before the recognition memory test. Our prediction was that, if the introduction of unexpected uncertainty promotes greater levels of exploratory attention, then we should see better recognition memory performance in this uncertain condition, compared to the certain condition.

::: {#tbl-exp2 apa-note="Uppercase letters A, B, X, and Y represent the cues presented during training. O1 and O2 represent the outcomes presented in training. Lowercase letters a, b, x, and y represent the foils that are similar to the (corresponding upper-case letter) cues presented in the training phase. The numbers before the trials define the proportion of trials of that type that were presented." apa-twocolumn="true"}
+---------------+--------------+---------------------------+------------------+
| Group         | Stage 1      | Stage 2                   | Test             |
+===============+==============+:=========================:+:================:+
| Certain Long  | AX - O1      | AX - O1                   | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      | AY - O1                   | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      | BX - O2                   | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      | BY - O2                   | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+
| Certain Short | AX - O1      |                           | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      |                           | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      |                           | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      |                           | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+
| Uncertain     | AX - O1      | 0.8 AX - O1 / 0.2 AX - O2 | A vs *b*/*x*/*y* |
|               |              |                           |                  |
|               | AY - O1      | 0.8 AY - O1 / 0.2 AY - O2 | B vs *a*/*x*/*y* |
|               |              |                           |                  |
|               | BX - O2      | 0.8 BX - O2 / 0.2 BX - O1 | X vs *a*/*b*/*y* |
|               |              |                           |                  |
|               | BY - O2      | 0.8 BY - O2 / 0.2 BY - O1 | Y vs *a*/*b*/*x* |
+---------------+--------------+---------------------------+------------------+

Design of Experiment 2
:::

Group Certain Short received the same certain contingencies as the other two conditions in Stage 1 but did not experience Stage 2; they received a shorter training phase than the other two conditions. If the onset of the uncertainty leads to greater cue-processing, then we should also see better cue-memory in the Uncertain condition compared to the Certain Short condition. The inclusion of this condition is important because longer training with the certain contingencies in the ‚ÄúCertain Long‚Äù condition could *decrease* cue processing, which would be an alternative explanation of any difference in cue processing we observe between Group Uncertain and Group Certain Long. If this is the case, we should see equivalent recognition memory in the Certain Short and Uncertain conditions, and poorer recognition memory in the Certain Long condition. Therefore, the addition of this third condition allowed us to make stronger inferences about the causal relationship between the onset of uncertainty and cue-processing.

## Methods

### Participants

```{r, include=FALSE}
#load the data
load("UNM08_proc_data.RData")
UNM08_demographics <- demographics
UNM08_training <- rbind(stage1, stage2)
UNM08_test <- test
UNM08_not_passed <- not_passed_pNum
UNM08_training <- filter(UNM08_training, !pNum %in% UNM08_not_passed$pNum)
UNM08_test <- filter(UNM08_test, !pNum %in% UNM08_not_passed$pNum)
```

```{r, include = FALSE}
#create the PPR measure
UNM08_training <- UNM08_training %>%
  mutate(prob_response = case_when((cue1 == 1 | cue1 == 3) & response == "o1_image" ~ 1,
                                   (cue1 == 1 | cue1 == 3) & response == "o2_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o1_image" ~ 0,
                                   (cue1 == 2 | cue1 == 4) & response == "o2_image" ~ 1))

#detect and clean participants that had an PPR lower than 0.6 in the final block or not passed the test comprehension check
UNM08_block6 <- filter(UNM08_training, block == 6) %>%
  group_by(pNum, condition) %>%
 summarise (mean_response = mean(prob_response, na.rm = TRUE))
UNM08_low_acc_total <- filter(UNM08_block6, mean_response < 0.75) 
UNM08_low_acc <- UNM08_low_acc_total$pNum
UNM08_training <- filter(UNM08_training, !pNum %in% UNM08_low_acc_total$pNum)
UNM08_test <- filter(UNM08_test, !pNum %in% UNM08_low_acc_total$pNum)
```

`r nrow(UNM08_demographics)` participants were recruited through Prolific. The mean age of the `r nrow(UNM08_demographics) - sum(is.na(UNM08_demographics$age))` participants that reported their age was `r format(mean(UNM08_demographics$age, na.rm = TRUE), digits = 3)` (range `r min(UNM08_demographics$age, na.rm = TRUE)` - `r max(UNM08_demographics$age, na.rm = TRUE)`), with `r length(which(UNM08_demographics$gender == "female"))` women, `r length(which(UNM08_demographics$gender == "male"))` men, and one non-binary person, and `r n_distinct(UNM08_demographics$Nationality)` different nationalities. Participants were randomly allocated to each condition. Eight participants were excluded on the basis of failing the comprehension check before the test, six in group Uncertain, one in group Certain Short, and one in group Certain Long. Since all three conditions experienced the same training in Stage 1, we imposed a performance criterion of 75% PPR (i.e., accuracy) in the last block of Stage 1, on the basis that the effect of "unexpected uncertainty"  would be minimal if the contingencies had not been learned to a reasonable level at the point of this manipulation. `r nrow(UNM08_low_acc_total)` participants were excluded due to a low PPR (\< 0.75) on the last block of Stage 1, `r length(which(UNM08_low_acc_total$condition == "Certain Long"))` in group Certain Long, `r length(which(UNM08_low_acc_total$condition == "Certain Short"))` in group Certain Short and `r length(which(UNM08_low_acc_total$condition == "Uncertain"))` in group Uncertain. Thus, the results below are for the remaining `r nrow(UNM08_test)/24` participants. Post-hoc calculations using G\*Power 3.1 [@faulStatisticalPowerAnalyses2007] revealed that this sample size had a power of .79 to detect an effect size of *Œ∑~p~^2^* = .05 that was observed for the group main effect reported in @fig-testExp2.

## Results

```{r, include = FALSE}
#Calculate the mean PPR and standard error for each block, including the groups and stages
UNM08_MA_training <- UNM08_training %>%
  group_by(block, stage, condition) %>%
  summarise(mean_accuracy = mean(prob_response, na.rm = TRUE), 
            se_accuracy = sd(prob_response, na.rm = TRUE)/sqrt(length(prob_response)))

#add a dummy to display stage 2 for Certain Short
MA_stage2_dummy <- data.frame(stage = c('stage 2', 'stage 2', 'stage 2', 'stage 2'),
                              block = c(7:10),
                              condition = c('Certain Short', 'Certain Short', 'Certain Short', 'Certain Short'),
                              mean_accuracy = c(0.001, 0.002, 0.003, 0.004),
                              se_accuracy = c(0.0001, 0.00020, 0.0003, 0.00004))
UNM08_MA_training <- rbind(UNM08_MA_training, MA_stage2_dummy)
#change stage 1 and stage 2 to Stage1 and Stage 2, and Certain_short to Certain Short
UNM08_MA_training <- UNM08_MA_training %>%
  mutate(stage = case_when(stage == "stage 1" ~ "Stage 1",
                           stage == "stage 2" ~ "Stage 2"))
```

@fig-trainingExp2 shows the mean PPR for each group across the ten blocks of training. All participants showed a similar increase in PPR in stage 1, reaching a PPR of around 0.93 on block 6. In Stage 2, group Certain showed a similar PPR to block 6, but the Uncertain group showed a decrease in PPR to a level of around 0.85.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-trainingExp2
#| fig-cap: PPR on the training phase of Experiment 2.
#| apa-note: "Mean proportion of probable responses (¬±SEM) during the training phase of Experiment 2, plotted against the ten blocks of trials, for each Group."
#| fig-height: 4
ggplot(UNM08_MA_training, mapping = aes(x = block, y = mean_accuracy, group = condition)) +
  geom_point(mapping = aes(shape = condition, color = condition), size = 2.5) +
  geom_line(mapping = aes(color = condition)) +
  geom_errorbar(aes(x= block, y = mean_accuracy, ymin = mean_accuracy-se_accuracy, ymax = mean_accuracy+se_accuracy), colour = "black", width=.1)+
  facet_grid(cols = vars(stage), space = "free_x", scales = "free_x") + 
  scale_x_continuous(name = "Block", breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) + 
  scale_color_discrete(type = c("#AF8DC3", "#FEB24C", "#7FBF7B"))+
  labs(shape = "Group", color = "Group") +
  scale_y_continuous(name = "PPR", limits = c(0.5, 1))+
  theme_apa()
```

```{r, include=FALSE}
#ANOVA
UNM08_stage1 <- filter(UNM08_training, stage == "stage 1") %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
UNM08_stage1$block <- factor(UNM08_stage1$block)
UNM08_stage1$pNum <- factor(UNM08_stage1$pNum)
UNM08_stage1$condition <- factor(UNM08_stage1$condition)
ANOVA_UNM08_stage1 <- aov_car(formula = mean_response ~ condition + Error(pNum/block), data = UNM08_stage1)
print(ANOVA_UNM08_stage1)
#Bayesian Anova
bay_ANOVA_UNM08_stage1 <- anovaBF(formula = mean_response ~ condition + block + pNum,
        data = data.frame(UNM08_stage1),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM08_stage1)
bay_ANOVA_UNM08_stage1_int <- bay_ANOVA_UNM08_stage1[4]/bay_ANOVA_UNM08_stage1[3]
print(bay_ANOVA_UNM08_stage1_int)
```

The Stage 1 data were analysed with a mixed-model ANOVA, with the between-subjects factor of *group* (Certain Long, Certain Short, and Uncertain), and the within-subjects factor of *block* (1-6). This revealed a significant effect of *block*, `r apa(ANOVA_UNM08_stage1, effect = "block")`, `r report_BF_and_error(bay_ANOVA_UNM08_stage1[1], sci_not = TRUE)`. There was no effect of *group*, `r apa(ANOVA_UNM08_stage1, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM08_stage1[2])`, and no interaction effect, `r apa(ANOVA_UNM08_stage1, effect = "condition:block")`, `r report_BF_and_error(bay_ANOVA_UNM08_stage1_int[1])`.

```{r, include=FALSE}
#ANOVA
UNM08_acc <- filter(UNM08_training, condition == "Certain Long" | condition == "Uncertain") %>%
  group_by (pNum, block, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
UNM08_acc$block <- factor(UNM08_acc$block)
UNM08_acc$pNum <- factor(UNM08_acc$pNum)
UNM08_acc$condition <- factor(UNM08_acc$condition)
ANOVA_UNM08_acc <- aov_car(formula = mean_response ~ condition + Error(pNum/block), data = UNM08_acc)
print(ANOVA_UNM08_acc)
#Bayesian Anova
bay_ANOVA_UNM08_acc <- anovaBF(formula = mean_response ~ condition + block + pNum,
        data = data.frame(UNM08_acc),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_ANOVA_UNM08_acc) 
bay_ANOVA_UNM08_acc_int <- bay_ANOVA_UNM08_acc[4]/bay_ANOVA_UNM08_acc[3]
print(bay_ANOVA_UNM08_acc_int)
```

```{r, include = FALSE}
# SME of the condition:block interaction
SME_acc_UNM08_training <- filter(UNM08_training, condition == "Certain Long" | condition == "Uncertain") %>%
  group_by(pNum, condition, block) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
#calculate the simple main effect of condition
sme_acc_UNM08_training_condition <- SME_acc_UNM08_training %>%
  group_by(block) %>%
  anova_test(mean_response ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_acc_UNM08_training_condition #Call the output table
#calculate the simple main effect of block
sme_acc_UNM08_training_pred <- SME_acc_UNM08_training %>%
  group_by(condition) %>%
  anova_test(mean_response ~ block + Error(pNum/block), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_acc_UNM08_training_pred #Call the output table

SME_acc_UNM08_training_block7 <- filter(UNM08_training, block == 7) %>%
  group_by(pNum, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
SME_acc_UNM08_training_block7$condition <- factor(SME_acc_UNM08_training_block7$condition)
SME_acc_UNM08_training_block7$pNum <- factor(SME_acc_UNM08_training_block7$pNum)

SME_acc_UNM08_training_block4 <- filter(UNM08_training, block == 4) %>%
  group_by(pNum, condition) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
SME_acc_UNM08_training_block4$condition <- factor(SME_acc_UNM08_training_block4$condition)
SME_acc_UNM08_training_block4$pNum <- factor(SME_acc_UNM08_training_block4$pNum)

bay_sme_acc_UNM08_training_block7 <- anovaBF(formula = mean_response ~ condition,
        data = data.frame(SME_acc_UNM08_training_block7),
        iterations = bfit)
print(bay_sme_acc_UNM08_training_block7)
bay_sme_acc_UNM08_training_block4 <- anovaBF(formula = mean_response ~ condition,
        data = data.frame(SME_acc_UNM08_training_block4),
        iterations = bfit)
print(bay_sme_acc_UNM08_training_block4)
```

The data from Stage 1 and 2 were analysed with a mixed model ANOVA (using the Greenhouse-Geisser correction when needed), with the between-subjects factor of *group* (Certain Long vs Uncertain) and the within-subjects factor of *block* (1-10). There was no effect of *group*, `r apa(ANOVA_UNM08_acc, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc[2])`, but there was a significant effect of *block*, `r apa(ANOVA_UNM07_acc, effect = "block")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc[1], sci_not = TRUE)`, and a significant *group x block* interaction, `r apa(ANOVA_UNM08_acc, effect = "condition:block")`, `r report_BF_and_error(bay_ANOVA_UNM08_acc_int[1])`. Simple main effects showed a significant effect of condition on blocks 7 to 10, *F*(`r sme_acc_UNM08_training_condition[7, 3]`, `r sme_acc_UNM08_training_condition[7, 4]`) > `r sme_acc_UNM08_training_condition[7, 5]`, *p* < `r sme_acc_UNM08_training_condition[7, 9]`, `r report_BF_and_error(bay_sme_acc_UNM08_training_block7[1])`, but not in block 1 to 6, *F*(`r sme_acc_UNM08_training_condition[4, 3]`, `r sme_acc_UNM08_training_condition[4, 4]`), < `r sme_acc_UNM08_training_condition[4, 5]`, *p* > `r sme_acc_UNM08_training_condition[4, 9]`, `r report_BF_and_error(bay_sme_acc_UNM08_training_block4[1])`.  


Taken together, these results indicate that the training in Stage 1 increased the PPR for all groups in the same fashion, while in Stage 2, the Certain Long group showed a consistently higher PPR than the Uncertain group.

```{r, include=FALSE}
#Calculate the mean accuracy and standard error for each block, including the groups
MA_UNM08_test <- UNM08_test %>%
  group_by(predictiveness, condition) %>%
    summarise(mean_acc = mean(acc, na.rm = TRUE), 
            se_acc = sd(acc, na.rm = TRUE)/sqrt(length(acc)))
```

@fig-acctestExp2 shows the accuracy results from the recognition memory test. Overall, accuracy was higher in group Uncertain compated with the two Certain groups. Accuracy for non-predictive cues was lower than for the predictive cues in both Certain Long and Certain Short groups, but this difference was attenuated in the Uncertain group.

```{r, echo=FALSE, message=FALSE}
#| label: fig-acctestExp2
#| fig-cap: Accuracy on the test phase of Experiment 2.
#| apa-note: "Mean accuracy (¬±SEM) during the test phase of Experiment 2, across the three groups."
#| fig-height: 4
ggplot(data = MA_UNM08_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain Short','Certain Long')), y = mean_acc, fill = predictiveness)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(y= mean_acc, ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), width = .2, position = position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_y_continuous(name = "Accuracy") +
  coord_cartesian(ylim = c(0.5, 1)) +
  scale_fill_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  theme_apa()
```

```{r, include=FALSE}
#ANOVA accuracy
acc_UNM08_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(acc = mean(acc, na.rm = TRUE))
acc_UNM08_test$predictiveness <- factor(acc_UNM08_test$predictiveness)
acc_UNM08_test$condition <- factor(acc_UNM08_test$condition)
acc_UNM08_test$pNum <- factor(acc_UNM08_test$pNum)
ANOVA_acc_UNM08_test <- aov_car(formula = acc ~ condition + Error(pNum*predictiveness), data = acc_UNM08_test)
print(ANOVA_acc_UNM08_test)

bay_ANOVA_acc_UNM08_test <- anovaBF(formula = acc ~ condition*predictiveness + pNum,
        data = data.frame(acc_UNM08_test),
        whichRandom = "pNum", 
        iterations = bfit)
print(bay_ANOVA_acc_UNM08_test)

bay_ANOVA_acc_UNM08_test_gxp <- bay_ANOVA_acc_UNM08_test[4]/bay_ANOVA_acc_UNM08_test[3]
print(bay_ANOVA_acc_UNM08_test_gxp)
```

```{r, include = FALSE}
# Pairwise comparisons for the main effect of condition
acc_UNM08_test_interaction <- emmeans(ANOVA_acc_UNM08_test, ~condition)
contrast(acc_UNM08_test_interaction, adjust = "bon", "trt.vs.ctrl", ref = c(1,2))

acc_UNM08_test_certs <- subset(acc_UNM08_test, (condition == "Certain Long") | (condition == "Certain Short"), acc, drop = TRUE)
acc_UNM08_test_uncert <- subset(acc_UNM08_test, condition == "Uncertain", acc, drop = TRUE)
bay_t.test_acc_UNM08_int_uncer_vs_certs <-  ttestBF(acc_UNM08_test_certs, acc_UNM08_test_uncert)
print(bay_t.test_acc_UNM08_int_uncer_vs_certs)

pairs(acc_UNM08_test_interaction, adjust = "bon")

acc_UNM08_test_cert_l <- subset(acc_UNM08_test, condition == "Certain Long", acc, drop = TRUE)
acc_UNM08_test_cert_s <- subset(acc_UNM08_test, condition == "Certain Short", acc, drop = TRUE)
bay_t.test_acc_UNM08_test_certs <-  ttestBF(acc_UNM08_test_cert_l, acc_UNM08_test_cert_s)
print(bay_t.test_acc_UNM08_test_certs)
```

There was a significant main effect of the *group*, `r apa(ANOVA_acc_UNM08_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test[1])`, and a main effect of *predictiveness*: `r apa(ANOVA_acc_UNM08_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test[2])`. The *group x predictiveness* interaction was not significant, `r apa(ANOVA_acc_UNM08_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_acc_UNM08_test_gxp[1])`. These results indicate that all groups were more accurate at recognising predictive cues than non-predictive cues and that overall accuracy was higher in group Uncertain compared to the other two groups. This interpretation of the main effect of group was confirmed by  Bonferroni corrected pairwise comparisons, which revealed a significant difference between the overall accuracy (average of P and NP cues) in group Uncertain compared to the overall accuracy in groups Certain Long and Certain Short, *t*(133) = 3.449, *p* < .001, `r report_BF_and_error(bay_t.test_acc_UNM08_int_uncer_vs_certs[1])`. There was no difference in accuracy between group Certain Long and group Certain Short, *t*(133) = 0.01, *p* = 1, `r report_BF_and_error(bay_t.test_acc_UNM08_test_certs[1])`.

```{r, include = FALSE}
#create the memory_score
UNM08_test <- UNM08_test %>%
  mutate (c_mem_score = case_when(acc == 0 ~ 0, acc == 1 ~ mem_score))
#Calculate the mean PPR and standard error for each block, including the groups
UNM08_MS_test <- UNM08_test %>%
  group_by(predictiveness, condition) %>%
    summarise(mean_mem_score = mean(c_mem_score, na.rm = TRUE), 
            se_mem_score = sd(c_mem_score, na.rm = TRUE)/sqrt(length(c_mem_score)))
```

@fig-testExp2 shows the recognition memory scores for the three conditions. Memory for non-predictive cues was lower than for predictive cues in all groups, but this difference was notably attenuated in the Uncertain group. Mirroring the accuracy data, the memory scores for the cues in group Uncertain were on average higher, than those for groups Certain Long and Certain Short.

```{r, echo = FALSE, warning=FALSE}
#| label: fig-testExp2
#| fig-cap: Memory scores on the Test of Experiment 2.
#| apa-note: "Mean memory scores (¬±SEM) during the Test of Experiment 2 for predictive and non-predictive trials across the three groups."
#| fig-height: 4
ggplot(UNM08_MS_test, mapping = aes(x = factor(condition, level=c('Uncertain', 'Certain Short', 'Certain Long')), y = mean_mem_score, fill = predictiveness)) +
  geom_col(position = position_dodge2()) +
  geom_errorbar(aes(ymin = mean_mem_score - se_mem_score, ymax = mean_mem_score + se_mem_score), width=.2, position=position_dodge(0.9)) +
  scale_x_discrete (name = "Group") +
  scale_fill_discrete(type = c("#AF8DC3", "#7FBF7B"))+
  scale_y_continuous(name = "Memory score")+
  #scale_fill_grey(start = 0.33) +
  theme_apa()
```

```{r, include=FALSE}
#ANOVA mem_score
UNM08_memscore_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
UNM08_memscore_test$predictiveness <- factor(UNM08_memscore_test$predictiveness)
UNM08_memscore_test$condition <- factor(UNM08_memscore_test$condition)
UNM08_memscore_test$pNum <- factor(UNM08_memscore_test$pNum)
ANOVA_UNM08_test <- aov_car(formula = mem_score ~ condition + Error(pNum*predictiveness), data = UNM08_memscore_test)
print(ANOVA_UNM08_test)
bay_ANOVA_UNM08_test <- anovaBF(formula = mem_score ~ condition + predictiveness ,
        data = data.frame(UNM08_memscore_test),
        whichRandom = "pNum", 
        iterations = bfit)
print(bay_ANOVA_UNM08_test)
bay_ANOVA_UNM08_test_gxp <- bay_ANOVA_UNM08_test[4]/bay_ANOVA_UNM08_test[3]
print(bay_ANOVA_UNM08_test_gxp)
```

```{r, include = FALSE}
# Pairwise comparisons for the main effect of condition
UNM08_test_interaction <- emmeans(ANOVA_UNM08_test, ~condition)
contrast(UNM08_test_interaction, adjust = "bon", "trt.vs.ctrl", ref = c(1,2))

UNM08_test_certs <- subset(UNM08_memscore_test, (condition == "Certain Long") | (condition == "Certain Short"), mem_score, drop = TRUE)
UNM08_test_uncert <- subset(UNM08_memscore_test, condition == "Uncertain", mem_score, drop = TRUE)
bay_t.test_UNM08_int_uncer_vs_certs <-  ttestBF(UNM08_test_certs, UNM08_test_uncert)
print(bay_t.test_UNM08_int_uncer_vs_certs)

pairs(UNM08_test_interaction, adjust = "bon")

UNM08_test_cert <- subset(UNM08_memscore_test, condition == "Certain Long", mem_score, drop = TRUE)
UNM08_test_cert_s <- subset(UNM08_memscore_test, condition == "Certain Short", mem_score, drop = TRUE)
bay_t.test_UNM08_test_certs <-  ttestBF(UNM08_test_cert, UNM08_test_cert_s)
print(bay_t.test_UNM08_test_certs)
```

```{r, include = FALSE}
# SME of the condition:predictiveness interaction
SME_UNM08_test <- UNM08_test %>%
  group_by (pNum, condition, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
#calculate the simple main effect of condition
sme_UNM08_test_condition <- SME_UNM08_test %>%
  group_by(predictiveness) %>%
  anova_test(mem_score ~ condition, effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_UNM08_test_condition #Call the output table
#calculate the simple main effect of predictiveness
sme_UNM08_test_pred <- SME_UNM08_test %>%
  group_by(condition) %>%
  anova_test(mem_score ~ predictiveness + Error(pNum/predictiveness), effect.size = "pes") %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
sme_UNM08_test_pred #Call the output table

SME_UNM08_test_CL <- filter(UNM08_test, condition == "Certain Long") %>%
  group_by(pNum, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
SME_UNM08_test_CL$predictiveness <- factor(SME_UNM08_test_CL$predictiveness)
SME_UNM08_test_CL$pNum <- factor(SME_UNM08_test_CL$pNum)

bay_SME_UNM08_test_CL <- anovaBF(formula = mem_score ~ predictiveness + pNum,
        data = data.frame(SME_UNM08_test_CL),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_UNM08_test_CL)

SME_UNM08_test_CS <- filter(UNM08_test, condition == "Certain Short") %>%
  group_by(pNum, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
SME_UNM08_test_CS$predictiveness <- factor(SME_UNM08_test_CS$predictiveness)
SME_UNM08_test_CS$pNum <- factor(SME_UNM08_test_CS$pNum)

bay_SME_UNM08_test_CS <- anovaBF(formula = mem_score ~ predictiveness + pNum,
        data = data.frame(SME_UNM08_test_CS),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_UNM08_test_CS)

SME_UNM08_test_U <- filter(UNM08_test, condition == "Uncertain") %>%
  group_by(pNum, predictiveness) %>%
  summarise(mem_score = mean(c_mem_score, na.rm = TRUE))
SME_UNM08_test_U$predictiveness <- factor(SME_UNM08_test_U$predictiveness)
SME_UNM08_test_U$pNum <- factor(SME_UNM08_test_U$pNum)

bay_SME_UNM08_test_U <- anovaBF(formula = mem_score ~ predictiveness + pNum,
        data = data.frame(SME_UNM08_test_U),
        whichRandom = "pNum",
        iterations = bfit)
print(bay_SME_UNM08_test_U)
```

A mixed model ANOVA, including the between-subjects factor *group* (Certain Long, Certain Short, Uncertain), and the within-subjects factor *predictiveness* (predictive vs non-predictive) showed a significant main effect of *group*, `r apa(ANOVA_UNM08_test, effect = "condition")`, `r report_BF_and_error(bay_ANOVA_UNM08_test_gxp[1])`, and *predictiveness*, `r apa(ANOVA_UNM08_test, effect = "predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM08_test[2])`, and a significant *group x predictiveness* interaction, `r apa(ANOVA_UNM08_test, effect = "condition:predictiveness")`, `r report_BF_and_error(bay_ANOVA_UNM08_test_gxp[1])`. However, is worth noting that the Bayesian analysis indicated moderate evidence in favour of the null hypothesis for this interaction. Bonferroni corrected pairwise comparisons on the main effect of *group* showed that group Uncertain differed significantly from the average of the Certain groups, *t*(133) = 2.624, *p* = .01, `r report_BF_and_error(bay_t.test_UNM08_int_uncer_vs_certs[1])`, but memory scores for the two Certain groups did not differ  from each other, *t*(133) = 0.732, *p* = 1, `r report_BF_and_error(bay_t.test_UNM08_test_certs[1])`, with the Bayesian evidence suggesting that memory performance was the same in these two groups. Furthermore, simple main effects showed a significant effect of *predictiveness* for group Certain Long, *F* (`r sme_UNM08_test_pred[1, 3]`, `r sme_UNM08_test_pred[1, 4]`) = `r sme_UNM08_test_pred[1, 5]`, *p* = `r sme_UNM08_test_pred[1, 9]`, *Œ∑~p~^2^* = `r sme_UNM08_test_pred[1, 8]`, `r report_BF_and_error(bay_SME_UNM08_test_CL[1])`, and for group Certain Short, *F* (`r sme_UNM08_test_pred[2, 3]`, `r sme_UNM08_test_pred[2, 4]`) = `r sme_UNM08_test_pred[2, 5]`, *p* = `r sme_UNM08_test_pred[2, 9]`, *Œ∑~p~^2^* = `r sme_UNM08_test_pred[2, 8]`, `r report_BF_and_error(bay_SME_UNM08_test_CS[1])`, but not for group Uncertain, *F* (`r sme_UNM08_test_pred[3, 3]`, `r sme_UNM08_test_pred[3, 4]`) = `r sme_UNM08_test_pred[3, 5]`, *p* = `r sme_UNM08_test_pred[3, 9]`, *Œ∑~p~^2^* = `r sme_UNM08_test_pred[3, 8]`, `r report_BF_and_error(bay_SME_UNM08_test_U[1])`.

## Discussion

Experiment 2 examined the effect of unexpected uncertainty on recognition memory. The ‚ÄúUncertain‚Äù group of participants first experienced a period of training with certain contingencies, before receiving a second period with uncertain contingencies. Participants that were exposed to this unexpected uncertainty showed a higher level of recognition memory for the cues than participants that received only certain training. An important difference between Experiment 2 and 3 is that in Experiment 2, the Certain and Uncertain groups had a similar recognition memory for the cues, whereas in the current experiment, the Uncertain group showed better cue-recognition. We interpret this difference to be a consequence of the expectancy of uncertainty: in Experiment 2, but not Experiment 2, uncertainty is suddenly introduced after a sustained period of certain training.

These results suggest that introducing a period of unexpected uncertainty results in enhanced cue processing, consistent with previous results [@easdaleOnsetUncertaintyFacilitates2019] that showed that unexpected uncertainty enhances learning. Easdale et al. used a training phase in which participants learnt about either certain or uncertain contingencies. Participants showed better attention to cues under uncertain conditions. However, when those cues were subsequently trained under new contingencies, it was participants in the certain condition that learnt about these more rapidly, compared to those participants in the uncertain condition. Easdale et al. suggested that the transition from certain to uncertain contingencies brought about a state of ‚Äúunexpected uncertainty‚Äù which promoted new learning. Experiment 2 shows more directly that a period of unexpected uncertainty leads to superior cue processing and stronger memory representations.
